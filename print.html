<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>AI Resources</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="overview.html"><strong aria-hidden="true">1.</strong> Overview</a></li><li class="chapter-item expanded "><a href="applications.html"><strong aria-hidden="true">2.</strong> Applications</a></li><li class="chapter-item expanded "><a href="multidisciplinary_approach.html"><strong aria-hidden="true">3.</strong> A Multidisciplinary Approach</a></li><li class="chapter-item expanded "><a href="approaches.html"><strong aria-hidden="true">4.</strong> Approaches</a></li><li class="chapter-item expanded "><a href="topics.html"><strong aria-hidden="true">5.</strong> ML/DL Topics</a></li><li class="chapter-item expanded "><a href="nlp.html"><strong aria-hidden="true">6.</strong> NLP</a></li><li class="chapter-item expanded "><a href="productionizing.html"><strong aria-hidden="true">7.</strong> To Production</a></li><li class="chapter-item expanded "><a href="tools_and_frameworks.html"><strong aria-hidden="true">8.</strong> Frameworks</a></li><li class="chapter-item expanded "><a href="books_and_resources.html"><strong aria-hidden="true">9.</strong> Books and Resources</a></li><li class="chapter-item expanded "><a href="conferences.html"><strong aria-hidden="true">10.</strong> Conferences</a></li><li class="chapter-item expanded "><a href="people.html"><strong aria-hidden="true">11.</strong> People</a></li><li class="chapter-item expanded "><a href="vocabulary.html"><strong aria-hidden="true">12.</strong> Vocabulary</a></li><li class="chapter-item expanded affix "><a href="bibliography.html">Bibliography</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">AI Resources</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#overview" id="overview">Overview</a></h1>
<p>At the beginning of 2021, it's been some years by now that we are immersed in the world of data, the Big Data. In the last few years, <a href="https://www.forbes.com/sites/bernardmarr/2018/05/21/how-much-data-do-we-create-every-day-the-mind-blowing-stats-everyone-should-read/?sh=4a82404a60ba">we've 
generated and collected more data than in all the previous history of mankind</a>.
This fact, joint with the recent improvements in computing power in the last decades, and the advances in a wide 
diversity of fields related to cognitive sciences have propelled Artificial Intelligence and Machine Learning to a new
status of preponderance in the modern world. Modern ML has already impacted our lives, and the impact will be higher in the
forthcoming years.</p>
<p>I love AI/ML because is a very complex topic which has to be approached with a multi-disciplinary view. It's a compendium 
of the advances and applications of well proven knowledge and battle-tested technology in many other fields, including:</p>
<ul>
<li>Mathematics &amp; Statistics</li>
<li>Neuroscience</li>
<li>Computer Science</li>
<li>Philosophy</li>
<li>Psychology</li>
<li>Medicine</li>
<li>Biology</li>
<li>Physics</li>
<li>Economics</li>
<li>Algorithmic Biology</li>
</ul>
<p>However, as it is true with most of the things in life, and despite the current advances and breakthroughs in the field, 
nothing is set in stone; we are and we'll continue being forever human &amp; machine learners. As Newton stated in 1675, 
&quot;If I have seen further it is by standing on the shoulders of Giants.&quot; The only thing that is potentially different 
today from that Newton's assertion back in those days is that from now on, maybe the Giants won't be only other humans; 
maybe they'll be also artificially created machines, algorithms or models.</p>
<p>A few years ago, I found in Jorge Luis Borges' Funes the Memorious, what I thought it was a beautiful unconscious 
portrait in the form of words that I think summarizes quite well the current State of the Art of Artificial Intelligence/Machine 
Learning at the begining of the XXI century:</p>
<pre><code class="language-text">&quot;Había aprendido sin esfuerzo el inglés, el francés, el portugués, 
el latín. Sospecho, sin embargo, que no era muy capaz de pensar. 
Pensar es olvidar diferencias, es generalizar, es abstraer. En 
el abarrotado mundo de Funes no había sino detalles, casi inmediatos.&quot;

Funes el Memorioso (1944) - Jorge Luís Borges
</code></pre>
<pre><code class="language-text">&quot;With no effort, he had learned English, French, Portuguese and
Latin. I suspect, however, that he was not very capable of thought.
To think is to forget differences, generalize, make abstractions. In
the teeming world of Funes, there were only details, almost
immediate in their presence.&quot;

Funes the Memorious (1944) - Jorge Luís Borges
</code></pre>
<p>There are interesting times ahead of us. This field, joint with the advances in another promising multidisciplinary
scientific field, <a href="https://en.wikipedia.org/wiki/Bioinformatics">bioinformatics</a> and the possible fast development of
quantum computing in the next few years, guarantee endless fun for scientist and engineers in the next decades. This 
book pretends to be my modest log and diary on the topics depicted above and others that will arise along the way.</p>
<h1><a class="header" href="#mindmap" id="mindmap">Mindmap</a></h1>
<iframe width='853' height='480' src='https://gitmind.com/app/doc/0f62047898' frameborder='0' allowfullscreen></iframe><h1><a class="header" href="#applications" id="applications">Applications</a></h1>
<ul>
<li><a href="https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf">DeepFace</a> always remind me of how Schwarzenegger is framed for the murder of almost a hundred unarmed civilians in <a href="https://www.imdb.com/title/tt0093894/">The Running Man</a></li>
</ul>
<p>This is an example of citation [Unknown bib ref: ven_brain-inspired_2020] in an mdBook </p>
<h2><a class="header" href="#prediction" id="prediction">Prediction</a></h2>
<h2><a class="header" href="#regression" id="regression">Regression</a></h2>
<h2><a class="header" href="#classification" id="classification">Classification</a></h2>
<h2><a class="header" href="#recommender-systems" id="recommender-systems">Recommender systems</a></h2>
<h2><a class="header" href="#recognition-images-audio-text" id="recognition-images-audio-text">Recognition (images, audio, text)</a></h2>
<h2><a class="header" href="#computer-vision" id="computer-vision">Computer vision</a></h2>
<h2><a class="header" href="#clustering-and-anomaly-detection" id="clustering-and-anomaly-detection">Clustering and anomaly detection</a></h2>
<h2><a class="header" href="#natural-language-processing-generation-and-understanding" id="natural-language-processing-generation-and-understanding">Natural language processing, generation, and understanding</a></h2>
<h2><a class="header" href="#translation" id="translation">Translation</a></h2>
<p>Along 2016/2017 Google switched from sentence-based/linguistic expert-based algorithmic approach to deep-learning based 
methods (what is called Neural Machine Translation, or NMT.) The leap in quality of the transations was massive:</p>
<ul>
<li><a href="https://blog.google/products/translate/found-translation-more-accurate-fluent-sentences-google-translate/">Found in translation: More accurate, fluent sentences in Google Translate (Barak Turovsky, Google Translate Product Lead, Nov 2016</a></li>
<li><a href="https://www.blog.google/products/translate/higher-quality-neural-translations-bunch-more-languages/">Higher quality neural translations for a bunch more languages (Barak Turovsky, Google Translate Product Lead, Mar 2017)</a></li>
<li><a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html">A Neural Network for Machine Translation, at Production Scale</a></li>
<li><a href="https://www.theatlantic.com/technology/archive/2018/01/the-shallowness-of-google-translate/551570/">The Shallowness of Google Translate (Douglas Hofstadter)</a></li>
</ul>
<h2><a class="header" href="#financial" id="financial">Financial</a></h2>
<p>FinBERT special pretraining with a large financial corpora of articles {{ cite yang_finbert_2020 }} </p>
<h2><a class="header" href="#medicine" id="medicine">Medicine</a></h2>
<p>Dermatology - Detect skin cancer or problematic skin ir</p>
<h2><a class="header" href="#legallaw" id="legallaw">Legal/Law</a></h2>
<h3><a class="header" href="#programing-languages" id="programing-languages">Programing Languages</a></h3>
<ul>
<li><a href="https://www.oreilly.com/radar/automated-coding-and-the-future-of-programming/?sfmc_id=85378584&amp;utm_medium=email&amp;utm_source=platform+b2b&amp;utm_campaign=engagement&amp;utm_content=whats+new+thinking+20200831">Automated Coding article (O'Reilly)</a></li>
<li><a href="https://arxiv.org/pdf/2006.03511.pdf">Unsupervised Translation of Programming Languages</a></li>
</ul>
<h1><a class="header" href="#ai-as-a-multidisciplinary-approach" id="ai-as-a-multidisciplinary-approach">AI as a Multidisciplinary Approach</a></h1>
<p>This chapter is devoted to describe high level concepts, topics and discussions that other disciplines around ML are
providing.</p>
<h1><a class="header" href="#brain---computer" id="brain---computer">Brain -&gt; Computer</a></h1>
<p>With what we have now know about the brain, we can definitely say that does not operate on logical functions.
The brain is a compound of deeply intertwined subsystems based on neurons that mix the properties of analog and digital 
signals.</p>
<h2><a class="header" href="#error-correction-in-the-brain" id="error-correction-in-the-brain">Error Correction in the Brain</a></h2>
<p>Apart from studying information <a href="people.html#John_von_Neumann">John von Neumman</a> studied the brain and how can it be reliable
most of the time out of unreliable components (e.g. neurons misfiring in a particular region of the brain) He concluded
that redundancy was the key to make the brain correct mistakes. Redundancy is also key to build reliable centralized and distributed systems in computer 
software. </p>
<h1><a class="header" href="#algorithms-and-dl" id="algorithms-and-dl">Algorithms and DL</a></h1>
<p>In Chapter 13 of his [The Deep Learning Revolution] book, T. Segnosky talks about the work of <a href="people.html#Stephen_Wolfgram">Stephen Wolfgram</a> 
and mentions what he calls Wofgram's law in the realm of neural networks. In April 2020, Wofgram presented his theory about
a new approach to find a fundamental theory of physics joint with an <a href="https://www.wolframphysics.org/">accompanying project</a> 
to the world in an extensive <a href="https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/">blog post</a>.
He blog post points to with a document of more than 400 pages {{ cite wolfgram_class_2020 }} where he details all his ideas.</p>
<p>Since then, <a href="https://www.scientificamerican.com/article/physicists-criticize-stephen-wolframs-theory-of-everything/#:%7E:text=Stephen%20Wolfram%20blames%20himself%20for%20not%20changing%20the%20face%20of%20physics%20sooner.&amp;text=At%20its%20heart%2C%20Wolfram&#x27;s%20new,resemble%20lines%20of%20computer%20code.">researchers haven't been very receptive</a> 
with his ideas. However, if from his theory we distill the idea that a meta-algorithm could be defined and used
to find other neural networks, that seems to smell to what <a href="https://francisco-perez-sorrosal.github.io/qc-resources/">Quantum Computing</a>
may bring to the table in the future if it develops its full potential. In particular, Sejnowsky raises the question of
whether it would be possible to find a region of the algorithm space faster than with gradient descent and how that
may not be that crazy if it's compared with what nature has done to evolve organisms (he cites Stephen Jay Gould and Niles
Eldredge and the process they described in 1972 as <a href="https://en.wikipedia.org/wiki/Punctuated_equilibrium">&quot;punctuated equilibria&quot;</a>.</p>
<iframe width='853' height='480' src='https://en.wikipedia.org/wiki/Punctuated_equilibrium#/media/File:Fossils_in_Evolutionary_Biology.png' frameborder='3' allowfullscreen>Example of Punctuated Equilibrium in Fossils</iframe>
<h1><a class="header" href="#aproaches-and-flavors-in-aiml" id="aproaches-and-flavors-in-aiml">Aproaches and Flavors in AI/ML</a></h1>
<h2><a class="header" href="#approaches-to-ml" id="approaches-to-ml">Approaches to ML</a></h2>
<p>The following categorization is done for simplification and is based on the one done by Pedro Domingos in 
[<a href="bibliography.html#domingos_master_2015">domingos_master_2015</a>]. The influence of each one of them has varied along the evolution of machine learning, 
but in the end all them influence each other in some way or another; so, many times, the &quot;boundaries&quot; we humans
tend to trace among them (or in any other categorization) they only exist in our imagination.</p>
<h3><a class="header" href="#symbolist" id="symbolist">Symbolist</a></h3>
<p>Learning is viewed as a kind of inverse approach of deduction. Very influenced by logic and the need of humans
to try to represent abstract problems in a human-readable way to facilitate communication with each other. It had early 
successes in early AI computer programs, in particular in the era of [expert systems](vocabulary.md#Expert System).</p>
<h3><a class="header" href="#connectionist" id="connectionist">Connectionist</a></h3>
<p>Basically this approach is based on studying the recent advances in cognitive sciences related to how the brain works 
and try to do a reverse engineering process of what has been learn. In cognitive sciences there have been and still
are many  researchers that advocate for ToMs that posits that the mind is only made up of randomly arranged neurons. We 
can say Artificial Neural Networks (ANNs) were the main result of this line of though.</p>
<p>However, this view is a very restricted one for many other researchers, for example <a href="people.html#gary-marcus">Gary Marcus</a> 
There are other trends like Neural-Symbolic systems that try to combine ANN and logic
{{ cite besold_neural-symbolic_2018 }} to try to build systems able to learn and reason.</p>
<p>As neuroscience is indeed influenced by physics
the connectionists, may model also the artificial neurons based on the physical properties observed in real neurons
. That's why in this approach we can include also the neuromorphic approach, which models neurons in a more similar
fashion to the neurons in the brain. For example, a neuromorphic neuron uses  just 1-bit spike to communicate with other neurons. 
Neurons can send these spikes in order to activate more or less neurons connected to them. <a href="people.html#carver-mead">Carver Mead</a>
was one of the initial contributors in developing this approach. More recently, <a href="https://www.ibm.com/blogs/research/category/neuromorphic-computing/?mhsrc=ibmsearch_a&amp;mhq=neuromorphic%20computing">IBM</a> 
or the <a href="http://e-lab.github.io/index.html">e-lab</a> at Purdue university have continued developing these ideas of this
field, now called <a href="vocabulary.html#neuromorphic-computing">neuromorphic computing</a>. Although there are <a href="http://apt.cs.manchester.ac.uk/projects/SpiNNaker/">simulators
</a> 
in conventional hardware for modelling this approach, this is highly ineficient, as for example, among other limitations
, 32-bits are used to model 1-bit spikes, so in order to fully develop neurorphic computing special hardware is needed. </p>
<h4><a class="header" href="#from-the-early-days-in-connectionism-towards-deep-learning" id="from-the-early-days-in-connectionism-towards-deep-learning">From the Early Days in Connectionism, towards Deep Learning</a></h4>
<pre><code class="language-textmate">Alan Turing's Intelligence Machinery (1948) -&gt; Perceptron (1962) -&gt; Hopfield Net (1982) -&gt; Bolzman Machines(1985) -&gt; Backprop (1986) -&gt; First NIPS Conf. (1987) -&gt; Deep Learning matures as a field on its own in NIPS Conf. (2012)
</code></pre>
<h3><a class="header" href="#evolutionary" id="evolutionary">Evolutionary</a></h3>
<p>Influenced by genetics and evolutionary biology, this approach tries to simulate this evolutionary environment
through computers. </p>
<h3><a class="header" href="#bayesian" id="bayesian">Bayesian</a></h3>
<p>This approach is based mainly in applying probabilistic inference to mimic the learning process and of course is
strongly influenced by mathematics and statistics. </p>
<p><a href="topics.html#Causality">Causal inference</a> can also be included in this approach. Human beings we tend to approach situations in terms of
cause and effect; this framework of thinking often modifies our behaviour when we find (or at least we think we've 
found) WHY a certain event has occurred and what are its consequences.</p>
<p>Some of the main advocates of this approach in its modern conception is <a href="people.html#Judea_Pearl">Judea Pearl</a>.</p>
<h4><a class="header" href="#analogizers" id="analogizers">Analogizers</a></h4>
<p>They consider that learning is done by abstracting and reconciling experiences. Influenced by psychology and cognitive
sciences in general and math optimization.</p>
<h3><a class="header" href="#actioninst" id="actioninst">Actioninst</a></h3>
<p>The approach is based on the fact that a limited set of basic behaviours or states in a system can lead to more complex 
ones, by correcting themselves through observation and subsequent action. This has to do to what is known as [reinforcement learning](#Reinforcement Learning)
and <a href="https://en.wikipedia.org/wiki/Behavior-based_robotics">behavioral robotics</a>. 
In the case of robots, this paradigm advocates that the most effective mechanism to learn sensory-motor cognitive 
abilities like walking, should be based on interactions with the environment. After all, this is more or less how toddlers
learn to walk; model these kind of interactions programmatically through abstract reasoning based on rules, 
it's inefficient and prone to errors. </p>
<h3><a class="header" href="#autonomicsurvivalistic" id="autonomicsurvivalistic">Autonomic/Survivalistic</a></h3>
<p>The approach is based on the fact that intelligent complex systems like humans, are able to survive on their own. In
order to do that, we rely in parts of the brain that either are not well understood now or they haven't taken into account
yet in the artificial systems implemented. This can be related to the field of <a href="https://en.wikipedia.org/wiki/Autonomic_computing">autonomic computing</a>.</p>
<p>Some of these brain areas are:</p>
<ul>
<li>
<p>Hypothalamus, which controls basic non-conscious subsystems related to maintaining body temperature, thirst, hunger 
and other homeostatic systems. Some of these could be mimicked by a computer system; e.g. the case of feeding, an 
intelligent ingestion data pipeline could be feeding a self-adaptive a neural network.</p>
</li>
<li>
<p>Cerabellum, which is located near the brainstem, and is responsible to coordinate movements. In the case of robotics,
this is related to the field of <a href="https://en.wikipedia.org/wiki/Behavior-based_robotics">behavioral robotics</a> and all the
advances done by companies such as <a href="https://www.bostondynamics.com/">Boston Dynamics</a>, Samsung STAR Labs or NASA.</p>
</li>
</ul>
<h3><a class="header" href="#adaptable" id="adaptable">Adaptable</a></h3>
<p>Kind of similar to the <a href="approaches.html#Autonomic/Survivalistic">Autonomic/Survivalistic</a> approach but taken from the 
point of view of computer science instead of the survival of species.
When modeling learning in with an artificial machine/algorithms, why be limited by Turing Machines? Human computational
power is way beyond what a Turing machine is capable to do and this approach tries to mimic that. The adaptable approach
is related to what is known as the Super-Turing Computation or [Lifelong Learning](topics.md#Continual Learning and Catastrophic Forgetting). 
This is also related to the <a href="https://www.darpa.mil/program/time-aware-machine-intelligence">Time-Aware Machine Intelligence (TAMI) program</a> at DARPA, 
which aims to model meta-learning.</p>
<h2><a class="header" href="#flavors-in-ml" id="flavors-in-ml">Flavors in ML</a></h2>
<h3><a class="header" href="#reinforcement-learning" id="reinforcement-learning">Reinforcement Learning</a></h3>
<p>A branch of machine learning that was influenced by the associative learning approach observed in animals and
newborns/young adults.</p>
<h1><a class="header" href="#machinedeep-learning-topics" id="machinedeep-learning-topics">Machine/Deep Learning Topics</a></h1>
<h2><a class="header" href="#artificial-general-inteligence" id="artificial-general-inteligence">(Artificial) General Inteligence</a></h2>
<p>This has been, is, and will be for some more time at least, the dream of scientist/researchers/engineers in the field of 
artificial intelligence.</p>
<p>In short, achieving a general artificial intelligence assumes the ability of an agent to learn new tasks whilst maintaining 
a general capability on fulfilling previous learned tasks.
This artificial general intelligence requires that the agent does not forget what it has learn -what is called <a href="topics.html#catastrophic_forgetting">catastrophic forgetting</a>
in the literature- and assumes that the agent will continue learning new tasks -called <a href="topics.html#continual-learning">continual or lifelong learning</a>.</p>
<h2><a class="header" href="#loss-function" id="loss-function">Loss Function</a></h2>
<p>Papers:</p>
<ul>
<li><a href="https://arxiv.org/abs/2006.13593">Retrospective Loss: Looking Back to Improve Training of Deep Neural Networks (KDD 2020)</a>	
Learns from prior training experiences in the form of DNN model states during to guide weight updates and improve DNN 
training performance. The retrospective loss seeks to ensure that the predictions at a particular training step are more 
similar to the ground truth than to the predictions from a previous training step (which has relatively
poorer performance). As training proceeds, minimizing this loss along with the task-specific loss, encourages the 
network parameters to move towards the optimal parameter state by pushing the training into tighter spaces around the 
optimum. Claims implementation is 3 lines of Pytorch code. Interesting paper</li>
</ul>
<h2><a class="header" href="#transfer-learning" id="transfer-learning">Transfer Learning</a></h2>
<p>Recent success of DL has been produced, among other reasons, for the big amount of labeled training data.
However, in general, this is not the approach to follow for AI solving different tasks.
Humans are good at learning from very few examples, so scientifically there's still &quot;something&quot; we still need to understand.</p>
<p>Approach of modern Transfer-Learning: </p>
<ol>
<li>Pre-train in large genral corpus, usually unsupervised (e.g. as in BERT)</li>
<li>Fine-Tunning on specific tasks with smaller (supervised) training sets.</li>
</ol>
<p>Approach of Hierarchical-Multilevel Classification:</p>
<ul>
<li><a href="https://www.aclweb.org/anthology/P19-1633/">Hierarchical Transfer Learning for Multi-label Text Classification (ACL 2019)</a></li>
<li><a href="https://arxiv.org/abs/2005.10996">Multi-Source Deep Domain Adaptation with Weak Supervision for Time-Series Sensor Data (KDD 2020)</a>
Interesting</li>
</ul>
<h3><a class="header" href="#surveys" id="surveys">Surveys</a></h3>
<ul>
<li><a href="https://docs.google.com/presentation/d/1fIhGikFPnb7G5kr58OvYC3GN4io7MznnM0aAgadvJfc/edit?ts=5c8d09e7#slide=id.g5888218f39_364_0">HuggingFace Presentation on Transfer Learning</a></li>
<li>2010 <a href="https://www.cse.ust.hk/%7Eqyang/Docs/2009/tkde_transfer_learning.pdf">A Survey on Transfer Learning</a></li>
<li>2018 <a href="https://arxiv.org/abs/1808.01974">A Survey on Deep Transfer Learning</a></li>
<li>2020 <a href="https://arxiv.org/abs/2007.04239">A Survey on Transfer Learning in Natural Language Processing</a></li>
</ul>
<h3><a class="header" href="#few-shot-learning-meta-learning" id="few-shot-learning-meta-learning">Few-shot Learning (Meta-learning)</a></h3>
<p>Meta-learning aims to train a general model in several learning tasks. The goal is that the resulting model has to be able to solve unseen tasks by using just 
a few training examples.</p>
<p>Concept of [shortcut learning]: You don't learn a task by completely understanding it but by taking &quot;shortcuts&quot; imitating.
e.g. when training on some math exercises in highschool because every year they had the same structure. </p>
<ul>
<li><a href="https://arxiv.org/abs/2004.07780">Shortcut Learning in Deep Neural Networks</a></li>
</ul>
<p>Meta-Learning -learning (how) to learn-: Find an algorithm <img src="https://render.githubusercontent.com/render/math?math=A"> that from a small input data (few-shot examples) <img src="https://render.githubusercontent.com/render/math?math=DS_{train}(x_i,y_i)"> can predict the output <img src="https://render.githubusercontent.com/render/math?math=y'"> of a new input 
<img src="https://render.githubusercontent.com/render/math?math=x'"></p>
<ul>
<li>
<p>Prototypical Networks <a href="">Prototypical Networks for Few-shot Learning</a>
Nearest centroid classification</p>
</li>
<li>
<p>MAML <a href="">Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</a> 
Model-agnostic meta-learning algorithm compatible with any model trained with GD and applicable to a variety of different learning problems, including 
classification, regression, and reinforcement learning.</p>
</li>
<li>
<p><a href="">Selecting Relevant Features from a Multi-Domain Representation for Few-shot Learning</a></p>
</li>
</ul>
<p>Work from Hugo Larochelle at Google Brain:</p>
<ul>
<li><a href="">Meta-Dataset: A Dataset of Datasets for Learning to Learn from Few Examples</a></li>
<li><a href="">A Universal Representation Transformer Layer for Few-shot Image Classification</a></li>
</ul>
<h2><a class="header" href="#calibration" id="calibration">Calibration</a></h2>
<p>A measure of the confidence of the predictions of a model. Concept comes from weather forecast.</p>
<p>Main Methods:</p>
<ul>
<li>Platt Scaling</li>
<li>Matrix Vector Scaling</li>
<li>Temperature scaling</li>
</ul>
<p>Papers:</p>
<ul>
<li><a href="https://arxiv.org/abs/1706.04599">On Calibration of Modern Neural Networks (ICML 2017)</a></li>
<li><a href="https://papers.nips.cc/paper/9397-beyond-temperature-scaling-obtaining-well-calibrated-multi-class-probabilities-with-dirichlet-calibration.pdf">Beyond temperature scaling: Obtaining well-calibrated multiclass probabilities with Dirichlet calibration (NeurIPS 2019)</a></li>
</ul>
<details>
  <summary>Blogs</summary>
 * [How and When to Use a Calibrated Classification Model with scikit-learn](https://machinelearningmastery.com/calibrated-classification-model-in-scikit-learn/)
 * [Prediction & Calibration Techniques to Optimize Performance of Machine Learning Models](https://towardsdatascience.com/calibration-techniques-of-machine-learning-models-d4f1a9c7a9cf)
 * [Calibration in Machine Learning](https://medium.com/analytics-vidhya/calibration-in-machine-learning-e7972ac93555#:~:text=In%20this%20blog%20we%20will%20learn%20what%20is%20calibration%20and,when%20we%20should%20use%20it.&text=We%20calibrate%20our%20model%20when,output%20given%20by%20a%20system.)
 * [Calibration Tutorial (KDD 2020)](http://kdd2020.nplan.io/presentation) [Github](https://github.com/nplan-io/kdd2020-calibration)
</details>
<details>
  <summary>Videos</summary>
 * [Calibration Tutorial](https://www.youtube.com/watch?v=rhnqZV6eKlg&feature=youtu.be)
</details>
<h2><a class="header" href="#causality" id="causality">Causality</a></h2>
<ul>
<li><a href="http://bayes.cs.ucla.edu/WHY/">The Book of Why (Judea Perl)</a></li>
<li><a href="https://github.com/DataForScience/CausalInference">Causal Inference Intro with Exercises</a></li>
<li><a href="https://arxiv.org/abs/1907.02893">Invariant Risk Minimization</a>
Learning paradigm to estimate invariant correlations across multiple training distributions. IRM learns a data representation such that the optimal classifier, 
on top of that data representation, matches for all training distributions.</li>
</ul>
<h2><a class="header" href="#a-namecontinual_learningacontinual-learning-and-catastrophic-forgetting" id="a-namecontinual_learningacontinual-learning-and-catastrophic-forgetting"><a name="continual_learning"></a>Continual Learning and Catastrophic Forgetting</a></h2>
<p>In biology, <em>Continual Learning</em> refers to the process of continually gather, update, and transfer skills/knowledge 
throughout life (lifespan).</p>
<p>In ML, it is still a major research problem to solve the fact that neural networks use to catastrophically forget 
previously learned tasks when they are trained in new ones. This fact it is the main obstacle that prevents the 
equivalent of continual learning to be implemented in the field of artificial neural networks.</p>
<p><a href="https://www.aclweb.org/anthology/2020.coling-main.574.pdf">This is a summary of the recent (2021) advances in continual learning in NLP.</a></p>
<p><a href="people.html#terrence-sejnowsky">Sejnowski</a> et al. {{ cite tsuda_modeling_2020 }} have developed a NN
architecture that shows how
hierarchical gating supports adaptive learning while preserving memories from prior experience. 
They show also how when introducing damages in the model, it recapitulates disorders found on the 
human Prefrontal Cortex.</p>
<h3><a class="header" href="#a-namecatastrophic_forgettingaprotocolsstrategies-for-solving-catastrophic-forgetting-cf" id="a-namecatastrophic_forgettingaprotocolsstrategies-for-solving-catastrophic-forgetting-cf"><a name="catastrophic_forgetting"></a>Protocols/Strategies for Solving Catastrophic Forgetting (CF)</a></h3>
<p>One problem with all the different strategies proposed for solving CF is that the field lacks a framework for comparing
the effectiveness of the techniques. This has been addressed by studies like <a href="refs.html#vandeven2019">vandeven2019</a> and <a href="refs.html#vandeven2019b">vandeven2019b</a>.</p>
<p>The approaches to solve Catastrophic Forgetting can be classified in:</p>
<h4><a class="header" href="#regularization-approaches" id="regularization-approaches">Regularization Approaches</a></h4>
<p>https://arxiv.org/pdf/1612.00796.pdf</p>
<h4><a class="header" href="#generative-replay" id="generative-replay">Generative Replay</a></h4>
<ul>
<li><a href="refs.html#parisi2020">Continual Lifelong Learning with Neural Networks:A Review</a></li>
<li><a href="https://www.nature.com/articles/s41467-020-17866-2.epdf?sharing_token=bkJqxr4qptypBkYehsw_FtRgN0jAjWel9jnR3ZoTv0NoUJpE84DVnSx_jyG1N8KQimOuCCtJtaDabIpjOWE47UccZTsgeeOekV8ng2BR-omuTPXahD4aCOiCIIfIO2IOB-qJOABLKf7BlAYsTBE8rCeZYZcKd0yuWJjlzAEc1G8%3D">Brain-inspired replay for continual learning with artiﬁcial neural networks (Nature, 2020)</a></li>
<li><a href="https://arxiv.org/pdf/1809.10635v2.pdf">Generative replay with feedback connections as a general strategy for continual learning (ICLR2019)</a></li>
<li><a href="https://arxiv.org/pdf/1904.07734.pdf">Three Scenarios for Continual Learning</a></li>
<li><a href="https://openreview.net/pdf?id=rklnDgHtDS">Compositional language continual learning</a></li>
</ul>
<h1><a class="header" href="#gans-and-creativity" id="gans-and-creativity">GANs and Creativity</a></h1>
<h1><a class="header" href="#nlp" id="nlp">NLP</a></h1>
<p>Initially, the NLP or Computational Linguistics field was focused on applying the generative grammar approach described 
by <a href="people.html#noam_comsky">Noam Chomsky</a> in <a href="https://en.wikipedia.org/wiki/Generative_grammar">the mid 60s</a>.
However, the results of applying that approach was never impressive.</p>
<p>Since then, other approachs like tagging Part of Speech (PoS) in sentences and applying statistical techniques have been
demostrated to be more successful in the NLP field. As it's usually described in any other modern ML field, the successful
application of these techniques has been only possible due to the increase in computing power and the tagging and recollection
of big datasets that have occurred in the last coupule of decades.</p>
<p>Nowadays, in the start of the third decade of the XXI century, the so called language models are predominant and applied 
in many of the problems related to NLP. </p>
<h2><a class="header" href="#frameworks" id="frameworks">Frameworks</a></h2>
<ul>
<li><a href="https://huggingface.co/">Huggingface</a> The de-facto standard framework for modern NLP.</li>
<li><a href="https://github.com/lucidrains/x-transformers">X-Transformers</a> A new repo, implementing also the later
advances in the spectrum of Transformer-based models.</li>
<li><a href="https://github.com/NervanaSystems/nlp-architect">NLP Architect</a></li>
</ul>
<h1><a class="header" href="#blogs--repos" id="blogs--repos">Blogs &amp; Repos</a></h1>
<ul>
<li><a href="https://github.com/neubig/lowresource-nlp-bootcamp-2020">NLP Bootcamp</a> CMU lectures on NLP by visitors to the
Language Technologies Institute.</li>
</ul>
<h1><a class="header" href="#nlp-topics" id="nlp-topics">NLP Topics</a></h1>
<h2><a class="header" href="#text-categorization" id="text-categorization">Text Categorization</a></h2>
<p>One of the classical problems in NLP.</p>
<p><strong>Goal</strong>: Assign labels/tags to text examples (e.g. sentences, paragraphs, documents...)
<strong>Options for doing text annotation</strong>:</p>
<ul>
<li>Manual - Reliess on humnans; Because of that fact this approachss doesn't scale, is costly, and error prone.</li>
<li>Automatic - The current trend due to the increasingly amount of text examples required for many applications in the
industry.
<ul>
<li>Rule-based methods
<ul>
<li>Use a set of predefined rules</li>
<li>Require domain knowledge from experts</li>
</ul>
</li>
<li>ML-driven methods
<ul>
<li>Use a set of prelabeled examples to train models.</li>
<li>Learn -during a training phase- based on observations of data contrasted against the true/gold labels already
tagged by domain experts for a certain number of the so-called train examples.</li>
<li>The final model obtained with this method has learned associations between the text and the labels</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>We will focus on this approach only, and mainly on the ML-driven methods.</p>
<p><strong>Applications</strong>:</p>
<ol>
<li>Sentiment analysis</li>
<li>News classification</li>
<li>Content moderation</li>
<li>Spam filtering</li>
<li>Question-answering</li>
<li>Natural language inference
...</li>
</ol>
<h3><a class="header" href="#procedure" id="procedure">Procedure</a></h3>
<p>The traditional way of doing text classification consists of these steps:</p>
<ol start="0">
<li><strong>Dataset creation</strong> - Create (or download, if a well-know industry used dataset is considered to be used) at least
two datasets from the text examples available: train and test. See <a href="datasets.html">Datasets</a> section for more information.</li>
<li><strong>Preprocessing</strong> - Some handcrafted <a href="vocabulary.html#feature">features</a> are [extracted](vocabulary.md#feature
-engineering) from the train and test datasets. This may require also to do some transformations on the raw input data.</li>
<li><strong>Training</strong> - From each train example, use the features extracted + its associated label, as input to train a model
that will
learn associations from the features and the labels to make predictions on new input features.</li>
<li><strong>Testing</strong> - Feed a model with the features extracted from each test example to the train model to obtain a
prediction.</li>
<li><strong>Evaluation</strong> - Take each prediction obtained and contrast it with the corresponding true/gold label for test
examples and calculate the required <a href="metrics.html">metrics</a> for the classification problem at hand.</li>
</ol>
<p>Popular Algorithms used for text classification are <a href="algorithms_and_model_architectures.html#naive-bayes">Naive Bayes</a>,
<a href="algorithms_and_model_architectures.html#support-vector-machines">SVMs</a>, <a href="algorithms_and_model_architectures.html#hidden-markov-models">HMMs</a>,
<a href="algorithms_and_model_architectures.html#gradient-boosting-trees">GBTs</a> and <a href="algorithms_and_model_architectures.html#random-forests">random forests
</a></p>
<h2><a class="header" href="#entity-recognition" id="entity-recognition">Entity Recognition</a></h2>
<h2><a class="header" href="#question-answering" id="question-answering">Question-Answering</a></h2>
<h1><a class="header" href="#nlp-architectures" id="nlp-architectures">NLP Architectures</a></h1>
<h2><a class="header" href="#recent-origins" id="recent-origins">Recent Origins</a></h2>
<p>These papers influenced a paradigm shift towards what will be called <a href="vocabulary.html#deep-learning">Deep Learning</a>, which will imply the massive adoption of neural networks for ML tasks.</p>
<h3><a class="header" href="#word2vec" id="word2vec">Word2Vec</a></h3>
<p>&quot;Efficient Estimation of Word Representations in Vector Space&quot; {{ cite mikolov_efficient_2013 }} or simply the
Word2Vec paper by Mikolov et al. at Google marked a paradigm shift in NLP, as it showed the potential of an embedding
model trained in large amounts of data (1.6 Billion data words). In particular, they showed the quality of the 
representations obtained after training by using a word similarity task.
A deeper explanation can be found in &quot;word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding
method&quot; {{ cite goldbert_word2vec_2014 }}</p>
<p><a href="https://github.com/tmikolov/word2vec">Source code</a></p>
<h1><a class="header" href="#" id=""></a></h1>
<h3><a class="header" href="#elmo" id="elmo">Elmo</a></h3>
<p>&quot;Deep contextualized word representations&quot; {{ cite peters_deep_2018 }} a.k.a. the &quot;Elmo&quot; paper, improved the results
obtaineed by Word2Vec. The main differencde is that Elmo adds context to word representations. Word vectors are
learned functions of the internal states of a deep bidirectional language model (biLM), pre-trained also on a large
text corpus. This marked the start of the &quot;Sesame Street Saga&quot;</p>
<h2><a class="header" href="#attention" id="attention">Attention</a></h2>
<p>This was a game changer paper when it appeared in 2017 {{ cite vaswani_attention_2017 }}.
The concept of attention is taken, as many others, from cognitive sciences (e.g. psycology, neuroscience, education.) It 
describes the process of focusing on certain concrete stimulus/stimuli while ignoring the rest of stimuli in an 
environment. In the case of NLP for example, the context/environment can be a sentence and the stimulus a word.</p>
<ul>
<li><a href="">Attention and Memory-Augmented Networks for Dual-View Sequential Learning (KDD 2020)</a></li>
</ul>
<h4><a class="header" href="#sparse-transformers" id="sparse-transformers">Sparse Transformers</a></h4>
<ul>
<li><a href="refs.html#sparse">Sparse Tansformer</a> Self-attention complexity from O(n2) to O(n*sqrt(n)).</li>
<li><a href="refs.html#reformer">Reformer</a> Self-attention complexity O(L2) to O(LlogL), where L is the length of the sequence.</li>
<li><a href="refs.html#linformer">Linformer</a> Self-attention complexity from O(n2) to O(n) in both time and space.</li>
</ul>
<h2><a class="header" href="#transformers" id="transformers">Transformers</a></h2>
<h3><a class="header" href="#sesame-street-saga" id="sesame-street-saga">Sesame Street Saga</a></h3>
<p>The <a href="nlp.html#elmo">ELMO</a> paper started a trend to name many NLP model architectures and variations after the characters of
Sesame Street/Muppets. Some refer to this fenomenon as <a href="https://www.theverge.com/2019/12/11/20993407/ai-language-models-muppets-sesame-street-muppetware-elmo-bert-ernie">&quot;Muppetware&quot;</a>
These are the most relevant ones.</p>
<p>TODO mention at least <del>ELMo,</del> BERT, Grover, Big BIRD, Rosita, RoBERTa, ERNIEs, and KERMIT. </p>
<h4><a class="header" href="#bert" id="bert">BERT</a></h4>
<p>By 2018 Google developed what is still as of 2021, the SotA of embedding-based models for the majority of the industry.
Based on the Transformer architecture, it was trained on 3.3 billion words. Comming in two different flavours, base
and large, they mainly differ on the number of parameters.</p>
<ul>
<li><a href="https://arxiv.org/abs/1810.04805">BERT</a> The reference model for NLP since 2018.</li>
<li><a href="https://arxiv.org/pdf/1907.10529.pdf">SpanBERT</a>
Masks spans of words instead of random subwords. Spans of words refers to global entities or loca/domain-specific meaning (e.g. American Football)
Span Boundary Objective(SBO) predicts the span context from boundary token representations. Uses single sentence document-level inputs instead of
the two sentences in BERT.
Code: https://github.com/facebookresearch/SpanBERT</li>
<li><a href="https://arxiv.org/abs/1907.11692">RoBERTa</a>
Replication study of BERT pretraining that measures the impact of many key hyperparameters (Bigger Batch size and LR) and training data size (10X).
It shows improvements on most of the SotA results by BERT and followers. Questions the results of some post-BERT models.
It uses a single sentence for the document-level input like SpanBERT.
Code: https://github.com/pytorch/fairseq</li>
</ul>
<h4><a class="header" href="#small-modelssmall-devices" id="small-modelssmall-devices">Small Models/Small Devices</a></h4>
<ul>
<li><a href="refs.html#lite">Lite transformer with Long-Short Range Attention</a>
Uses Long-Short Range Attention (LSRA) in which a group of heads specializes in
the local context (using convolution) and another group specializes in the
long-distance relationships (ussing the attention mechanism.) Focus on edge (mobile) devices.</li>
</ul>
<details>
  <summary>Small Models</summary>
 * [Distilbert](https://arxiv.org/abs/1910.01108)
 Check it out in https://huggingface.co/
</details>
<details>
  <summary>Other Sesame Street Papers</summary>
<ul>
<li><a href="https://arxiv.org/abs/1908.10063">FinBERT</a> Bert applied to Financial Sentiment Analysis.
Code: https://github.com/ProsusAI/finBERT]</li>
<li><a href="refs.html#abcd">FinBERT</a></li>
</ul>
</details>
<h3><a class="header" href="#non-sesame-street-environment" id="non-sesame-street-environment">Non-Sesame Street Environment</a></h3>
<p>** <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/">Turing NLG</a>
&quot;Turing Natural Language Generation (T-NLG) is a 17 billion parameter language model by Microsoft that outperforms the state of the art on many downstream NLP
tasks. We present a demo of the model, including its freeform generation, question answering, and summarization capabilities, to academics for feedback and
research purposes. &lt;|endoftext|&gt;&quot; - Summary generated by itself.</p>
<h3><a class="header" href="#lifelong-learning-in-nlp" id="lifelong-learning-in-nlp">Lifelong learning in NLP</a></h3>
<ul>
<li><a name="biesialska"><a href="https://www.aclweb.org/anthology/2020.coling-main.574.pdf">Continual Lifelong Learning in Natural Language Processing: A Survey</a> Colling, 2020</a></li>
</ul>
<h2><a class="header" href="#text-generation" id="text-generation">Text Generation</a></h2>
<p>Data-to-Text Generation (DTG) or simpy, text generation is a subfield of NLP which pursues the automatic generation of
human-readable text using computational linguistics and AI.</p>
<p>Approaches to text generation use a <a href="vocabulary.html#language-model">language model (LM)</a> to generate the probability
distribution from we can sample to generate the next token in a sentence.</p>
<p>In the last few years, one of the most used generative models is the so-called Recurrent Neural Networks (RNN) that
have been used successfully also for other NLP task such as classification. </p>
<p>However, LMs per-se, despite promising for text generation, are limited in the control terms that humans
have for &quot;influencing&quot; the generated content. The problem relies on the fact that, once the models are trained
, it becomes difficult add control attributes without modifying the architecture to allow extra input
attributes or tuning with extra data. The prompts written by humans or generated automatically act just a starting
cue for the generator, but does not allow to control other properties such as define the topic of the generated
text.</p>
<p>Without these control attributes, models tend to <a href="vocabulary.html#hallucination">&quot;hallucinate&quot;</a>.
More recent approaches to text generation include these control mechanism: CTRL {{ cite shirish_ctrl_2019 }} and PPLM
{{ dathathri_plug_2020 }}.</p>
<p><a href="https://github.com/salesforce/ctrl">Conditional Transformer Language (CTRL)</a> introduces control codes to condition the
language model. These control
codes govern
the style, content, and task-specific
behavior of the generated text. More specifically, the control codes allow 1) preserve the advantages of unsupervise
learning; 2) seamless
integration in the structure of the raw while providing the required control over generation, and 3) predict which
parts  of the training data are most likely given a sequence.</p>
<p>CTRL is trained on control codes that co-occur narurally with the original text typically used for training LMs.
Big datasets such Wikipedia are assigned with a domain-related control code; other smaller datasets (e.g. content from
specific online communities in Reddit are assigned to a broader domain name (Reddit) and with subdomain information
(e.g. r/politics.) All control codes can be traced to a particular subset of the training data.
Moreover, the codes can be combined with codes during generation to cross-over task-specific and domain/content
behaviors.</p>
<p>As CTRL, Plug and Play Language Model (PPLM) combines a pretrained LM with n &quot;attribute classifiers&quot; which allow to
drive the text generation process externally without architectural changes. This work was influenced by the
Plug &amp; Play Generative Networks (PPGN) work in computer vision (2017). In PPGN a discriminator (attribute model)
[ p(a|x) ] is plugged with a generative model p(x), so that sampling from the resulting [ p(x|a) \propto p(a|x
)p(x) ], effectively creates a generative model conditioned from the provided attribute a.
As the attribute is plugged post facto in the activation space, no further fine-tuning is required.</p>
<p>Another recent work is {{ cite rebuffel_controlling_2021 }}, based on RNNs. This work addresses hallucination by
treating it at a
word level, which is a more fine-grained approach than other works, which deal with hallucination at the instance
level. It proposes a procedure that consist of: 1) a word-level labeling procedure built on dependency parsing and
based on co-ocurrences and sentence structure; 2) a weighted multi-branch decoder which, guided by the alignment
labels from the previous step, will used them as word-level control factors. At a training time, the decoder
will learn generating descriptions without being misled by un-factual reference information. This is due to
the fact that the model will be able to distinguish between aligned and unaligned words.  </p>
<h1><a class="header" href="#productionizing-mldl" id="productionizing-mldl">Productionizing ML/DL</a></h1>
<p>The software infrastructure stack that is required for ML projects in general, is quite different from the current stack
of non-ML projects. <a href="people.html#Andrej-Karpathy">Andrej Karpathy</a></p>
<p><a href="http://pages.cs.wisc.edu/%7Ewentaowu/papers/kdd20-ci-for-ml.pdf">Multimodal Learning with Incomplete Modalities by Knowledge Distillation (KDD 2020)</a>
Interesting</p>
<h2><a class="header" href="#challenges-in-putting-a-ml-model-into-production" id="challenges-in-putting-a-ml-model-into-production">Challenges in Putting a ML Model into Production</a></h2>
<ul>
<li><strong>Infrastructure and Tooling</strong>: As of 2021, current tools and platforms, mainly CI/CD do not have great support for data and/or
ML specific computing resources (e.g. GPUs/TPUs) which causes problems when trying to integrate the tasks and necessary
steps that conform a modern ML pipeline for any use case at hand.</li>
<li><strong>Culture and Organizational Structure</strong>: Companies should reorganize their divisions to accommodate this new way of producing
software systems based on a ML model. The standard model for software development does not fit here. But that doesn't mean
that data scientists should not adopt norms, techniques and tools from the traditional software development (such as 
testing) and adapt them to their needs.</li>
<li><strong>Decision Making</strong>: How to decide that a model is &quot;good enough&quot;? Check <a href="topics.html#Model_Interpretability">Interpretability</a> </li>
</ul>
<h1><a class="header" href="#data" id="data">Data</a></h1>
<h2><a class="header" href="#data-management-at-scale" id="data-management-at-scale">Data Management At Scale</a></h2>
<p>Data management is one of the new problems many companies in the industry are facing. Usually managed by individual teams
in isolation and with very different policies in terms of versioning, privacy and accesibility and location, with the
increasing sources of data, this has become a problem in modern companies.</p>
<p>In the past, solutions like Data Warehouses -built out of multiple of ETL processes- or its evolution, the Data Lake where the norm. 
The trend in 2021 is to evolve the Data Lake view towards the so-called <a href="https://martinfowler.com/articles/data-monolith-to-mesh.html">Data Mesh</a> are the tendency.
The idea is to scale up the </p>
<h2><a class="header" href="#datasets" id="datasets">Datasets</a></h2>
<p>It's well know that the main datasets involved in any ML process for creating a model are:</p>
<ul>
<li><strong>Train</strong>, which is the data your model will train on</li>
<li><strong>Dev</strong>, which is a representation of the test dataset used to do hyperparameter tuning, select features or make any other
decision over the model. In scikit-learn use to be called <strong>hold-out cross-validation set</strong>. </li>
<li><strong>Test</strong>, which is used exclusively for evaluating the metrics selected for the model. It should not be used to make any other
decision about the process of developing the final model.</li>
</ul>
<p>However there's more things to take into account, mainly: </p>
<ul>
<li>Main test set should mirror your online distribution</li>
<li>It's possible to collect alternative datasets
<ul>
<li>They don't have to come from the real distribution but will be useful to evaluate the model selected</li>
<li>When is this useful?
<ul>
<li>when there are certain edge cases that we need to actuate on</li>
<li>when the model has to run on multiple datasets with different modalities (e.g. English and Spanish datasets, wild and pet animals datasets)</li>
</ul>
</li>
</ul>
</li>
<li>Compare new model against:</li>
<li>
<ol>
<li>the previous model and </li>
</ol>
</li>
<li>
<ol start="2">
<li>a fixed older model (baseline)</li>
</ol>
</li>
<li>
<ol start="3">
<li>against the possible slices interesting for the business model</li>
</ol>
</li>
<li>
<ol start="4">
<li>against the alternative datasets</li>
</ol>
</li>
</ul>
<p>More information about dataset creation and quality can be found in the online book by Andrew Ng, <a href="https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf">Machine Learning Yearning</a></p>
<h2><a class="header" href="#versioning" id="versioning">Versioning</a></h2>
<p>One of the main problems that I found when I started working in the ML field 3 years ago was that there was almost no 
control of what data was used in some of experiments we were doing; the vast majority 
(if not all) of my colleagues were not using versioned data; they were just relying on the knowledge transmitted by the
old members of the team. As an outsider at that time coming from other computer science
disciplines and being more aware of software engineering techniques, that shocked me because I knew that working in a
context like that was to bring two well-known major pains for me:</p>
<ul>
<li>Back to old same problems back in the days for not having regular versioned code</li>
<li>Frustration when trying to communicate and explain that data versioning was helpful and we had to implement a policy
and use tools for keep track of the evolution of the data in our datasets </li>
</ul>
<p>But there's more when you introduce data versioning in your scope. Almost immediately it comes up to your mind that you
also have to keep track of the data-code version pairs to be able to reproduce exactly your experiments.</p>
<p>The next step is of course, find tools about version control for data. You can think immediately on Git/Github and similar
tools (Bitbucket, Gitlab, etc..) Sooner that later that those existing solutions might work for projects with
small datasets, but scalability is gonna become a problem (e.g. you can't store in git files bigger than a certain size).
Also because when building a dataset, you need certain flexibility
to manage the deltas you are adding; if you add data incrementally at some point you may create biases (e.g. by 
adding at some point many examples of a particular category in data for a classifier). It would be nice to use a tool that 
despite recognizing you added data to a dataset incrementally, it would allow you certain flexibility when building the datasets
for training/testing based on the deltas added (e.g. by skipping certain delta increments, combining only the base datasets
and two specific deltas, etc). This kind of tools that allow user to create versioned datasets and then aggregate them
by following a workflow-based data combination approach is what it would be nice to have to manage data used in ML model/experiments.</p>
<p>In Lecture 8, Slide 76 of the [Full Stack DL of 2021] there a summary of the approaches that currently are followed by the practitioners:</p>
<ul>
<li>Level 0 - No data versioning. Unfortunately, the most common approach.</li>
<li>Level 1 - Snapshot at training time. The next level if you are a little bit more careful when developing a new model.</li>
<li>Level 2 - Data is versioned as mix of assets and code. I pushed hard to follow this approach at least when I implemented my first ML training pipeline a couple of years ago.</li>
<li>Level 3 - New tools for integrated data versioning. An active space for developing new tools.</li>
</ul>
<h3><a class="header" href="#tools" id="tools">Tools</a></h3>
<ul>
<li></li>
<li><a href="https://dvc.org/">dvc Data Version Control</a></li>
</ul>
<h1><a class="header" href="#machine-learning-platforms-and-pipelines" id="machine-learning-platforms-and-pipelines">Machine Learning Platforms and Pipelines</a></h1>
<p>At some point, the main leaders in the software development industry decided to show off their ML platforms. Here there
are some of them.</p>
<h2><a class="header" href="#architectural-examples" id="architectural-examples">Architectural Examples</a></h2>
<ul>
<li><a href="https://eng.uber.com/michelangelo-machine-learning-platform/">Michelangelo (Uber)</a> - Uber's machine learning platform. Here, 
<a href="https://eng.uber.com/scaling-michelangelo/">there's another blogpost</a> with more details.</li>
<li><a href="https://www.youtube.com/watch?v=XV5VGddmP24">Metaflow (Netflix)</a> - They don't offer much details about the data-related
tasks (e.g. data-lake, versioning, preprocessing, etc.) available in the platform. Post about <a href="https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9">moving Metaflow to an open-source effort</a></li>
<li><a href="https://engineering.linkedin.com/blog/2019/01/scaling-machine-learning-productivity-at-linkedin">Pro-ML (Linkedin)</a> - Also
they don't provide much detail about the data part, which present as a silo on the left part of their architectural diagram,
and called Feature Marketplace.</li>
</ul>
<h2><a class="header" href="#regular-sw-vs-machine-learning-sw" id="regular-sw-vs-machine-learning-sw">Regular SW vs Machine Learning SW</a></h2>
<table><thead><tr><th>Traditional SW</th><th>Machine Learning</th></tr></thead><tbody>
<tr><td>Code + Config Data</td><td>Code + Data + Workflow + Config Data</td></tr>
<tr><td>Written by humans to be validated essentially by humans</td><td>Specified by humans, optimized by compilers to satisfy a proxy metric</td></tr>
<tr><td>Bugs &amp; Failures are perceived almost instantly by humans</td><td>Failures can be silent and system degradation can be imperceptible</td></tr>
<tr><td>Change according to versions</td><td>Change is almost a constant in this systems</td></tr>
</tbody></table>
<h2><a class="header" href="#errors-when-testing-ml-as-regular-sw" id="errors-when-testing-ml-as-regular-sw">Errors when Testing ML as Regular SW</a></h2>
<ol>
<li>Not analyzing sufficiently how the performance of the model is gonna be quantified and measured (metrics) and its
relation to the context where it's gonna be applied (business part)</li>
<li>Test only the model and not the system as a whole (as a consequence of 1.)</li>
<li>Missing data testing (also as a consequence of 1.)</li>
<li>Rely too much in automated testing and not in production testing</li>
<li>Lose sight of the possible divergence of the business measures against the model metrics observed (also as a consequence of 1. and 4.) </li>
</ol>
<h2><a class="header" href="#meet-the-testing-family-in-ml" id="meet-the-testing-family-in-ml">Meet The Testing Family in ML</a></h2>
<h3><a class="header" href="#label-tests" id="label-tests">Label Tests</a></h3>
<ul>
<li>Focus: Labeling system/editor tools/editors</li>
<li>Goal: Catch poor quality labels or parts of the dataset to avoid model corruption</li>
<li>Techniques:
<ul>
<li>Get trained labelers
<ul>
<li>We all are prone to biases so...</li>
</ul>
</li>
<li>Try to avoid human biases
<ul>
<li>by aggregating labels from multiple labelers</li>
</ul>
</li>
<li>Assign labelers a trust score based on how often they are wrong</li>
<li>Identify examples in training/testing processes which get different judgement from humans vs computers
<ul>
<li>Relabel those examples again and check if it's true that there were inconsistencies/errors in human and computer judgements</li>
</ul>
</li>
<li>Compare older models on new labels</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#data-tests" id="data-tests">Data Tests</a></h3>
<ul>
<li>a.k.a. Expectation Tests</li>
<li>Focus: Storage and Preprocessing Task</li>
<li>Goal: Catch bad data or data with quality issues before going to the train pipeline</li>
<li>Techniques:
<ul>
<li>Define expectations:
<ul>
<li>Assertions for data or</li>
<li>rules about properties of each of your data tables at each stage in your data cleaning/preprocessing pipeline</li>
<li>e.g. we should expect that Column X in Table A after preprocessing does not contain any null values</li>
<li>e.g. we should expect that the average value of Column Y in Table B after preprocessing should be between v1 and v2 </li>
</ul>
</li>
</ul>
</li>
<li>Tools:
<ul>
<li><a href="https://greatexpecations.io">Great Expectations</a></li>
</ul>
</li>
</ul>
<h3><a class="header" href="#infrastructure-test-aka-unit-tests-in-regular-sw-development" id="infrastructure-test-aka-unit-tests-in-regular-sw-development">Infrastructure Test (aka Unit tests in Regular SW development)</a></h3>
<ul>
<li>Focus: Training Task</li>
<li>Goal: Avoid bugs</li>
<li>Techniques:
<ul>
<li>Use unit test for the parts that are similar to regular sofware (e.g. data preparation and cleaning)</li>
<li>Extract a small sample of the dataset to test quickly over it</li>
<li>Add tests of a single epoch with the previous extracted small dataset</li>
<li>Run frequently</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#training-tests" id="training-tests">Training Tests</a></h3>
<ul>
<li>Focus: Storage and preprocessing Tasks and Training Task</li>
<li>Goal: Ensure reproducibility of training</li>
<li>Techniques:</li>
<li>Define a set of baseline metrics</li>
<li>Pull a fixed dataset representative of the full dataset</li>
<li>Check model performance remains consistent against the baseline metrics</li>
<li>Consider pulling a sliding window of data</li>
<li>As they're slow, run periodically (night or any other specific times)</li>
</ul>
<h3><a class="header" href="#functionality-tests" id="functionality-tests">Functionality Tests</a></h3>
<ul>
<li>Focus: Prediction Task</li>
<li>Goal: Avoid regressions in the code that makes up your prediction infrastructure</li>
<li>Techniques:
<ul>
<li>Unit test for the prediction code as for traditional software</li>
<li>Load model and test particular examples</li>
<li>Run frequently</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#evaluation-tests" id="evaluation-tests">Evaluation Tests</a></h3>
<ul>
<li>
<p>Focus: Training Task and Production Task</p>
</li>
<li>
<p>Goal: Validate the model to go into production by testing the integration of the two tasks above</p>
</li>
<li>
<p>Techniques:</p>
<ul>
<li>Evaluate model in all the important datasets, metrics and slices
<ul>
<li>Traditional metrics (Accuracy, Precision, Recall, etc.) </li>
<li><a href="https://github.com/francisco-perez-sorrosal/deep-learning-papers/tree/master/Beyond%20Accuracy">Behavioral Tests</a></li>
<li>Robustness Metrics
<ul>
<li>Related to <a href="productionizing.html#Errors_when_Testing_ML_as_Regular_SW">Step 5 here</a></li>
<li>I think is very important to asses the overall quality of the model and decide when it's time to react</li>
<li>Extract data to understand where the model is gonna perform well or bad</li>
<li>Study the feature importance</li>
<li>Densitivity to data staleness (vs old data)...</li>
<li>...and data drifts (training vs prod data or different prod data distributions)
<ul>
<li>Important to define metrics for particular data categories (e.g. metrics for the &quot;news&quot; category)</li>
</ul>
</li>
</ul>
</li>
<li>Privacy and fairness
<ul>
<li>Will become more important from now on</li>
</ul>
</li>
<li>Simulation tests
<ul>
<li>Understand the interaction of your model with the rest of the environment (&quot;the world&quot;)</li>
<li>Used in Robotics/Automated Vehicles</li>
<li>Hard to model &quot;the world&quot;</li>
</ul>
</li>
<li>Shadow tests
<ul>
<li>Testing in production and compare with the results in the offline</li>
<li>Detect issues in production</li>
<li>Apply the <a href="">strangler fig pattern</a> to not impact users</li>
</ul>
</li>
</ul>
</li>
<li>Compare model against previous one and the baselines</li>
<li>This is done only at a particular point in time; so run these tests when you've selected a candidate
model from the training phase and you want to put it in production.</li>
</ul>
</li>
<li>
<p>Tools: </p>
<ul>
<li>Robustness: 
<ul>
<li><a href="https://pair-code.github.io/what-if-tool/">what-if-tool</a> </li>
<li><a href="https://research.google/pubs/pub47966/">Slice Finder</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#ab-tests" id="ab-tests">A/B Tests</a></h3>
<ul>
<li>Focus: Serving System</li>
<li>Goal: Check how the users react to the new model and how the business metrics are affected</li>
<li>Techniques:
<ul>
<li>Separate a fraction of the request and redirect it to the new model. The rest of the request will
still targeting the old model which will serve as a control</li>
<li>Compare the two cohorts</li>
<li>Use monitoring as a tool for evaluation!!!</li>
<li><a href="https://levelup.gitconnected.com/the-engineering-problem-of-a-b-testing-ac1adfd492a8">A/B Testing blog</a></li>
</ul>
</li>
</ul>
<h2><a class="header" href="#model-size-vs-efficiency" id="model-size-vs-efficiency">Model Size vs Efficiency</a></h2>
<p>Big models -&gt; Big problem for company at deploy time. Not to speak about deploying an ensemble of models, even if this
shows better performance overall. Several techniques, such as knowledge distillation, pruning and quantization, have 
been identified to reduce the number of parameters of a model without impacting significantly the quality of the model. 
In the end, most of the techniques described below, result in slightly degraded prediction metrics.</p>
<ul>
<li><a href="https://blog.roblox.com/2020/05/scaled-bert-serve-1-billion-daily-requests-cpus/">How We Scaled Bert To Serve 1+ Billion Daily Requests on CPUs (Roblox)</a></li>
</ul>
<h3><a class="header" href="#distilation" id="distilation">Distilation</a></h3>
<p>Hinton, Vinyals and Dean showed in [<a href="bibliography.html#hinton_distilling_2015">hinton_distilling_2015</a>] how to apply Caruana's model compression techniques described in [<a href="bibliography.html#bucilua_model_2006">bucilua_model_2006</a>].
Caruana et all showed how to take advantage of the property of ANN of being <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">universal approximators</a>,
to train an ANN to mimic the function learned by an ensemble of models. The idea behind the universal approximator theorem
is that, with enough neurons and training data, a NN can approximate any function with enough precision. To do that,
basically they take a brand new (and usually big) <em>unlabeled</em> dataset and they label it using the ensemble. Then they
train an ANN using this brand new large (and recently labeled dataset,) so the resulting model mimics the ensemble, and
which, as they demonstrate, performs much better than the same ANN trained on the original dataset. </p>
<p>Hinton et all, in the aforementioned paper, prove Caruana's ensemble model distillation on MNIST and in a commercial
acoustic model. They also add a new composite ensemble with several specialist models (which can also be trained in 
parallel) that learn to distinguish classes that the full models confuse.</p>
<h3><a class="header" href="#pruning" id="pruning">Pruning</a></h3>
<h3><a class="header" href="#quantization" id="quantization">Quantization</a></h3>
<ul>
<li>Focused on inference</li>
<li>Focused on small devices/IoT</li>
</ul>
<p>Papers:</p>
<ul>
<li><a href="https://arxiv.org/abs/1910.06188">Q8BERT: Quantized 8Bit BERT (2019</a></li>
<li><a href="https://pytorch.org/tutorials/intermediate/dynamic_quantization_bert_tutorial.html">DYNAMIC QUANTIZATION ON BERT (BETA)</a></li>
</ul>
<p>It turns out that quantization is now now possible in ONNX models:</p>
<pre><code class="language-python">import onnx
from quantize import quantize, QuantizationMode
...
# Load onnx model
onnx_model = onnx.load('XXX_path')
# Quantize following a specific mode from https://github.com/microsoft/onnxruntime/tree/e26e11b9f7f7b1d153d9ce2ac160cffb241e4ded/onnxruntime/python/tools/quantization#examples-of-various-quantization-modes
q_onnx_model = quantize(onnx_model, quantization_mode=XXXXX)
# Save the quantized model
onnx.save(q_onnx_model, 'XXXX_path')
</code></pre>
<p><a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#work-with-qat-networks">Tensor RT supports the quantized models so, it should work</a></p>
<ul>
<li><a href="https://github.com/microsoft/DeepSpeed">Deep Speed (Microsoft)</a> ZeRO redundancy memory optimizer: Addresses the problems with high memory consumption of 
large models with pure data parallelism and the problem of using model parallelism.</li>
<li><a href="https://www.youtube.com/watch?v=n4bESjZ-VaY&amp;feature=youtu.be">Training BERT with Deep Speed</a></li>
<li><a href="https://pytorch.org/elastic">Torch Elastic</a></li>
<li><a href="https://pytorch.org/docs/stable/rpc.html">PyTorch RPC</a></li>
<li><a href="https://pytorch.org/serve">PyTorch Serve</a></li>
</ul>
<h1><a class="header" href="#tools-and-frameworks-for-ml" id="tools-and-frameworks-for-ml">Tools and Frameworks for ML</a></h1>
<ul>
<li><a href="">Scikit-learn</a></li>
<li><a href="">JAX</a></li>
<li><a href="">Caffe2</a></li>
</ul>
<h2><a class="header" href="#deep-learning" id="deep-learning">Deep Learning</a></h2>
<ul>
<li><a href="https://pytorch.org/">Pytorch</a>
Recent trend in Research Community. Improving a lot to get into production.</li>
<li><a href="https://www.tensorflow.org/">Tensorflow/Keras</a>
Google's big hit in 2015.</li>
<li><a href="https://mxnet.apache.org/versions/1.6/">MxNet</a> Apache</li>
</ul>
<h2><a class="header" href="#nlp-1" id="nlp-1">NLP</a></h2>
<ul>
<li><a href="https://huggingface.co/">Huggingface</a></li>
<li><a href="https://github.com/NervanaSystems/nlp-architect">NLP Architect</a></li>
<li><a href="https://github.com/dmlc/gluon-nlp">GluonNlp</a></li>
</ul>
<h2><a class="header" href="#distributed-environments" id="distributed-environments">Distributed Environments</a></h2>
<ul>
<li><a href="https://github.com/horovod/horovod">Horovod</a></li>
<li><a href="https://github.com/microsoft/DeepSpeed">DeepSpeed</a></li>
</ul>
<h1><a class="header" href="#d" id="d">D</a></h1>
<h2><a class="header" href="#datasets-1" id="datasets-1">Datasets</a></h2>
<ul>
<li><a href="https://huggingface.co/datasets">Huggingface Datasets</a></li>
</ul>
<h1><a class="header" href="#web-resources" id="web-resources">Web Resources</a></h1>
<ul>
<li><a href="https://wiki.pathmind.com/">AI &amp; DL Wiki</a> Wiki from Pathmind, a deep reinforcement learning company focused on improving efficiency, throughput and cost of operations and chains.</li>
<li><a href="https://thegradient.pub/">The Gradient</a> Magazine about research, recent developments and current/long-term trends in 
AI/ML. Origin: 2017 by students and researchers @ Stanford Artificial Intelligence Laboratory (SAIL).
Status: non-profit and volunteers in the AI community.</li>
<li><a href="https://learn.xnextcon.com/">AI Camp Webminars</a></li>
</ul>
<h1><a class="header" href="#books" id="books">Books</a></h1>
<ul>
<li><a href="https://www.deeplearningbook.org/">Deep Learning (Online version)</a> <em>Ian Goodfellow and Yoshua Bengio and Aaron Courville</em> [<a href="bibliography.html#goodfellow_deep_2016">goodfellow_deep_2016</a>] </li>
<li><a href="http://d2l.ai/">Dive into Deep Learning</a> Interactive book</li>
</ul>
<h2><a class="header" href="#general-overview" id="general-overview">General Overview</a></h2>
<ul>
<li>Genius Makers: The Mavericks Who Brought AI to Google, Facebook, and the World [<a href="bibliography.html#metz_genius_2021">metz_genius_2021</a>]</li>
<li>The Deep Learning Revolution [<a href="bibliography.html#sejnowski_deep_2018">sejnowski_deep_2018</a>]</li>
<li>A Brief History of Artificial Intelligence: What It Is, Where We Are, and Where We Are Going [<a href="bibliography.html#wooldridge_brief_2021">wooldridge_brief_2021</a>]</li>
</ul>
<h1><a class="header" href="#research-centerscommunities" id="research-centerscommunities">Research Centers/Communities</a></h1>
<ul>
<li><a href="https://mila.quebec/en/">Mila</a> A community of researchers specializing in ML and dedicated to scientific excellence 
and innovation.</li>
<li><a href="https://www.salk.edu/">Salk Institute</a> A well-known institute researching the foundations of life, seeking new
understandings in neuroscience, genetics, immunology, plant biology and more.</li>
</ul>
<h1><a class="header" href="#opinion" id="opinion">Opinion</a></h1>
<ul>
<li><a href="https://marksaroufim.substack.com/p/machine-learning-the-great-stagnation">Machine Learning: The Great Stagnation</a> Defines the current (early 2021) situation of DS/ML roles in industry, at least in US.
<ul>
<li><a href="https://learn.xnextcon.com/event/eventdetails/W2021031810">Video</a></li>
</ul>
</li>
<li><a href="https://www.edge.org">Edge Org</a> - A website with (speculative) ideas from scientists and thinkers that pretend to draw
and go beyond the current frontiers of knowledge in evolutionary biology, genetics, computer science, neurophysiology, psychology, and physics. </li>
</ul>
<h1><a class="header" href="#my-summary-of-papers" id="my-summary-of-papers">My Summary of Papers</a></h1>
<ul>
<li><a href="https://github.com/francisco-perez-sorrosal/deep-learning-papers/tree/master/Beyond%20Accuracy">Beyond Accuracy: Behavioral Testing of NLP models with CheckList</a> [<a href="bibliography.html#ribeiro_beyond_2020">ribeiro_beyond_2020</a>] </li>
<li><a href="https://github.com/francisco-perez-sorrosal/deep-learning-papers/tree/master/Generative%20Replay">Brain-inspired Replay for Continual Learning with Artiﬁcial Neural Networks</a> [<a href="bibliography.html#van_de_ven_brain-inspired_2020">van_de_ven_brain-inspired_2020</a>]</li>
<li><a href="https://github.com/francisco-perez-sorrosal/deep-learning-papers/tree/master/Generative%20Replay">Generative Replay with Feedback Connections as a General Strategy for Continual Learning</a> [<a href="bibliography.html#van_de_ven_generative_2019">van_de_ven_generative_2019</a>]</li>
<li><a href="(https://github.com/francisco-perez-sorrosal/deep-learning-papers/tree/master/Generative%20Replay)">Three scenarios for continual learning</a> [<a href="bibliography.html#van_de_ven_three_2019">van_de_ven_three_2019</a>]</li>
<li><a href="https://github.com/francisco-perez-sorrosal/deep-learning-papers/tree/master/What%20Does%20BERT%20Look%20At">What Does BERT Look At? An Analysis of BERT’s Attention</a> {{ cite clark_what_2019 }}</li>
</ul>
<h1><a class="header" href="#milestones" id="milestones">Milestones</a></h1>
<ul>
<li>
<p>1966</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Automatic_Language_Processing_Advisory_Committee">ALPAC</a> report is published, which causes the abandon of the efforts in machine translation by the National 
Research Council at that period (cold ward) </li>
</ul>
</li>
<li>
<p>1969</p>
<ul>
<li>Original publication of Perceptrons by S. Papert and M. Minsky {{ cite }}. This book is marked by some
experts (e.g. T. Sejnowsky {{ cite sejnowski_deep_2018 }}) as one of the causes to the dawn of the connectionist paradigm in the field of AI.</li>
</ul>
</li>
<li>
<p>circa 1974 1st AI Winter</p>
</li>
<li>
<p>circa 1984 2nd AI Winter</p>
</li>
<li>
<p>1986 </p>
<ul>
<li><a href="http://www.lecun.org/gallery/libpro/19860701-cmu/index.html">Connectionist Summer School at CMU</a></li>
</ul>
</li>
<li>
<p>1987</p>
<ul>
<li>G. Hinton moves to Toronto University</li>
<li>First NIPS Conference</li>
</ul>
</li>
<li>
<p>2003</p>
<ul>
<li>Y. LeCunn moves to NYU</li>
</ul>
</li>
<li>
<p>2004</p>
<ul>
<li><a href="https://cifar.ca/ai/canadas-leadership-in-ai/">CIFAR NCAP</a> Program is launched. This can be considered the germ of
the deep learning field. </li>
</ul>
</li>
<li>
<p>2012</p>
<ul>
<li>AlexNet is published by Alex Krizhevsky, Ilya Sutskever and Geoffrey Hinton.</li>
</ul>
</li>
</ul>
<h1><a class="header" href="#main-aimldldata-science-conferences" id="main-aimldldata-science-conferences">Main AI/ML/DL/Data Science Conferences</a></h1>
<ul>
<li><a href="https://nips.cc/">NIPS/Neurips</a></li>
<li><a href="https://www.kdd.org/">KDD (SIGKDD) ACM</a></li>
<li><a href="https://iclr.cc/">ICLR (International Conference on Learning Representations)</a> Dedicated to advances of the
representation learning a.k.a. deep learning.</li>
<li><a href="https://cikm2020.org/">International Conference on Information and Knowledge Management</a></li>
</ul>
<h2><a class="header" href="#nlplinguistics" id="nlplinguistics">NLP/Linguistics</a></h2>
<ul>
<li><a href="https://www.aclweb.org/">ACL (Association of Computational Linguistics)</a></li>
<li><a href="https://2020.emnlp.org/">Conference on Empirical Methods in Natural Language Processing</a></li>
</ul>
<h1><a class="header" href="#andrew-barto" id="andrew-barto">Andrew Barto</a></h1>
<p>Joint with [Richard Sutton](#Richard Sutton), <a href="https://www.cics.umass.edu/news/barto-sutton-co-author-second-edition-ground-breaking-textbook-reinforcement-learning">one of the most influential academics</a> 
behind the recent successes and dissemination of reinforcement learning. <a href="https://www.cics.umass.edu/faculty/directory/barto_andrew">He was at University of Ahmerst</a> 
in Massachusets. Author of the already classic book on RL [<a href="bibliography.html#sutton_reinforcement_2018">sutton_reinforcement_2018</a>]</p>
<h1><a class="header" href="#a-hrefyoshuabengioorgyoshua-bengioa" id="a-hrefyoshuabengioorgyoshua-bengioa"><a href="yoshuabengio.org">Yoshua Bengio</a></a></h1>
<p>Joint with <a href="people.html#geoffrey-hinton">Geoffrey Hinton</a> and <a href="people.html#yann-lecunn">Yann LeCunn</a>, he received the Turing Award in 2018. In
the last decades, he's been one of the leading experts pushing the limits of field of AI contributing forward.</p>
<p>A computer scientist by career, he is a professor at Université de Montréal. <a href="people.html#ian-goofellow">Ian Goodfellow</a> was one
of his students. He's also the Scientific Director of <a href="books_and_resources.html#research-centerscommunities">Mila</a> in Quebec.</p>
<p>He's been also an entrepreneur, although not very successful up to now. <a href="https://en.wikipedia.org/wiki/Element_AI">Element AI</a>
has been up to know his most well-known company.</p>
<h1><a class="header" href="#rodney-brooks" id="rodney-brooks">Rodney Brooks</a></h1>
<p>Father of modern robotics. Strong believer in the <a href="approaches.html#Actionist">actionist approach</a> of ML/AI.
Founder of <a href="https://www.irobot.com/">iRobot</a> and <a href="https://www.rethinkrobotics.com/">Rethink Robotics</a>.</p>
<p><a href="https://dblp.org/pid/b/RodneyABrooks.html">DBLP Papers</a></p>
<h1><a class="header" href="#ian-goofellow" id="ian-goofellow">Ian Goofellow</a></h1>
<p>Generative Adversarial Networks</p>
<h1><a class="header" href="#demis-hassabis" id="demis-hassabis">Demis Hassabis</a></h1>
<p><a href="https://en.wikipedia.org/wiki/Demis_Hassabis">CEO and co-founder</a> of DeepMind.</p>
<h1><a class="header" href="#geoffrey-hinton" id="geoffrey-hinton">Geoffrey Hinton</a></h1>
<p>One of the main people behind the rebirth of NN. Winner of <a href="https://amturing.acm.org/award_winners/hinton_4791679.cfm">Turing Award in 2018</a>
&quot;[f]or conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing.&quot;
Founder of <a href="https://techcrunch.com/2013/06/12/how-googles-acquisition-of-dnnresearch-allowed-it-to-build-its-impressive-google-photo-search-in-6-months/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAEXqPKy-F911hPhusOztjZn7ny0W7-dggrCD7aET0bqXJLH1xkVbsJWPBdtBM-Gpa5TfLM9k6PqR_NvbvLheqpoo4wkVaNKKd8NyGorbUm9S_oVQ-m8OsTFueR0lVO-n5-LrLWs6PAqGW1oyTEjmwAUExSmE_hDey3fyMaLKZeCA">DNN Research</a>,
which was acquired by Google in 2013.</p>
<ul>
<li><a href="https://www.cs.toronto.edu/%7Ehinton/">Toronto University Web Page</a></li>
<li><a href="https://research.google/people/GeoffreyHinton/">Google Research Web Page</a></li>
<li><a href="https://twitter.com/geoffreyhinton?lang=en">Twitter Handle</a></li>
</ul>
<h1><a class="header" href="#step-hochreiter" id="step-hochreiter">Step Hochreiter</a></h1>
<p>LSTM</p>
<h1><a class="header" href="#andrej-karpathy" id="andrej-karpathy">Andrej Karpathy</a></h1>
<p>AI Researcher mainly in the field of vision. He focused also on model <a href="topics.html#Interpretability">Interpretability</a>. 
Former student of <a href="people.html#Geoff_Hinton">Geoff Hinton</a> at U. of Toronto, his PhD. advisor was <a href="people.html#Fei-Fei_Li">Fei-Fei Li</a> at 
Stanford. After passing by Google's Brain, Research and DeepMind teams, by 2021, current director of AI and Autopilot 
Vision at Tesla. </p>
<p><a href="https://karpathy.ai/">Personal Website</a>
<a href="http://karpathy.github.io/">Blog</a> </p>
<p>Main papers:</p>
<ul>
<li>Large-scale Video Classiﬁcation with Convolutional Neural Networks [<a href="bibliography.html#karpathy_large-scale_nodate">karpathy_large-scale_nodate</a>]</li>
<li>Visualizing and Understanding Recurrent Networks [<a href="bibliography.html#karpathy_visualizing_2015">karpathy_visualizing_2015</a>]</li>
</ul>
<h1><a class="header" href="#a-hrefhttpsenwikipediaorgwikiscott_kirkpatrickscott-kirkpatricka" id="a-hrefhttpsenwikipediaorgwikiscott_kirkpatrickscott-kirkpatricka"><a href="https://en.wikipedia.org/wiki/Scott_Kirkpatrick">Scott Kirkpatrick</a></a></h1>
<p>Inventor of <a href="vocabulary.html#Simulated_Annealing">simulated annealing</a></p>
<h1><a class="header" href="#alex-krizhevsky" id="alex-krizhevsky">Alex Krizhevsky</a></h1>
<p>Co-Developer of AlexNet, which in 2012 obtained an impressive error rate of 18% in the ImageNet dataset.</p>
<h1><a class="header" href="#yann-lecunn" id="yann-lecunn">Yann LeCunn</a></h1>
<p>Creator of &quot;Le Net&quot; and it's subsequent evolutions, mimicking the visual cortex (&quot;ConvNet&quot;).
Creator of a backpropagation-like method in his PhD thesis in 1987 (Modeles connexionnistes de l'apprentissage).</p>
<h1><a class="header" href="#fei-fei-li" id="fei-fei-li">Fei-Fei Li</a></h1>
<h1><a class="header" href="#marvin-minsky" id="marvin-minsky">Marvin Minsky</a></h1>
<p>Winner of the <a href="https://amturing.acm.org/award_winners/minsky_7440781.cfm">Turing Award</a> in 1969. Joint with (#Seymour_Papert)
both being authors of &quot;Perceptrons&quot; {{ cite minsky_perceptrons_1987 }}, demonstrated initially that NN had severe learning limitations as a ML technique.
This is often cited as a cause for the advent of the first machine learning winter int the 70s.</p>
<p>Apart from this, he was famous from his &quot;Theory of Frames&quot;, summarized in the paper, “A Framework for Representing Knowledge” [<a href="bibliography.html#minsky_framework_1974">minsky_framework_1974</a>].
The theory of frames is one of the things I still remember being introduced to during the poorly AI class I took at the
university (although I have to say that at that time, AI wasn't very popular due to all the buzz about the Internet and
the WWW flying around). This evolved years later in his broader theory for memory published in 1979 in the book 
“K-lines: A Theory of Memory” [<a href="bibliography.html#minsky_k-lines_1979">minsky_k-lines_1979</a>].</p>
<p>In the 2006 AI@50 conference, he critized the AI community in not being focused on trying to solve the &quot;general intelligence&quot;
problem and be just focused on applications. According to T. Sejnosky, Dr. Minsky recognized in that conference to have
been the &quot;devil&quot; that caused the 1st winter period in AI in the 70s [<a href="bibliography.html#sejnowski_deep_2018">sejnowski_deep_2018</a>].</p>
<ul>
<li><a href="https://dblp.org/pid/m/MarvinMinsky.html">DBLP Papers</a></li>
</ul>
<h1><a class="header" href="#gary-marcus" id="gary-marcus">Gary Marcus</a></h1>
<p>Cognitive scientist (in his PhD had Steven Pinker as advisor,) founder of Geometric Intelligence, a ML company
acquired by Uber in 2016. He's trying to &quot;shape&quot; the next steps in ML through his essays and articles (e.g. {{ cite marcus_next_2020 }}).
Well known for challenging the traditional <a href="approaches.html#connectionist">connectionist theories</a>, he believes that
<a href="https://en.wikipedia.org/wiki/Gary_Marcus">neurons can be put together to build circuits in order to do things such as process rules or process structured 
representations</a>, which is more aligned with the Neuro-Symbolic Learning 
and Reasoning line of work.</p>
<h1><a class="header" href="#carver-mead" id="carver-mead">Carver Mead</a></h1>
<p>Neuromorphic computation</p>
<h1><a class="header" href="#javier-movellan" id="javier-movellan">Javier Movellan</a></h1>
<p>Piooner in introducing social robots in classrooms.</p>
<p><a href="https://scholar.google.com/citations?user=07NrZFIAAAAJ&amp;hl=en">Google Scholar Papers</a>
<a href="https://dblp.org/pid/41/4458.html">DBLP Papers</a></p>
<h1><a class="header" href="#andrew-ng" id="andrew-ng">Andrew Ng</a></h1>
<p>He's driven a lot of efforts for disseminating and democratizing modern AI and DL. Founder of <a href="https://www.coursera.org/">Coursera</a> and <a href="https://www.deeplearning.ai/">DeepLearning.AI</a>
Author of a guide for Machine Learning engineers that summarizes the basic principles and best practices to take into account in
that new &quot;work position&quot; called <a href="https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf">Machine Learning Yearning</a></p>
<h1><a class="header" href="#allen-newell" id="allen-newell">Allen Newell</a></h1>
<p>Joint with [Herbert A. Simon](#Herbert A. Simon) one of the fathers of the <a href="approaches.html#Symbolist">symbolic approach in AI/ML</a>. </p>
<h1><a class="header" href="#arthur-samuel" id="arthur-samuel">Arthur Samuel</a></h1>
<p>One of the pioners of a game-oriented AI, and reinforcement learning precursor. Creator of a chess game while at IBM that
learned playing against itself.</p>
<h1><a class="header" href="#santiago-ramon-y-cajal" id="santiago-ramon-y-cajal">Santiago Ramon y Cajal</a></h1>
<p>Spanish neuroanatomist considered one of the fathers of modern neuroscience.</p>
<h1><a class="header" href="#david-rumelhart" id="david-rumelhart">David Rumelhart</a></h1>
<p>(1943-2011)</p>
<p>Known for being one of the persons developing <a href="vocabulary.html#backpropagation">Backpropagation</a>.
He was diagnosed with FTD (frontotemporal dementia). In FTD, some areas of the frontal lobes of the brain suffer an 
atrophy (they shrink), which in the end may cause problems with behavior and language depending on the area affected.</p>
<h1><a class="header" href="#terrence-sejnowsky" id="terrence-sejnowsky">Terrence Sejnowsky</a></h1>
<p>(1947-)</p>
<p>One of the initial developers and advocates of connectionism.</p>
<h1><a class="header" href="#herbert-a-simon" id="herbert-a-simon">Herbert A. Simon</a></h1>
<p>A strong believer of the <a href="approaches.html#Symbolist">symbolic approach in AI/ML</a>. </p>
<h1><a class="header" href="#marian-stewart-bartlett" id="marian-stewart-bartlett">Marian Stewart-Bartlett</a></h1>
<p>Pioneer on recognizing facial expressions identified by Paul Ekman with neural networks.
Founder, joint with <a href="people.html#Javier_Movellan">Javier Movellan</a> of Emotient, which was eventually acquired by Apple.</p>
<p><a href="https://dblp.org/pid/54/4284.html">DBLP Papers</a></p>
<h1><a class="header" href="#ilya-sutskever" id="ilya-sutskever">Ilya Sutskever</a></h1>
<p>Co-Developer of AlexNet
Co-Founder of Open AI</p>
<h1><a class="header" href="#richard-sutton" id="richard-sutton">Richard Sutton</a></h1>
<p>One of the current popes of Reinforcement Learning</p>
<h1><a class="header" href="#seymour-papert" id="seymour-papert">Seymour Papert</a></h1>
<h1><a class="header" href="#judea-perl" id="judea-perl">Judea Perl</a></h1>
<p>Creator of Belief Networks based on Bayesian analysis.
Author or {{ cite perl_2018 }}</p>
<h1><a class="header" href="#jurgen-schimidhuber" id="jurgen-schimidhuber">Jurgen Schimidhuber</a></h1>
<p>LSTM</p>
<h1><a class="header" href="#hava-siegelmann" id="hava-siegelmann">Hava Siegelmann</a></h1>
<p><a href="https://www.cics.umass.edu/faculty/directory/siegelmann_hava">She's the creator</a> of a new field of computer science, 
Super-Turing computation. This is related to the <a href="approaches.html#Adaptable">Adaptable approach</a> to AI/ML learning.</p>
<h1><a class="header" href="#vladimir-vapnik" id="vladimir-vapnik">Vladimir Vapnik</a></h1>
<p>Author of the SVM</p>
<h1><a class="header" href="#stephen-wolfram" id="stephen-wolfram">Stephen Wolfram</a></h1>
<p>Pioneer in Complexity theory and creator of Mathematica and Wolfgram Alpha mathematical search engine. He studied complexity
through cellular automatas (e.g. Conway's Game of Life.) John von Neuman also studied cellullar automata, in this case
for self-replication. <a href="https://science.sciencemag.org/content/157/3785/180.1">He found an automata</a> with 29 states 
and a large memory that was able to self-replicate.</p>
<h1><a class="header" href="#a" id="a">A</a></h1>
<h2><a class="header" href="#auto-encoder" id="auto-encoder">Auto-Encoder</a></h2>
<p>Autoencoders are unsupervised ANN that can learn data encodings, making the encoder generate those encodings 
specifically for reconstructing its own input (See figure below.) They convert their inputs to encoded vectors that lie
in a latent space that may not be continuous or allow easy interpolation. In the end, this means that regular autoencoders 
are mostly limited to be used to generate compressed representations of their inputs, allowing to regenerate the original
input with minimal loss.</p>
<p><img src="images/autoencoder.png" alt="Autoencoder (Source: https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf)" /></p>
<h1><a class="header" href="#b" id="b">B</a></h1>
<h2><a class="header" href="#backpropagation" id="backpropagation">Backpropagation</a></h2>
<p>A procedure to adjust the weights of a neural network by propagating the error obtained in the forward pass, backwards. 
After calculating the error in the output layer, e.g. by contrasting the output of the forward pass with the known 
so-called gold labels by means of a cost function, the gradient on the input weights of the last layer to the output units 
is calculated; then the weights of that layer are adjusted; this process is repeated backwards layer after layer until 
reaching the input layer. </p>
<h1><a class="header" href="#causality-1" id="causality-1">Causality</a></h1>
<p>Correlations is not causation. In ML causality tries to understand the relationships between data in order to create models
that generalize well.</p>
<h1><a class="header" href="#e" id="e">E</a></h1>
<h2><a class="header" href="#expert-system" id="expert-system">Expert System</a></h2>
<h2><a class="header" href="#a-hrefvocabularyhtmlinterpretabilityexplainabilitya" id="a-hrefvocabularyhtmlinterpretabilityexplainabilitya"><a href="vocabulary.html#Interpretability">Explainability</a></a></h2>
<p><a href="vocabulary.html#Interpretability">See Interpretability</a>.</p>
<h2><a class="header" href="#explanation" id="explanation">Explanation</a></h2>
<p>The explicit ability expected in an intelligent agent to give &quot;good&quot; explanations of its decisions to humans. As usual,
the problem here is to define what is a &quot;good&quot; explanation. If we try to mimic in the intelligent agent world, how 
humans proceed giving explanations to other humans, we have to acknowledge we'll have to deal with biases and/or social
expectations. Some researchers argue {{ cite graaf_how_2017 }} that the framework of explanation of those agents will need 
to be consistent with the conceptual framework and psychological mechanisms of human behavior explanation, as humans
will expect explanations falling under those two premises.</p>
<h1><a class="header" href="#f" id="f">F</a></h1>
<h2><a class="header" href="#feature" id="feature">Feature</a></h2>
<p>It's a property extracted from each data instance of a dataset being observed. An example would be the &quot;color&quot; attribute
extracted from row coding an outfit item example from a file called seasonal_outfits.csv). Features are
crucial for many ML procesess. Selecting those features it's an art, which even has a name: <a href="vocabulary.html#feature_enginering">feature engineering</a>.
Some of the properties that a good feature should have for being selected are:</p>
<ul>
<li>Informative about the concept that they represent</li>
<li>Discriminating, to be able to separate one example instance from another </li>
<li>Independent, if possible from the other features extracted from the data instance</li>
</ul>
<h2><a class="header" href="#feature-engineering" id="feature-engineering">Feature Engineering</a></h2>
<p>The classical/traditional way of &quot;massage&quot; the input to pass to a ML model (e.g. a classifier.) It refers to the process 
of using domain knowledge to extract features from raw data. This was an &quot;art&quot; in itself usually done by domain experts.
In the age of DL, this has been substituted by the DL models themselves, which represents also the features on top of
which the learning of a task is done.</p>
<h1><a class="header" href="#g" id="g">G</a></h1>
<h2><a class="header" href="#generalization" id="generalization">Generalization</a></h2>
<p>The capability of an already trained ML model of adapting to previously unseen data taken from the same distribution as
the data used to train it.</p>
<h2><a class="header" href="#generative-adversarial-network-gan" id="generative-adversarial-network-gan">Generative Adversarial Network (GAN)</a></h2>
<p>A special architecture of ANN aimed to <em>generate new data</em> with similar statistics as of the ones found in a particular 
training set. The classical example of what GANs are used for, is the generation of new faces, by interpolating new
features from the data obtained from a pool of preexisting images of faces. The goal is to build the new images as real 
as possible, making them undistinguisable from real images for the human eye.</p>
<p>The idea is to train two models at the same time; the first one is the &quot;generative&quot; one, which serves as the &quot;trend 
gatherer&quot;, that is capturing the data distribution; the second one model, called &quot;discriminative&quot;, is trained to discern
if a particular sample comes from the training data or from the &quot;generative&quot; moidel [<a href="bibliography.html#goodfellow_generative_2014">goodfellow_generative_2014</a>]</p>
<p><img src="images/gan.png" alt="GAN (Source: https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29)" /></p>
<h1><a class="header" href="#h" id="h">H</a></h1>
<h2><a class="header" href="#hallucination" id="hallucination">Hallucination</a></h2>
<p>In text generation tasks, it refers to misleading statements generated by the models when outputing their results
. Usually hallucinations have to do with the quality of the data the model was trained on; for example the</p>
<h1><a class="header" href="#i" id="i">I</a></h1>
<h2><a class="header" href="#interpretability" id="interpretability">Interpretability</a></h2>
<p>How well a human can understand the decisions (e.g. the output of a ML classifier) taken by an intelligent system in a given context.
This is related to the extent up to which humans can predict the results of a model. </p>
<h3><a class="header" href="#related" id="related">Related</a></h3>
<ul>
<li><a href="https://www.technologyreview.com/2018/02/21/145289/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/">Ian Goodfellow Interview</a></li>
</ul>
<h1><a class="header" href="#l" id="l">L</a></h1>
<h1><a class="header" href="#language-model" id="language-model">Language Model</a></h1>
<p>In any language, the words (or characters) in a sentence show certain correlations. Those correlations
capture and contextualize the underlying semantics and characteristics of the particular language. </p>
<p>Sequences of tokens can be found almost anywhere, being the words in a text, pixels in an image, the musical notes in
a score, etc. A language model could be defined as a statistical model that has learnt to predict the probability of a
sequence of tokens, capturing the correlation with other nearby tokens, either consecutive or not. In NLP, the tokens 
use to represent words or n-grams.</p>
<p>The calculation of the next token in the sequence \( x_n \) can be modeled as:</p>
<p>\( p(x_n | x_{n-1}, x_{n-2}...x_{1}) \)</p>
<p>where \( x_i \) represents the ith token in the sequence.</p>
<p>For more information see [<a href="bibliography.html#bengio_neural_2003">bengio_neural_2003</a>].</p>
<h1><a class="header" href="#neural-network" id="neural-network">Neural Network</a></h1>
<h1><a class="header" href="#neuromorphic-computing" id="neuromorphic-computing">Neuromorphic Computing</a></h1>
<p>A computing approach which model neurons as asynchronous and independent computation units which are stimulated by the
spikes triggered by other interconnected neurons, in a similar way as brain neurons behave.</p>
<p>Relying on asynchronous communication between the neurons, these neuromorphic systems do not need to rely on a system 
clock. So, this async communication of pulses to simulate neuron spikes is more enegy efficient, as it consumes less 
power.</p>
<h1><a class="header" href="#o" id="o">O</a></h1>
<h2><a class="header" href="#overfitting" id="overfitting">Overfitting</a></h2>
<p>The effect seen in a ML model when it seems to fit the training data so closely to the target goal that its unable to 
<a href="vocabulary.html#Generalization">generalize</a> well to unseen data. When a model is said to be overfitted, usually we observe a low
error in the metrics from the train dataset and a high error in the metrics from the test dataset. </p>
<h1><a class="header" href="#s" id="s">S</a></h1>
<h2><a class="header" href="#simulated-annealing" id="simulated-annealing">Simulated Annealing</a></h2>
<p>Inspired by the process of annealing in metal works, it describes a probabilistic approach to solve problems by 
&quot;heating&quot; them up and, subsequently, &quot;cooling&quot; them down. Let's see what this means.</p>
<p>The algorithmic solution of is applicable in large search domain problems with may contain several local optima points.
At the core of a simulated annealing algorithm, there's a temperature variable. This variable is set up with a high
value to simulate the heating process. As the algorithm proceeds with its iterations, the variable is allowed to be 
&quot;cooled down&quot;. While the temperature is high, the algorithm accepts solutions that are worse than the current solution;
that means in some way that is less risk averse. This allows the algorithm to jump out from locations with local optima
that may be appear early when executing. Gradually, as the temperature decreases, the probability of accepting worse 
solutions decreases, hopefully &quot;crystallizing&quot; on the area of the search space where the global optimum solution is located. </p>
<p>More info see [<a href="bibliography.html#kirkpatrick_optimization_1983">kirkpatrick_optimization_1983</a>].</p>
<h2><a class="header" href="#svm-support-vector-machine" id="svm-support-vector-machine">SVM (Support Vector Machine)</a></h2>
<p>Perceptron-based classifier. SVM learns how to separate points in the space by establishing the so-called decision boundaries.
When data is separable linearly, as it shown in many examples in the ML literature, it may seem a trivial task. However, 
data in the real world is not always linearly separable, being randomly distributed, making it hard the process of segregating
the different classes linearly. The kernel trick introduced by the SVM paper performs a mathematical trick to efficiently 
(in O(n)) map -for example- data from a 2-dimensional space to 3-dimensional space, where maybe it's possible to find a 
hyperplane that separates the different classes.</p>
<h1><a class="header" href="#v" id="v">V</a></h1>
<h2><a class="header" href="#variational-auto-encoder" id="variational-auto-encoder">Variational Auto-Encoder</a></h2>
<p>In contrast to a vanilla <a href="vocabulary.html#auto-encoder">autoencoder</a>, a Variational AutoEncoder (VAE) is a <em>generative model</em> 
that shares most of the architecture with a regular autoencoder, like Generative Adversarial Networks. Because of this, 
VAEs have relatively little to do with classical autoencoders (sparse or denoising autoencoders) from a mathematical
point of view.
VAEs have a special property (which we could call the &quot;creativity&quot; property) that makes them more interesting over 
regular autoencoders for generating outputs; their latent spaces are 
continuous by design, which allows random sampling and interpolation. In a generative model this is what you want in the
end; randomly sample from the continuous latent space in order to &quot;distort a bit&quot; the input image generating an image 
variation, similar to the original one, but definitely not the same.</p>
<p>A VAE tries to maximize the probability of each X in the training set under the entire generative process
according to \( P(X) = \int P(X|z; \theta)P(z)dz \)</p>
<p>\( P(X|z; \theta) \), allows making the dependence of X on z explicit by using the law of total probability. This<br />
framework, called &quot;maximum likelihood&quot;, allows to assume that if the model is likely to produce training set samples, 
then it is also likely to produce similar samples, and also unlikely to produce dissimilar ones.</p>
<p>According to [<a href="bibliography.html#doersch_tutorial_2016">doersch_tutorial_2016</a>] VAEs are called &quot;autoencoders&quot; because the final training objective does
share the encoder/decoder architecture, so it resembles a traditional autoencoder.</p>
<h1><a class="header" href="#bibliography" id="bibliography">Bibliography</a></h1>
<script type="text/javascript">
function defaultCopyTextToClipboard(text) {
    var textArea = document.createElement("textarea");
    textArea.value = text;

    // Avoid scrolling to bottom
    textArea.style.top = "0";
    textArea.style.left = "0";
    textArea.style.position = "fixed";

    document.body.appendChild(textArea);
    textArea.focus();
    textArea.select();

    try {
        var ok = document.execCommand('copy');
        var msg = ok ? 'was ok' : 'failed';
        console.log('Backing copy: Text copy was ' + msg);
    } catch (err) {
        console.error('Backing copy: Unable to copy text', err);
    }

    document.body.removeChild(textArea);
}

function copyToClipboard(text) {
    if (!navigator.clipboard) {
        defaultCopyTextToClipboard(text);
        return;
    }
    navigator.clipboard.writeText(text).then(function() {
        console.log('Text copied to clipboard');
    }, function(err) {
        console.error('Error copying text: ', err);
    });
}

</script>
<style></style>
<div class="bib_div">
<details data-key="schmidhuber_deep_2015" class=ref>
<summary class=citation>
<a id="schmidhuber_deep_2015">[schmidhuber_deep_2015]</a> - Schmidhuber, Juergen - <a href="http://arxiv.org/abs/1404.7828" target="_blank"><cite>Deep Learning in Neural Networks: An Overview</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite schmidhuber_deep_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract" id="summaryabstract">Summary/Abstract</a></h1>
<div>In recent years, deep artiﬁcial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \&amp; evolutionary computation, and indirect search for short programs encoding deep and large networks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="kirkpatrick_optimization_1983" class=ref>
<summary class=citation>
<a id="kirkpatrick_optimization_1983">[kirkpatrick_optimization_1983]</a> - Kirkpatrick, S., Gelatt, C. D., Vecchi, M. P. - <a href="https://science.sciencemag.org/content/220/4598/671" target="_blank"><cite>Optimization by Simulated Annealing</cite></a>. - 1983. -
<button onclick="copyToClipboard('\{\{ #cite kirkpatrick_optimization_1983 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-1" id="summaryabstract-1">Summary/Abstract</a></h1>
<div>There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="bucilua_model_2006" class=ref>
<summary class=citation>
<a id="bucilua_model_2006">[bucilua_model_2006]</a> - Buciluǎ, Cristian, Caruana, Rich, Niculescu-Mizil, Alex, ru - <a href="https://doi.org/10.1145/1150402.1150464" target="_blank"><cite>Model compression</cite></a>. - 2006. -
<button onclick="copyToClipboard('\{\{ #cite bucilua_model_2006 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-2" id="summaryabstract-2">Summary/Abstract</a></h1>
<div>Often the best performing supervised learning models are ensembles of hundreds or thousands of base-level classifiers. Unfortunately, the space required to store this many classifiers, and the time required to execute them at run-time, prohibits their use in applications where test sets are large (e.g. Google), where storage space is at a premium (e.g. {PDAs}), and where computational power is limited (e.g. hea-ring aids). We present a method for compressing large, complex ensembles into smaller, faster models, usually without significant loss in performance.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="tavakoli_prioritizing_2019" class=ref>
<summary class=citation>
<a id="tavakoli_prioritizing_2019">[tavakoli_prioritizing_2019]</a> - Tavakoli, Arash, Levdik, Vitaly, Islam, Riashat, Kormushev, Petar - <a href="http://arxiv.org/abs/1811.11298" target="_blank"><cite>Prioritizing Starting States for Reinforcement Learning</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite tavakoli_prioritizing_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-3" id="summaryabstract-3">Summary/Abstract</a></h1>
<div>Online, off-policy reinforcement learning algorithms are able to use an experience memory to remember and replay past experiences. In prior work, this approach was used to stabilize training by breaking the temporal correlations of the updates and avoiding the rapid forgetting of possibly rare experiences. In this work, we propose a conceptually simple framework that uses an experience memory to help exploration by prioritizing the starting states from which the agent starts acting in the environment, importantly, in a fashion that is also compatible with on-policy algorithms. Given the capacity to restart the agent in states corresponding to its past observations, we achieve this objective by (i) enabling the agent to restart in states belonging to significant past experiences (e.g., nearby goals), and (ii) promoting faster coverage of the state space through starting from a more diverse set of states. While, using a good priority measure to identify significant past transitions, we expect case (i) to more considerably help exploration in certain domains (e.g., sparse reward tasks), we hypothesize that case (ii) will generally be beneficial, even without any prioritization. We show empirically that our approach improves learning performance for both off-policy and on-policy deep reinforcement learning methods, with most notable gains in highly sparse reward tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="marcus_next_2020" class=ref>
<summary class=citation>
<a id="marcus_next_2020">[marcus_next_2020]</a> - Marcus, Gary - <a href="http://arxiv.org/abs/2002.06177" target="_blank"><cite>The Next Decade in {AI}: Four Steps Towards Robust Artificial Intelligence</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite marcus_next_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-4" id="summaryabstract-4">Summary/Abstract</a></h1>
<div>Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust {AI} than is currently possible.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="van_de_ven_three_2019-1" class=ref>
<summary class=citation>
<a id="van_de_ven_three_2019-1">[van_de_ven_three_2019-1]</a> - van de Ven, Gido M., Tolias, Andreas S. - <a href="http://arxiv.org/abs/1904.07734" target="_blank"><cite>Three scenarios for continual learning</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite van_de_ven_three_2019-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-5" id="summaryabstract-5">Summary/Abstract</a></h1>
<div>Standard artificial neural networks suffer from the well-known issue of catastrophic forgetting, making continual or lifelong learning difficult for machine learning. In recent years, numerous methods have been proposed for continual learning, but due to differences in evaluation protocols it is difficult to directly compare their performance. To enable more structured comparisons, we describe three continual learning scenarios based on whether at test time task identity is provided and--in case it is not--whether it must be inferred. Any sequence of well-defined tasks can be performed according to each scenario. Using the split and permuted {MNIST} task protocols, for each scenario we carry out an extensive comparison of recently proposed continual learning methods. We demonstrate substantial differences between the three scenarios in terms of difficulty and in terms of how efficient different methods are. In particular, when task identity must be inferred (i.e., class incremental learning), we find that regularization-based approaches (e.g., elastic weight consolidation) fail and that replaying representations of previous experiences seems required for solving this scenario.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="parisi_continual_2019-1" class=ref>
<summary class=citation>
<a id="parisi_continual_2019-1">[parisi_continual_2019-1]</a> - Parisi, German I., Kemker, Ronald, Part, Jose L., Kanan, Christopher, Wermter, Stefan - <a href="http://arxiv.org/abs/1802.07569" target="_blank"><cite>Continual Lifelong Learning with Neural Networks: A Review</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite parisi_continual_2019-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-6" id="summaryabstract-6">Summary/Abstract</a></h1>
<div>Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="real_automl-zero_2020" class=ref>
<summary class=citation>
<a id="real_automl-zero_2020">[real_automl-zero_2020]</a> - Real, Esteban, Liang, Chen, So, David R., Le, Quoc V. - <a href="http://arxiv.org/abs/2003.03384" target="_blank"><cite>{AutoML}-Zero: Evolving Machine Learning Algorithms From Scratch</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite real_automl-zero_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-7" id="summaryabstract-7">Summary/Abstract</a></h1>
<div>Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as {AutoML}, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that {AutoML} can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. {CIFAR}-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="ribeiro_beyond_2020" class=ref>
<summary class=citation>
<a id="ribeiro_beyond_2020">[ribeiro_beyond_2020]</a> - Ribeiro, Marco Tulio, Wu, Tongshuang, Guestrin, Carlos, Singh, Sameer - <a href="http://arxiv.org/abs/2005.04118" target="_blank"><cite>Beyond Accuracy: Behavioral Testing of {NLP} models with {CheckList}</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite ribeiro_beyond_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-8" id="summaryabstract-8">Summary/Abstract</a></h1>
<div>Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of {NLP} models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce {CheckList}, a task-agnostic methodology for testing {NLP} models. {CheckList} includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of {CheckList} with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, {NLP} practitioners with {CheckList} created twice as many tests, and found almost three times as many bugs as users without it.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="synced_google_2019" class=ref>
<summary class=citation>
<a id="synced_google_2019">[synced_google_2019]</a> - Synced - <a href="https://medium.com/syncedreview/google-t5-explores-the-limits-of-transfer-learning-a87afbf2615b" target="_blank"><cite>Google T5 Explores the Limits of Transfer Learning</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite synced_google_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-9" id="summaryabstract-9">Summary/Abstract</a></h1>
<div>A Google research team recently published the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer…</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="brittain_prioritized_nodate" class=ref>
<summary class=citation>
<a id="brittain_prioritized_nodate">[brittain_prioritized_nodate]</a> - Brittain, Marc, Bertram, Josh, Yang, Xuxi, Wei, Peng - <cite>Prioritized Sequence Experience Replay</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite brittain_prioritized_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-10" id="summaryabstract-10">Summary/Abstract</a></h1>
<div>Experience replay is widely used in deep reinforcement learning algorithms and allows agents to remember and learn from experiences from the past. In an effort to learn more efﬁciently, researchers proposed prioritized experience replay ({PER}) which samples important transitions more frequently. In this paper, we propose Prioritized Sequence Experience Replay ({PSER}) a framework for prioritizing sequences of experience in an attempt to both learn more efﬁciently and to obtain better performance. We compare the performance of {PER} and {PSER} sampling techniques in a tabular Q-learning environment and in {DQN} on the Atari 2600 benchmark. We prove theoretically that {PSER} is guaranteed to converge faster than {PER} and empirically show {PSER} substantially improves upon {PER}.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="klein_opennmt_2017" class=ref>
<summary class=citation>
<a id="klein_opennmt_2017">[klein_opennmt_2017]</a> - Klein, Guillaume, Kim, Yoon, Deng, Yuntian, Senellart, Jean, Rush, Alex, er - <a href="http://aclweb.org/anthology/P17-4012" target="_blank"><cite>{OpenNMT}: Open-Source Toolkit for Neural Machine Translation</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite klein_opennmt_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-11" id="summaryabstract-11">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="shin_continual_2017" class=ref>
<summary class=citation>
<a id="shin_continual_2017">[shin_continual_2017]</a> - Shin, Hanul, Lee, Jung Kwon, Kim, Jaehong, Kim, Jiwon - <a href="http://arxiv.org/abs/1705.08690" target="_blank"><cite>Continual Learning with Deep Generative Replay</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite shin_continual_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-12" id="summaryabstract-12">Summary/Abstract</a></h1>
<div>Attempts to train a comprehensive artificial intelligence capable of solving multiple tasks have been impeded by a chronic problem called catastrophic forgetting. Although simply replaying all previous data alleviates the problem, it requires large memory and even worse, often infeasible in real world applications where the access to past data is limited. Inspired by the generative nature of hippocampus as a short-term memory system in primate brain, we propose the Deep Generative Replay, a novel framework with a cooperative dual model architecture consisting of a deep generative model (generator) and a task solving model (solver). With only these two models, training data for previous tasks can easily be sampled and interleaved with those for a new task. We test our methods in several sequential learning settings involving image classification tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="polyzotis_slice_2019" class=ref>
<summary class=citation>
<a id="polyzotis_slice_2019">[polyzotis_slice_2019]</a> - Polyzotis, Neoklis, Whang, Steven, Kraska, Tim Klas, Chung, Yeounoh - <a href="https://arxiv.org/pdf/1807.06068.pdf" target="_blank"><cite>Slice Finder: Automated Data Slicing for Model Validation</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite polyzotis_slice_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-13" id="summaryabstract-13">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="tsuda_modeling_2020" class=ref>
<summary class=citation>
<a id="tsuda_modeling_2020">[tsuda_modeling_2020]</a> - Tsuda, Ben, Tye, Kay M., Siegelmann, Hava T., Sejnowski, Terrence J. - <a href="https://www.pnas.org/content/117/47/29872" target="_blank"><cite>A modeling framework for adaptive lifelong learning with transfer and savings through gating in the prefrontal cortex</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite tsuda_modeling_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-14" id="summaryabstract-14">Summary/Abstract</a></h1>
<div>The prefrontal cortex encodes and stores numerous, often disparate, schemas and flexibly switches between them. Recent research on artificial neural networks trained by reinforcement learning has made it possible to model fundamental processes underlying schema encoding and storage. Yet how the brain is able to create new schemas while preserving and utilizing old schemas remains unclear. Here we propose a simple neural network framework that incorporates hierarchical gating to model the prefrontal cortex’s ability to flexibly encode and use multiple disparate schemas. We show how gating naturally leads to transfer learning and robust memory savings. We then show how neuropsychological impairments observed in patients with prefrontal damage are mimicked by lesions of our network. Our architecture, which we call {DynaMoE}, provides a fundamental framework for how the prefrontal cortex may handle the abundance of schemas necessary to navigate the real world.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zhu_freelb_2019" class=ref>
<summary class=citation>
<a id="zhu_freelb_2019">[zhu_freelb_2019]</a> - Zhu, Chen, Cheng, Yu, Gan, Zhe, Sun, Siqi, Goldstein, Tom, Liu, Jingjing - <a href="http://arxiv.org/abs/1909.11764" target="_blank"><cite>{FreeLB}: Enhanced Adversarial Training for Language Understanding</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite zhu_freelb_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-15" id="summaryabstract-15">Summary/Abstract</a></h1>
<div>Adversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm - {FreeLB}, that promotes higher robustness and invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the {GLUE} benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of {BERT}-based model from 78.3 to 79.4, and {RoBERTa}-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art single-model test accuracies of 85.44\% and 67.75\% on {ARC}-Easy and {ARC}-Challenge. Experiments on {CommonsenseQA} benchmark further demonstrate that {FreeLB} can be generalized and boost the performance of {RoBERTa}-large model on other tasks as well.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="van_de_ven_three_2019" class=ref>
<summary class=citation>
<a id="van_de_ven_three_2019">[van_de_ven_three_2019]</a> - van de Ven, Gido M., Tolias, Andreas S. - <a href="http://arxiv.org/abs/1904.07734" target="_blank"><cite>Three scenarios for continual learning</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite van_de_ven_three_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-16" id="summaryabstract-16">Summary/Abstract</a></h1>
<div>Standard artificial neural networks suffer from the well-known issue of catastrophic forgetting, making continual or lifelong learning difficult for machine learning. In recent years, numerous methods have been proposed for continual learning, but due to differences in evaluation protocols it is difficult to directly compare their performance. To enable more structured comparisons, we describe three continual learning scenarios based on whether at test time task identity is provided and–in case it is not–whether it must be inferred. Any sequence of well-defined tasks can be performed according to each scenario. Using the split and permuted {MNIST} task protocols, for each scenario we carry out an extensive comparison of recently proposed continual learning methods. We demonstrate substantial differences between the three scenarios in terms of difficulty and in terms of how efficient different methods are. In particular, when task identity must be inferred (i.e., class incremental learning), we find that regularization-based approaches (e.g., elastic weight consolidation) fail and that replaying representations of previous experiences seems required for solving this scenario.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="van_de_ven_generative_2019-1" class=ref>
<summary class=citation>
<a id="van_de_ven_generative_2019-1">[van_de_ven_generative_2019-1]</a> - van de Ven, Gido M., Tolias, Andreas S. - <a href="http://arxiv.org/abs/1809.10635" target="_blank"><cite>Generative replay with feedback connections as a general strategy for continual learning</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite van_de_ven_generative_2019-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-17" id="summaryabstract-17">Summary/Abstract</a></h1>
<div>A major obstacle to developing artificial intelligence applications capable of true lifelong learning is that artificial neural networks quickly or catastrophically forget previously learned tasks when trained on a new one. Numerous methods for alleviating catastrophic forgetting are currently being proposed, but differences in evaluation protocols make it difficult to directly compare their performance. To enable more meaningful comparisons, here we identified three distinct scenarios for continual learning based on whether task identity is known and, if it is not, whether it needs to be inferred. Performing the split and permuted {MNIST} task protocols according to each of these scenarios, we found that regularization-based approaches (e.g., elastic weight consolidation) failed when task identity needed to be inferred. In contrast, generative replay combined with distillation (i.e., using class probabilities as soft targets) achieved superior performance in all three scenarios. Addressing the issue of efficiency, we reduced the computational cost of generative replay by integrating the generative model into the main model by equipping it with generative feedback or backward connections. This Replay-through-Feedback approach substantially shortened training time with no or negligible loss in performance. We believe this to be an important first step towards making the powerful technique of generative replay scalable to real-world continual learning applications.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_improvements_2018" class=ref>
<summary class=citation>
<a id="noauthor_improvements_2018">[noauthor_improvements_2018]</a> - N/A - <a href="https://www.freecodecamp.org/news/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682/" target="_blank"><cite>Improvements in Deep Q Learning: Dueling Double {DQN}, Prioritized Experience Replay, and fixed…</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_improvements_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-18" id="summaryabstract-18">Summary/Abstract</a></h1>
<div>by Thomas Simonini
<p>Improvements in Deep Q Learning: Dueling Double {DQN}, Prioritized Experience
Replay, and fixed Q-targets
{\textgreater} This article is part of Deep Reinforcement Learning Course with Tensorflow ?️.
Check the syllabus here.
[https://simoninithomas.github.io/Deep_reinforcement_learning_Course/]
In our last article about Deep Q Learning with Tensorflow
[https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8]
, we implemented an agent that learns to pla</div></p>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="raffel_exploring_2019" class=ref>
<summary class=citation>
<a id="raffel_exploring_2019">[raffel_exploring_2019]</a> - Raffel, Colin, Shazeer, Noam, Roberts, Adam, Lee, Katherine, Narang, Sharan, Matena, Michael, Zhou, Yanqi, Li, Wei, Liu, Peter J. - <a href="http://arxiv.org/abs/1910.10683" target="_blank"><cite>Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite raffel_exploring_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-19" id="summaryabstract-19">Summary/Abstract</a></h1>
<div>Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing ({NLP}). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for {NLP} by introducing a unified framework that converts every language problem into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled datasets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new Colossal Clean Crawled Corpus, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for {NLP}, we release our dataset, pre-trained models, and code.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="doersch_tutorial_2016" class=ref>
<summary class=citation>
<a id="doersch_tutorial_2016">[doersch_tutorial_2016]</a> - Doersch, Carl - <a href="http://arxiv.org/abs/1606.05908" target="_blank"><cite>Tutorial on Variational Autoencoders</cite></a>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite doersch_tutorial_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-20" id="summaryabstract-20">Summary/Abstract</a></h1>
<div>In just three years, Variational Autoencoders ({VAEs}) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. {VAEs} are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. {VAEs} have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, {CIFAR} images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind {VAEs}, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="ruder_transfer_2019" class=ref>
<summary class=citation>
<a id="ruder_transfer_2019">[ruder_transfer_2019]</a> - Ruder, Sebastian, Peters, Matthew E., Swayamdipta, Swabha, Wolf, Thomas - <a href="https://www.aclweb.org/anthology/N19-5004" target="_blank"><cite>Transfer Learning in Natural Language Processing</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite ruder_transfer_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-21" id="summaryabstract-21">Summary/Abstract</a></h1>
<div>The classic supervised machine learning paradigm is based on learning in isolation, a single predictive model for a task using a single dataset. This approach requires a large number of training examples and performs best for well-defined and narrow tasks. Transfer learning refers to a set of methods that extend this approach by leveraging data from additional domains or tasks to train a model with better generalization properties. Over the last two years, the field of Natural Language Processing ({NLP}) has witnessed the emergence of several transfer learning methods and architectures which significantly improved upon the state-of-the-art on a wide range of {NLP} tasks. These improvements together with the wide availability and ease of integration of these methods are reminiscent of the factors that led to the success of pretrained word embeddings and {ImageNet} pretraining in computer vision, and indicate that these methods will likely become a common tool in the {NLP} landscape as well as an important research direction. We will present an overview of modern transfer learning methods in {NLP}, how models are pre-trained, what information the representations they learn capture, and review examples and case studies on how these models can be integrated and adapted in downstream {NLP} tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="salimans_weight_2016" class=ref>
<summary class=citation>
<a id="salimans_weight_2016">[salimans_weight_2016]</a> - Salimans, Tim, Kingma, Diederik P. - <a href="http://arxiv.org/abs/1602.07868" target="_blank"><cite>Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks</cite></a>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite salimans_weight_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-22" id="summaryabstract-22">Summary/Abstract</a></h1>
<div>We present weight normalization: a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction. By reparameterizing the weights in this way we improve the conditioning of the optimization problem and we speed up convergence of stochastic gradient descent. Our reparameterization is inspired by batch normalization but does not introduce any dependencies between the examples in a minibatch. This means that our method can also be applied successfully to recurrent models such as {LSTMs} and to noise-sensitive applications such as deep reinforcement learning or generative models, for which batch normalization is less well suited. Although our method is much simpler, it still provides much of the speed-up of full batch normalization. In addition, the computational overhead of our method is lower, permitting more optimization steps to be taken in the same amount of time. We demonstrate the usefulness of our method on applications in supervised image recognition, generative modelling, and deep reinforcement learning.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="shaw_self-attention_2018" class=ref>
<summary class=citation>
<a id="shaw_self-attention_2018">[shaw_self-attention_2018]</a> - Shaw, Peter, Uszkoreit, Jakob, Vaswani, Ashish - <a href="http://arxiv.org/abs/1803.02155" target="_blank"><cite>Self-Attention with Relative Position Representations</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite shaw_self-attention_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-23" id="summaryabstract-23">Summary/Abstract</a></h1>
<div>Relying entirely on an attention mechanism, the Transformer introduced by Vaswani et al. (2017) achieves state-of-the-art results for machine translation. In contrast to recurrent and convolutional neural networks, it does not explicitly model relative or absolute position information in its structure. Instead, it requires adding representations of absolute positions to its inputs. In this work we present an alternative approach, extending the self-attention mechanism to efficiently consider representations of the relative positions, or distances between sequence elements. On the {WMT} 2014 English-to-German and English-to-French translation tasks, this approach yields improvements of 1.3 {BLEU} and 0.3 {BLEU} over absolute position representations, respectively. Notably, we observe that combining relative and absolute position representations yields no further improvement in translation quality. We describe an efficient implementation of our method and cast it as an instance of relation-aware self-attention mechanisms that can generalize to arbitrary graph-labeled inputs.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="kemker_fearnet_2018" class=ref>
<summary class=citation>
<a id="kemker_fearnet_2018">[kemker_fearnet_2018]</a> - Kemker, Ronald, Kanan, Christopher - <a href="https://openreview.net/forum?id&#x3D;SJ1Xmf-Rb" target="_blank"><cite>{FearNet}: Brain-Inspired Model for Incremental Learning</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite kemker_fearnet_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-24" id="summaryabstract-24">Summary/Abstract</a></h1>
<div>{FearNet} is a memory efficient neural-network, inspired by memory formation in the mammalian brain, that is capable of incremental class learning without catastrophic forgetting.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="arute_quantum_2019" class=ref>
<summary class=citation>
<a id="arute_quantum_2019">[arute_quantum_2019]</a> - Arute, Frank, Arya, Kunal, Babbush, Ryan, Bacon, Dave, Bardin, Joseph C., Barends, Rami, Biswas, Rupak, Boixo, Sergio, Br, ao, Fern, o G. S. L., Buell, David A., Burkett, Brian, Chen, Yu, Chen, Zijun, Chiaro, Ben, Collins, Roberto, Courtney, William, Dunsworth, Andrew, Farhi, Edward, Foxen, Brooks, Fowler, Austin, Gidney, Craig, Giustina, Marissa, Graff, Rob, Guerin, Keith, Habegger, Steve, Harrigan, Matthew P., Hartmann, Michael J., Ho, Alan, Hoffmann, Markus, Huang, Trent, Humble, Travis S., Isakov, Sergei V., Jeffrey, Evan, Jiang, Zhang, Kafri, Dvir, Kechedzhi, Kostyantyn, Kelly, Julian, Klimov, Paul V., Knysh, Sergey, Korotkov, Alex, er, Kostritsa, Fedor, L, huis, David, Lindmark, Mike, Lucero, Erik, Lyakh, Dmitry, M, rà, Salvatore, {McClean}, Jarrod R., {McEwen}, Matthew, Megrant, Anthony, Mi, Xiao, Michielsen, Kristel, Mohseni, Masoud, Mutus, Josh, Naaman, Ofer, Neeley, Matthew, Neill, Charles, Niu, Murphy Yuezhen, Ostby, Eric, Petukhov, Andre, Platt, John C., Quintana, Chris, Rieffel, Eleanor G., Roushan, Pedram, Rubin, Nicholas C., Sank, Daniel, Satzinger, Kevin J., Smelyanskiy, Vadim, Sung, Kevin J., Trevithick, Matthew D., Vainsencher, Amit, Villalonga, Benjamin, White, Theodore, Yao, Z. Jamie, Yeh, Ping, Zalcman, Adam, Neven, Hartmut, Martinis, John M. - <a href="http://www.nature.com/articles/s41586-019-1666-5" target="_blank"><cite>Quantum supremacy using a programmable superconducting processor</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite arute_quantum_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-25" id="summaryabstract-25">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="child_generating_2019-1" class=ref>
<summary class=citation>
<a id="child_generating_2019-1">[child_generating_2019-1]</a> - Child, Rewon, Gray, Scott, Radford, Alec, Sutskever, Ilya - <a href="http://arxiv.org/abs/1904.10509" target="_blank"><cite>Generating Long Sequences with Sparse Transformers</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite child_generating_2019-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-26" id="summaryabstract-26">Summary/Abstract</a></h1>
<div>Transformers are powerful sequence models, but require time and memory that grows quadratically with the sequence length. In this paper we introduce sparse factorizations of the attention matrix which reduce this to \$O(n {\textbackslash}sqrt\{n\})\$. We also introduce a) a variation on architecture and initialization to train deeper networks, b) the recomputation of attention matrices to save memory, and c) fast attention kernels for training. We call networks with these changes Sparse Transformers, and show they can model sequences tens of thousands of timesteps long using hundreds of layers. We use the same architecture to model images, audio, and text from raw bytes, setting a new state of the art for density modeling of Enwik8, {CIFAR}-10, and {ImageNet}-64. We generate unconditional samples that demonstrate global coherence and great diversity, and show it is possible in principle to use self-attention to model sequences of length one million or more.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sculley_hidden_2015" class=ref>
<summary class=citation>
<a id="sculley_hidden_2015">[sculley_hidden_2015]</a> - Sculley, D., Holt, Gary, Golovin, Daniel, Davydov, Eugene, Phillips, Todd, Ebner, Dietmar, Chaudhary, Vinay, Young, Michael, Crespo, Jean-François, Dennison, Dan - <a href="http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf" target="_blank"><cite>Hidden Technical Debt in Machine Learning Systems</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite sculley_hidden_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-27" id="summaryabstract-27">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="child_generating_2019" class=ref>
<summary class=citation>
<a id="child_generating_2019">[child_generating_2019]</a> - Child, Rewon, Gray, Scott, Radford, Alec, Sutskever, Ilya - <a href="http://arxiv.org/abs/1904.10509" target="_blank"><cite>Generating Long Sequences with Sparse Transformers</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite child_generating_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-28" id="summaryabstract-28">Summary/Abstract</a></h1>
<div>Transformers are powerful sequence models, but require time and memory that grows quadratically with the sequence length. In this paper we introduce sparse factorizations of the attention matrix which reduce this to \$O(n {\textbackslash}sqrt\{n\})\$. We also introduce a) a variation on architecture and initialization to train deeper networks, b) the recomputation of attention matrices to save memory, and c) fast attention kernels for training. We call networks with these changes Sparse Transformers, and show they can model sequences tens of thousands of timesteps long using hundreds of layers. We use the same architecture to model images, audio, and text from raw bytes, setting a new state of the art for density modeling of Enwik8, {CIFAR}-10, and {ImageNet}-64. We generate unconditional samples that demonstrate global coherence and great diversity, and show it is possible in principle to use self-attention to model sequences of length one million or more.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sanh_distilbert_2020" class=ref>
<summary class=citation>
<a id="sanh_distilbert_2020">[sanh_distilbert_2020]</a> - Sanh, Victor, Debut, Lys, re, Chaumond, Julien, Wolf, Thomas - <a href="http://arxiv.org/abs/1910.01108" target="_blank"><cite>{DistilBERT}, a distilled version of {BERT}: smaller, faster, cheaper and lighter</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite sanh_distilbert_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-29" id="summaryabstract-29">Summary/Abstract</a></h1>
<div>As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing ({NLP}), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called {DistilBERT}, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a {BERT} model by 40\%, while retaining 97\% of its language understanding capabilities and being 60\% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zhuang_comprehensive_2020" class=ref>
<summary class=citation>
<a id="zhuang_comprehensive_2020">[zhuang_comprehensive_2020]</a> - Zhuang, Fuzhen, Qi, Zhiyuan, Duan, Keyu, Xi, Dongbo, Zhu, Yongchun, Zhu, Hengshu, Xiong, Hui, He, Qing - <a href="http://arxiv.org/abs/1911.02685" target="_blank"><cite>A Comprehensive Survey on Transfer Learning</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite zhuang_comprehensive_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-30" id="summaryabstract-30">Summary/Abstract</a></h1>
<div>Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge contained in different but related source domains. In this way, the dependence on a large number of target domain data can be reduced for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances in transfer learning. Due to the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect and systematize the existing transfer learning researches, as well as to summarize and interpret the mechanisms and the strategies of transfer learning in a comprehensive way, which may help readers have a better understanding of the current research status and ideas. Unlike previous surveys, this survey paper reviews more than forty representative transfer learning approaches, especially homogeneous transfer learning approaches, from the perspectives of data and model. The applications of transfer learning are also briefly introduced. In order to show the performance of different transfer learning models, over twenty representative transfer learning models are used for experiments. The models are performed on three different datasets, i.e., Amazon Reviews, Reuters-21578, and Office-31. And the experimental results demonstrate the importance of selecting appropriate transfer learning models for different applications in practice.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="parisi_continual_2019" class=ref>
<summary class=citation>
<a id="parisi_continual_2019">[parisi_continual_2019]</a> - Parisi, German I., Kemker, Ronald, Part, Jose L., Kanan, Christopher, Wermter, Stefan - <a href="http://arxiv.org/abs/1802.07569" target="_blank"><cite>Continual Lifelong Learning with Neural Networks: A Review</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite parisi_continual_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-31" id="summaryabstract-31">Summary/Abstract</a></h1>
<div>Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="goodfellow_generative_2014" class=ref>
<summary class=citation>
<a id="goodfellow_generative_2014">[goodfellow_generative_2014]</a> - Goodfellow, Ian J., Pouget-Abadie, Jean, Mirza, Mehdi, Xu, Bing, Warde-Farley, David, Ozair, Sherjil, Courville, Aaron, Bengio, Yoshua - <a href="http://arxiv.org/abs/1406.2661" target="_blank"><cite>Generative Adversarial Networks</cite></a>. - 2014. -
<button onclick="copyToClipboard('\{\{ #cite goodfellow_generative_2014 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-32" id="summaryabstract-32">Summary/Abstract</a></h1>
<div>We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="van_de_ven_generative_2019" class=ref>
<summary class=citation>
<a id="van_de_ven_generative_2019">[van_de_ven_generative_2019]</a> - van de Ven, Gido M., Tolias, Andreas S. - <a href="http://arxiv.org/abs/1809.10635" target="_blank"><cite>Generative replay with feedback connections as a general strategy for continual learning</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite van_de_ven_generative_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-33" id="summaryabstract-33">Summary/Abstract</a></h1>
<div>A major obstacle to developing artificial intelligence applications capable of true lifelong learning is that artificial neural networks quickly or catastrophically forget previously learned tasks when trained on a new one. Numerous methods for alleviating catastrophic forgetting are currently being proposed, but differences in evaluation protocols make it difficult to directly compare their performance. To enable more meaningful comparisons, here we identified three distinct scenarios for continual learning based on whether task identity is known and, if it is not, whether it needs to be inferred. Performing the split and permuted {MNIST} task protocols according to each of these scenarios, we found that regularization-based approaches (e.g., elastic weight consolidation) failed when task identity needed to be inferred. In contrast, generative replay combined with distillation (i.e., using class probabilities as soft targets) achieved superior performance in all three scenarios. Addressing the issue of efficiency, we reduced the computational cost of generative replay by integrating the generative model into the main model by equipping it with generative feedback or backward connections. This Replay-through-Feedback approach substantially shortened training time with no or negligible loss in performance. We believe this to be an important first step towards making the powerful technique of generative replay scalable to real-world continual learning applications.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="masse_alleviating_2018" class=ref>
<summary class=citation>
<a id="masse_alleviating_2018">[masse_alleviating_2018]</a> - Masse, Nicolas Y., Grant, Gregory D., Freedman, David J. - <a href="https://www.pnas.org/content/115/44/E10467" target="_blank"><cite>Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite masse_alleviating_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-34" id="summaryabstract-34">Summary/Abstract</a></h1>
<div>Humans and most animals can learn new tasks without forgetting old ones. However, training artificial neural networks ({ANNs}) on new tasks typically causes them to forget previously learned tasks. This phenomenon is the result of “catastrophic forgetting,” in which training an {ANN} disrupts connection weights that were important for solving previous tasks, degrading task performance. Several recent studies have proposed methods to stabilize connection weights of {ANNs} that are deemed most important for solving a task, which helps alleviate catastrophic forgetting. Here, drawing inspiration from algorithms that are believed to be implemented in vivo, we propose a complementary method: adding a context-dependent gating signal, such that only sparse, mostly nonoverlapping patterns of units are active for any one task. This method is easy to implement, requires little computational overhead, and allows {ANNs} to maintain high performance across large numbers of sequentially presented tasks, particularly when combined with weight stabilization. We show that this method works for both feedforward and recurrent network architectures, trained using either supervised or reinforcement-based learning. This suggests that using multiple, complementary methods, akin to what is believed to occur in the brain, can be a highly effective strategy to support continual learning.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zhao_how_2020" class=ref>
<summary class=citation>
<a id="zhao_how_2020">[zhao_how_2020]</a> - Zhao, Yiyun, Bethard, Steven - <a href="https://www.aclweb.org/anthology/2020.acl-main.429" target="_blank"><cite>How does {BERT}&#x27;s attention change when you fine-tune? An analysis methodology and a case study in negation scope</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite zhao_how_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-35" id="summaryabstract-35">Summary/Abstract</a></h1>
<div>Large pretrained language models like {BERT}, after fine-tuning to a downstream task, have achieved high performance on a variety of {NLP} problems. Yet explaining their decisions is difficult despite recent work probing their internal representations. We propose a procedure and analysis methods that take a hypothesis of how a transformer-based model might encode a linguistic phenomenon, and test the validity of that hypothesis based on a comparison between knowledge-related downstream tasks with downstream control tasks, and measurement of cross-dataset consistency. We apply this methodology to test {BERT} and {RoBERTa} on a hypothesis that some attention heads will consistently attend from a word in negation scope to the negation cue. We find that after fine-tuning {BERT} and {RoBERTa} on a negation scope task, the average attention head improves its sensitivity to negation and its attention consistency across negation datasets compared to the pre-trained models. However, only the base models (not the large models) improve compared to a control task, indicating there is evidence for a shallow encoding of negation only in the base models.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="metz_genius_2021" class=ref>
<summary class=citation>
<a id="metz_genius_2021">[metz_genius_2021]</a> - Metz, Cade - <cite>Genius Makers: The Mavericks Who Brought {AI} to Google, Facebook, and the World</cite>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite metz_genius_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-36" id="summaryabstract-36">Summary/Abstract</a></h1>
<div>This colorful page-turner puts artificial intelligence into a human perspective. Through the lives of Geoff Hinton and other major players, Metz explains this transformative technology and makes the quest thrilling.—Walter Isaacson, author of The Code {BreakerRecipient} of starred reviews in both Kirkus and Library {JournalTHE} {UNTOLD} {TECH} {STORY} {OF} {OUR} {TIME}   What does it mean to be smart? To be human? What do we really want from life and the intelligence we have, or might create?   With deep and exclusive reporting, across hundreds of interviews, New York Times Silicon Valley journalist Cade Metz brings you into the rooms where these questions are being answered. Where an extraordinarily powerful new artificial intelligence has been built into our biggest companies, our social discourse, and our daily lives, with few of us even noticing.     Long dismissed as a technology of the distant future, artificial intelligence was a project consigned to the fringes of the scientific community. Then two researchers changed everything. One was a sixty-four-year-old computer science professor who didn’t drive and didn’t fly because he could no longer sit down—but still made his way across North America for the moment that would define a new age of technology. The other was a thirty-six-year-old neuroscientist and chess prodigy who laid claim to being the greatest game player of all time before vowing to build a machine that could do anything the human brain could do.   They took two very different paths to that lofty goal, and they disagreed on how quickly it would arrive. But both were soon drawn into the heart of the tech industry. Their ideas drove a new kind of arms race, spanning Google, Microsoft, Facebook, and {OpenAI}, a new lab founded by Silicon Valley kingpin Elon Musk. But some believed that China would beat them all to the finish line.   Genius Makers dramatically presents the fierce conflict between national interests, shareholder value, the pursuit of scientific knowledge, and the very human concerns about privacy, security, bias, and prejudice. Like a great Victorian novel, this world of eccentric, brilliant, often unimaginably yet suddenly wealthy characters draws you into the most profound moral questions we can ask. And like a great mystery, it presents the story and facts that lead to a core, vital question:   How far will we let it go?</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="geiger_scaling_2020" class=ref>
<summary class=citation>
<a id="geiger_scaling_2020">[geiger_scaling_2020]</a> - Geiger, Mario, Jacot, Arthur, Spigler, Stefano, Gabriel, Franck, Sagun, Levent, d&#x27;Ascoli, Stéphane, Biroli, Giulio, Hongler, Clément, Wyart, Matthieu - <a href="http://arxiv.org/abs/1901.01608" target="_blank"><cite>Scaling description of generalization with number of parameters in deep learning</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite geiger_scaling_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-37" id="summaryabstract-37">Summary/Abstract</a></h1>
<div>Supervised deep learning involves the training of neural networks with a large number \$N\$ of parameters. For large enough \$N\$, in the so-called over-parametrized regime, one can essentially fit the training data points. Sparsity-based arguments would suggest that the generalization error increases as \$N\$ grows past a certain threshold \$N{\textasciicircum}\{*\}\$. Instead, empirical studies have shown that in the over-parametrized regime, generalization error keeps decreasing with \$N\$. We resolve this paradox through a new framework. We rely on the so-called Neural Tangent Kernel, which connects large neural nets to kernel methods, to show that the initialization causes finite-size random fluctuations \${\textbackslash}{\textbar}f\_\{N\}-{\textbackslash}bar\{f\}\_\{N\}{\textbackslash}{\textbar}{\textbackslash}sim N{\textasciicircum}\{-1/4\}\$ of the neural net output function \$f\_\{N\}\$ around its expectation \${\textbackslash}bar\{f\}\_\{N\}\$. These affect the generalization error \${\textbackslash}epsilon\_\{N\}\$ for classification: under natural assumptions, it decays to a plateau value \${\textbackslash}epsilon\_\{{\textbackslash}infty\}\$ in a power-law fashion \${\textbackslash}sim N{\textasciicircum}\{-1/2\}\$. This description breaks down at a so-called jamming transition \$N&#x3D;N{\textasciicircum}\{*\}\$. At this threshold, we argue that \${\textbackslash}{\textbar}f\_\{N\}{\textbackslash}{\textbar}\$ diverges. This result leads to a plausible explanation for the cusp in test error known to occur at \$N{\textasciicircum}\{*\}\$. Our results are confirmed by extensive empirical observations on the {MNIST} and {CIFAR} image datasets. Our analysis finally suggests that, given a computational envelope, the smallest generalization error is obtained using several networks of intermediate sizes, just beyond \$N{\textasciicircum}\{*\}\$, and averaging their outputs.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="venkatesan_strategy_2017" class=ref>
<summary class=citation>
<a id="venkatesan_strategy_2017">[venkatesan_strategy_2017]</a> - Venkatesan, Ragav, Venkateswara, Hemanth, Panchanathan, Sethuraman, Li, Baoxin - <a href="http://arxiv.org/abs/1705.00744" target="_blank"><cite>A Strategy for an Uncompromising Incremental Learner</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite venkatesan_strategy_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-38" id="summaryabstract-38">Summary/Abstract</a></h1>
<div>Multi-class supervised learning systems require the knowledge of the entire range of labels they predict. Often when learnt incrementally, they suffer from catastrophic forgetting. To avoid this, generous leeways have to be made to the philosophy of incremental learning that either forces a part of the machine to not learn, or to retrain the machine again with a selection of the historic data. While these hacks work to various degrees, they do not adhere to the spirit of incremental learning. In this article, we redefine incremental learning with stringent conditions that do not allow for any undesirable relaxations and assumptions. We design a strategy involving generative models and the distillation of dark knowledge as a means of hallucinating data along with appropriate targets from past distributions. We call this technique, phantom sampling.We show that phantom sampling helps avoid catastrophic forgetting during incremental learning. Using an implementation based on deep neural networks, we demonstrate that phantom sampling dramatically avoids catastrophic forgetting. We apply these strategies to competitive multi-class incremental learning of deep neural networks. Using various benchmark datasets and through our strategy, we demonstrate that strict incremental learning could be achieved. We further put our strategy to test on challenging cases, including cross-domain increments and incrementing on a novel label space. We also propose a trivial extension to unbounded-continual learning and identify potential for future development.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="kirkpatrick_overcoming_2017" class=ref>
<summary class=citation>
<a id="kirkpatrick_overcoming_2017">[kirkpatrick_overcoming_2017]</a> - Kirkpatrick, James, Pascanu, Razvan, Rabinowitz, Neil, Veness, Joel, Desjardins, Guillaume, Rusu, Andrei A., Milan, Kieran, Quan, John, Ramalho, Tiago, Grabska-Barwinska, Agnieszka, Hassabis, Demis, Clopath, Claudia, Kumaran, Dharshan, Hadsell, Raia - <a href="http://arxiv.org/abs/1612.00796" target="_blank"><cite>Overcoming catastrophic forgetting in neural networks</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite kirkpatrick_overcoming_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-39" id="summaryabstract-39">Summary/Abstract</a></h1>
<div>The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the {MNIST} hand written digit dataset and by learning several Atari 2600 games sequentially.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="dathathri_plug_2020" class=ref>
<summary class=citation>
<a id="dathathri_plug_2020">[dathathri_plug_2020]</a> - Dathathri, Sumanth, Madotto, Andrea, Lan, Janice, Hung, Jane, Frank, Eric, Molino, Piero, Yosinski, Jason, Liu, Rosanne - <a href="http://arxiv.org/abs/1912.02164" target="_blank"><cite>Plug and Play Language Models: A Simple Approach to Controlled Text Generation</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite dathathri_plug_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-40" id="summaryabstract-40">Summary/Abstract</a></h1>
<div>Large transformer-based language models ({LMs}) trained on huge text corpora have shown unparalleled generation capabilities. However, controlling attributes of the generated language (e.g. switching topic or sentiment) is difficult without modifying the model architecture or fine-tuning on attribute-specific data and entailing the significant cost of retraining. We propose a simple alternative: the Plug and Play Language Model ({PPLM}) for controllable language generation, which combines a pretrained {LM} with one or more simple attribute classifiers that guide text generation without any further training of the {LM}. In the canonical scenario we present, the attribute models are simple classifiers consisting of a user-specified bag of words or a single learned layer with 100,000 times fewer parameters than the {LM}. Sampling entails a forward and backward pass in which gradients from the attribute model push the {LM}&#x27;s hidden activations and thus guide the generation. Model samples demonstrate control over a range of topics and sentiment styles, and extensive automated and human annotated evaluations show attribute alignment and fluency. {PPLMs} are flexible in that any combination of differentiable attribute models may be used to steer text generation, which will allow for diverse and creative applications beyond the examples given in this paper.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="brunner_identifiability_2020" class=ref>
<summary class=citation>
<a id="brunner_identifiability_2020">[brunner_identifiability_2020]</a> - Brunner, Gino, Liu, Yang, Pascual, Damián, Richter, Oliver, Ciaramita, Massimiliano, Wattenhofer, Roger - <a href="http://arxiv.org/abs/1908.04211" target="_blank"><cite>On Identifiability in Transformers</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite brunner_identifiability_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-41" id="summaryabstract-41">Summary/Abstract</a></h1>
<div>In this paper we delve deep in the Transformer architecture by investigating two of its core components: self-attention and contextual embeddings. In particular, we study the identifiability of attention weights and token embeddings, and the aggregation of context into hidden tokens. We show that, for sequences longer than the attention head dimension, attention weights are not identifiable. We propose effective attention as a complementary tool for improving explanatory interpretations based on attention. Furthermore, we show that input tokens retain to a large degree their identity across the model. We also find evidence suggesting that identity information is mainly encoded in the angle of the embeddings and gradually decreases with depth. Finally, we demonstrate strong mixing of input information in the generation of contextual embeddings by means of a novel quantification method based on gradient attribution. Overall, we show that self-attention distributions are not directly interpretable and present tools to better understand and further investigate Transformer models.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="xie_adversarial_nodate" class=ref>
<summary class=citation>
<a id="xie_adversarial_nodate">[xie_adversarial_nodate]</a> - Xie, Cihang, Tan, Mingxing, Gong, Boqing, Wang, Jiang, Yuille, Alan, Le, Quoc V - <cite>Adversarial Examples Improve Image Recognition</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite xie_adversarial_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-42" id="summaryabstract-42">Summary/Abstract</a></h1>
<div>Adversarial examples are commonly viewed as a threat to {ConvNets}. Here we present an opposite perspective: adversarial examples can be used to improve image recognition models if harnessed in the right manner. We propose {AdvProp}, an enhanced adversarial training scheme which treats adversarial examples as additional examples, to prevent overﬁtting. Key to our method is the usage of a separate auxiliary batch norm for adversarial examples, as they have different underlying distributions to normal examples. We show that {AdvProp} improves a wide range of models on various image recognition tasks and performs better when the models are bigger. For instance, by applying {AdvProp} to the latest {EfﬁcientNet}-B7 [28] on {ImageNet}, we achieve signiﬁcant improvements on {ImageNet} (+0.7\%), {ImageNet}-C (+6.5\%), {ImageNet}-A (+7.0\%), {StylizedImageNet} (+4.8\%). With an enhanced {EfﬁcientNet}-B8, our method achieves the state-of-the-art 85.5\% {ImageNet} top-1 accuracy without extra data. This result even surpasses the best model in [20] which is trained with 3.5B Instagram images (∼3000× more than {ImageNet}) and ∼9.4× more parameters. Models are available at https://github.com/tensorflow/tpu/tree/ master/models/official/efficientnet.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="alyafeai_survey_2020" class=ref>
<summary class=citation>
<a id="alyafeai_survey_2020">[alyafeai_survey_2020]</a> - Alyafeai, Zaid, {AlShaibani}, Maged Saeed, Ahmad, Irfan - <a href="http://arxiv.org/abs/2007.04239" target="_blank"><cite>A Survey on Transfer Learning in Natural Language Processing</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite alyafeai_survey_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-43" id="summaryabstract-43">Summary/Abstract</a></h1>
<div>Deep learning models usually require a huge amount of data. However, these large datasets are not always attainable. This is common in many challenging {NLP} tasks. Consider Neural Machine Translation, for instance, where curating such large datasets may not be possible specially for low resource languages. Another limitation of deep learning models is the demand for huge computing resources. These obstacles motivate research to question the possibility of knowledge transfer using large trained models. The demand for transfer learning is increasing as many large models are emerging. In this survey, we feature the recent transfer learning advances in the field of {NLP}. We also provide a taxonomy for categorizing different transfer learning approaches from the literature.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sutton_reinforcement_2018" class=ref>
<summary class=citation>
<a id="sutton_reinforcement_2018">[sutton_reinforcement_2018]</a> - Sutton, Richard S., Barto, Andrew G. - <cite>Reinforcement Learning, second edition: An Introduction</cite>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite sutton_reinforcement_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-44" id="summaryabstract-44">Summary/Abstract</a></h1>
<div>The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence.Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field&#x27;s key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics.Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including {UCB}, Expected Sarsa, and Double Learning. Part {II} extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part {III} has new chapters on reinforcement learning&#x27;s relationships to psychology and neuroscience, as well as an updated case-studies chapter including {AlphaGo} and {AlphaGo} Zero, Atari game playing, and {IBM} Watson&#x27;s wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_using_nodate" class=ref>
<summary class=citation>
<a id="noauthor_using_nodate">[noauthor_using_nodate]</a> - N/A - <a href="https://www.confluent.io/blog/using-apache-kafka-drive-cutting-edge-machine-learning" target="_blank"><cite>Using Apache Kafka to Drive Cutting-Edge Machine Learning {\textbar} Confluent</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_using_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-45" id="summaryabstract-45">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_enforcing_nodate" class=ref>
<summary class=citation>
<a id="noauthor_enforcing_nodate">[noauthor_enforcing_nodate]</a> - N/A - <a href="https://stackoverflow.com/questions/19534896/enforcing-python-version-in-setup-py" target="_blank"><cite>Enforcing python version in setup.py</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_enforcing_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-46" id="summaryabstract-46">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wei_nezha_2019" class=ref>
<summary class=citation>
<a id="wei_nezha_2019">[wei_nezha_2019]</a> - Wei, Junqiu, Ren, Xiaozhe, Li, Xiaoguang, Huang, Wenyong, Liao, Yi, Wang, Yasheng, Lin, Jiashu, Jiang, Xin, Chen, Xiao, Liu, Qun - <a href="http://arxiv.org/abs/1909.00204" target="_blank"><cite>{NEZHA}: Neural Contextualized Representation for Chinese Language Understanding</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite wei_nezha_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-47" id="summaryabstract-47">Summary/Abstract</a></h1>
<div>The pre-trained language models have achieved great successes in various natural language understanding ({NLU}) tasks due to its capacity to capture the deep contextualized information in text by pre-training on large-scale corpora. In this technical report, we present our practice of pre-training language models named {NEZHA} ({NEural} {contextualiZed} representation for {CHinese} {lAnguage} understanding) on Chinese corpora and finetuning for the Chinese {NLU} tasks. The current version of {NEZHA} is based on {BERT} with a collection of proven improvements, which include Functional Relative Positional Encoding as an effective positional encoding scheme, Whole Word Masking strategy, Mixed Precision Training and the {LAMB} Optimizer in training the models. The experimental results show that {NEZHA} achieves the state-of-the-art performances when finetuned on several representative Chinese tasks, including named entity recognition (People&#x27;s Daily {NER}), sentence matching ({LCQMC}), Chinese sentiment classification ({ChnSenti}) and natural language inference ({XNLI}).</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="li_learning_2017" class=ref>
<summary class=citation>
<a id="li_learning_2017">[li_learning_2017]</a> - Li, Zhizhong, Hoiem, Derek - <a href="http://arxiv.org/abs/1606.09282" target="_blank"><cite>Learning without Forgetting</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite li_learning_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-48" id="summaryabstract-48">Summary/Abstract</a></h1>
<div>When building a unified vision system or gradually adding new capabilities to a system, the usual assumption is that training data for all tasks is always available. However, as the number of tasks grows, storing and retraining on such data becomes infeasible. A new problem arises where we add new capabilities to a Convolutional Neural Network ({CNN}), but the training data for its existing capabilities are unavailable. We propose our Learning without Forgetting method, which uses only new task data to train the network while preserving the original capabilities. Our method performs favorably compared to commonly used feature extraction and fine-tuning adaption techniques and performs similarly to multitask learning that uses original task data we assume unavailable. A more surprising observation is that Learning without Forgetting may be able to replace fine-tuning with similar old and new task datasets for improved new task performance.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="miller_explanation_2018" class=ref>
<summary class=citation>
<a id="miller_explanation_2018">[miller_explanation_2018]</a> - Miller, Tim - <a href="http://arxiv.org/abs/1706.07269" target="_blank"><cite>Explanation in Artificial Intelligence: Insights from the Social Sciences</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite miller_explanation_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-49" id="summaryabstract-49">Summary/Abstract</a></h1>
<div>There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to make their algorithms more understandable. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers&#x27; intuition of what constitutes a &#x60;good&#x27; explanation. There exists vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations towards the explanation process. This paper argues that the field of explainable artificial intelligence should build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_more_nodate" class=ref>
<summary class=citation>
<a id="noauthor_more_nodate">[noauthor_more_nodate]</a> - N/A - <a href="http://ai.googleblog.com/2020/03/more-efficient-nlp-model-pre-training.html" target="_blank"><cite>More Efficient {NLP} Model Pre-training with {ELECTRA}</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_more_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-50" id="summaryabstract-50">Summary/Abstract</a></h1>
<div>Posted by Kevin Clark, Student Researcher and Thang Luong, Senior Research Scientist, Google Research, Brain Team   Recent advances in langu...</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="yang_finbert_2020" class=ref>
<summary class=citation>
<a id="yang_finbert_2020">[yang_finbert_2020]</a> - Yang, Yi, {UY}, Mark Christopher Siy, Huang, Allen - <a href="http://arxiv.org/abs/2006.08097" target="_blank"><cite>{FinBERT}: A Pretrained Language Model for Financial Communications</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite yang_finbert_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-51" id="summaryabstract-51">Summary/Abstract</a></h1>
<div>Contextual pretrained language models, such as {BERT} (Devlin et al., 2019), have made significant breakthrough in various {NLP} tasks by training on large scale of unlabeled text re-sources.Financial sector also accumulates large amount of financial communication text.However, there is no pretrained finance specific language models available. In this work,we address the need by pretraining a financial domain specific {BERT} models, {FinBERT}, using a large scale of financial communication corpora. Experiments on three financial sentiment classification tasks confirm the advantage of {FinBERT} over generic domain {BERT} model. The code and pretrained models are available at https://github.com/yya518/{FinBERT}. We hope this will be useful for practitioners and researchers working on financial {NLP} tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="luo_have_2021" class=ref>
<summary class=citation>
<a id="luo_have_2021">[luo_have_2021]</a> - Luo, Ziyang - <a href="http://arxiv.org/abs/2102.07926" target="_blank"><cite>Have Attention Heads in {BERT} Learned Constituency Grammar?</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite luo_have_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-52" id="summaryabstract-52">Summary/Abstract</a></h1>
<div>With the success of pre-trained language models in recent years, more and more researchers focus on opening the black box of these models. Following this interest, we carry out a qualitative and quantitative analysis of constituency grammar in attention heads of {BERT} and {RoBERTa}. We employ the syntactic distance method to extract implicit constituency grammar from the attention weights of each head. Our results show that there exist heads that can induce some grammar types much better than baselines, suggesting that some heads act as a proxy for constituency grammar. We also analyze how attention heads&#x27; constituency grammar inducing ({CGI}) ability changes after fine-tuning with two kinds of tasks, including sentence meaning similarity ({SMS}) tasks and natural language inference ({NLI}) tasks. Our results suggest that {SMS} tasks decrease the average {CGI} ability of upper layers, while {NLI} tasks increase it. Lastly, we investigate the connections between {CGI} ability and natural language understanding ability on {QQP} and {MNLI} tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="peng_hierarchical_2019" class=ref>
<summary class=citation>
<a id="peng_hierarchical_2019">[peng_hierarchical_2019]</a> - Peng, Hao, Li, Jianxin, Gong, Qiran, Wang, Senzhang, He, Lifang, Li, Bo, Wang, Lihong, Yu, Philip S. - <a href="http://arxiv.org/abs/1906.04898" target="_blank"><cite>Hierarchical Taxonomy-Aware and Attentional Graph Capsule {RCNNs} for Large-Scale Multi-Label Text Classification</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite peng_hierarchical_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-53" id="summaryabstract-53">Summary/Abstract</a></h1>
<div>{CNNs}, {RNNs}, {GCNs}, and {CapsNets} have shown significant insights in representation learning and are widely used in various text mining tasks such as large-scale multi-label text classification. However, most existing deep models for multi-label text classification consider either the non-consecutive and long-distance semantics or the sequential semantics, but how to consider them both coherently is less studied. In addition, most existing methods treat output labels as independent methods, but ignore the hierarchical relations among them, leading to useful semantic information loss. In this paper, we propose a novel hierarchical taxonomy-aware and attentional graph capsule recurrent {CNNs} framework for large-scale multi-label text classification. Specifically, we first propose to model each document as a word order preserved graph-of-words and normalize it as a corresponding words-matrix representation which preserves both the non-consecutive, long-distance and local sequential semantics. Then the words-matrix is input to the proposed attentional graph capsule recurrent {CNNs} for more effectively learning the semantic features. To leverage the hierarchical relations among the class labels, we propose a hierarchical taxonomy embedding method to learn their representations, and define a novel weighted margin loss by incorporating the label representation similarity. Extensive evaluations on three datasets show that our model significantly improves the performance of large-scale multi-label text classification by comparing with state-of-the-art approaches.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wu_incremental_2018" class=ref>
<summary class=citation>
<a id="wu_incremental_2018">[wu_incremental_2018]</a> - Wu, Yue, Chen, Yinpeng, Wang, Lijuan, Ye, Yuancheng, Liu, Zicheng, Guo, Y, ong, Zhang, Zhengyou, Fu, Yun - <a href="http://arxiv.org/abs/1802.00853" target="_blank"><cite>Incremental Classifier Learning with Generative Adversarial Networks</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite wu_incremental_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-54" id="summaryabstract-54">Summary/Abstract</a></h1>
<div>In this paper, we address the incremental classifier learning problem, which suffers from catastrophic forgetting. The main reason for catastrophic forgetting is that the past data are not available during learning. Typical approaches keep some exemplars for the past classes and use distillation regularization to retain the classification capability on the past classes and balance the past and new classes. However, there are four main problems with these approaches. First, the loss function is not efficient for classification. Second, there is unbalance problem between the past and new classes. Third, the size of pre-decided exemplars is usually limited and they might not be distinguishable from unseen new classes. Forth, the exemplars may not be allowed to be kept for a long time due to privacy regulations. To address these problems, we propose (a) a new loss function to combine the cross-entropy loss and distillation loss, (b) a simple way to estimate and remove the unbalance between the old and new classes , and (c) using Generative Adversarial Networks ({GANs}) to generate historical data and select representative exemplars during generation. We believe that the data generated by {GANs} have much less privacy issues than real images because {GANs} do not directly copy any real image patches. We evaluate the proposed method on {CIFAR}-100, Flower-102, and {MS}-Celeb-1M-Base datasets and extensive experiments demonstrate the effectiveness of our method.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="brown_language_2020" class=ref>
<summary class=citation>
<a id="brown_language_2020">[brown_language_2020]</a> - Brown, Tom B., Mann, Benjamin, Ryder, Nick, Subbiah, Melanie, Kaplan, Jared, Dhariwal, Prafulla, Neelakantan, Arvind, Shyam, Pranav, Sastry, Girish, Askell, Am, a, Agarwal, S, hini, Herbert-Voss, Ariel, Krueger, Gretchen, Henighan, Tom, Child, Rewon, Ramesh, Aditya, Ziegler, Daniel M., Wu, Jeffrey, Winter, Clemens, Hesse, Christopher, Chen, Mark, Sigler, Eric, Litwin, Mateusz, Gray, Scott, Chess, Benjamin, Clark, Jack, Berner, Christopher, {McC, lish}, Sam, Radford, Alec, Sutskever, Ilya, Amodei, Dario - <a href="http://arxiv.org/abs/2005.14165" target="_blank"><cite>Language Models are Few-Shot Learners</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite brown_language_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-55" id="summaryabstract-55">Summary/Abstract</a></h1>
<div>Recent work has demonstrated substantial gains on many {NLP} tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current {NLP} systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train {GPT}-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, {GPT}-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. {GPT}-3 achieves strong performance on many {NLP} datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where {GPT}-3&#x27;s few-shot learning still struggles, as well as some datasets where {GPT}-3 faces methodological issues related to training on large web corpora. Finally, we find that {GPT}-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of {GPT}-3 in general.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="cheng_long_2016" class=ref>
<summary class=citation>
<a id="cheng_long_2016">[cheng_long_2016]</a> - Cheng, Jianpeng, Dong, Li, Lapata, Mirella - <a href="http://arxiv.org/abs/1601.06733" target="_blank"><cite>Long Short-Term Memory-Networks for Machine Reading</cite></a>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite cheng_long_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-56" id="summaryabstract-56">Summary/Abstract</a></h1>
<div>In this paper we address the question of how to render sequence-level networks better at handling structured input. We propose a machine reading simulator which processes text incrementally from left to right and performs shallow reasoning with memory and attention. The reader extends the Long Short-Term Memory architecture with a memory network in place of a single memory cell. This enables adaptive memory usage during recurrence with neural attention, offering a way to weakly induce relations among tokens. The system is initially designed to process a single sequence but we also demonstrate how to integrate it with an encoder-decoder architecture. Experiments on language modeling, sentiment analysis, and natural language inference show that our model matches or outperforms the state of the art.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wu_lite_2020" class=ref>
<summary class=citation>
<a id="wu_lite_2020">[wu_lite_2020]</a> - Wu, Zhanghao, Liu, Zhijian, Lin, Ji, Lin, Yujun, Han, Song - <a href="http://arxiv.org/abs/2004.11886" target="_blank"><cite>Lite Transformer with Long-Short Range Attention</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite wu_lite_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-57" id="summaryabstract-57">Summary/Abstract</a></h1>
<div>Transformer has become ubiquitous in natural language processing (e.g., machine translation, question answering); however, it requires enormous amount of computations to achieve high performance, which makes it not suitable for mobile applications that are tightly constrained by the hardware resources and battery. In this paper, we present an efficient mobile {NLP} architecture, Lite Transformer to facilitate deploying mobile {NLP} applications on edge devices. The key primitive is the Long-Short Range Attention ({LSRA}), where one group of heads specializes in the local context modeling (by convolution) while another group specializes in the long-distance relationship modeling (by attention). Such specialization brings consistent improvement over the vanilla transformer on three well-established language tasks: machine translation, abstractive summarization, and language modeling. Under constrained resources (500M/100M {MACs}), Lite Transformer outperforms transformer on {WMT}&#x27;14 English-French by 1.2/1.7 {BLEU}, respectively. Lite Transformer reduces the computation of transformer base model by 2.5x with 0.3 {BLEU} score degradation. Combining with pruning and quantization, we further compressed the model size of Lite Transformer by 18.2x. For language modeling, Lite Transformer achieves 1.8 lower perplexity than the transformer at around 500M {MACs}. Notably, Lite Transformer outperforms the {AutoML}-based Evolved Transformer by 0.5 higher {BLEU} for the mobile {NLP} setting without the costly architecture search that requires more than 250 {GPU} years. Code has been made available at https://github.com/mit-han-lab/lite-transformer.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="keskar_ctrl_2019" class=ref>
<summary class=citation>
<a id="keskar_ctrl_2019">[keskar_ctrl_2019]</a> - Keskar, Nitish Shirish, {McCann}, Bryan, Varshney, Lav R., Xiong, Caiming, Socher, Richard - <a href="http://arxiv.org/abs/1909.05858" target="_blank"><cite>{CTRL}: A Conditional Transformer Language Model for Controllable Generation</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite keskar_ctrl_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-58" id="summaryabstract-58">Summary/Abstract</a></h1>
<div>Large-scale language models show promising text generation capabilities, but users cannot easily control particular aspects of the generated text. We release {CTRL}, a 1.63 billion-parameter conditional transformer language model, trained to condition on control codes that govern style, content, and task-specific behavior. Control codes were derived from structure that naturally co-occurs with raw text, preserving the advantages of unsupervised learning while providing more explicit control over text generation. These codes also allow {CTRL} to predict which parts of the training data are most likely given a sequence. This provides a potential method for analyzing large amounts of data via model-based source attribution. We have released multiple full-sized, pretrained versions of {CTRL} at https://github.com/salesforce/ctrl.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="ribeiro_beyond_2020-1" class=ref>
<summary class=citation>
<a id="ribeiro_beyond_2020-1">[ribeiro_beyond_2020-1]</a> - Ribeiro, Marco Tulio, Wu, Tongshuang, Guestrin, Carlos, Singh, Sameer - <a href="https://www.aclweb.org/anthology/2020.acl-main.442" target="_blank"><cite>Beyond Accuracy: Behavioral Testing of {NLP} Models with {CheckList}</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite ribeiro_beyond_2020-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-59" id="summaryabstract-59">Summary/Abstract</a></h1>
<div>Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of {NLP} models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce {CheckList}, a task-agnostic methodology for testing {NLP} models. {CheckList} includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of {CheckList} with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, {NLP} practitioners with {CheckList} created twice as many tests, and found almost three times as many bugs as users without it.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="karpathy_large-scale_nodate" class=ref>
<summary class=citation>
<a id="karpathy_large-scale_nodate">[karpathy_large-scale_nodate]</a> - Karpathy, Andrej, Toderici, George, Shetty, Sanketh, Leung, Thomas, Sukthankar, Rahul, Fei-Fei, Li - <cite>Large-scale Video Classiﬁcation with Convolutional Neural Networks</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite karpathy_large-scale_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-60" id="summaryabstract-60">Summary/Abstract</a></h1>
<div>Convolutional Neural Networks ({CNNs}) have been established as a powerful class of models for image recognition problems. Encouraged by these results, we provide an extensive empirical evaluation of {CNNs} on largescale video classiﬁcation using a new dataset of 1 million {YouTube} videos belonging to 487 classes. We study multiple approaches for extending the connectivity of a {CNN} in time domain to take advantage of local spatio-temporal information and suggest a multiresolution, foveated architecture as a promising way of speeding up the training. Our best spatio-temporal networks display signiﬁcant performance improvements compared to strong feature-based baselines (55.3\% to 63.9\%), but only a surprisingly modest improvement compared to single-frame models (59.3\% to 60.9\%). We further study the generalization performance of our best model by retraining the top layers on the {UCF}101 Action Recognition dataset and observe signiﬁcant performance improvements compared to the {UCF}-101 baseline model (63.3\% up from 43.9\%).</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="minsky_k-lines_1979" class=ref>
<summary class=citation>
<a id="minsky_k-lines_1979">[minsky_k-lines_1979]</a> - Minsky, Marvin - <a href="https://dspace.mit.edu/handle/1721.1/5739" target="_blank"><cite>K-Lines: A Theory of Memory</cite></a>. - 1979. -
<button onclick="copyToClipboard('\{\{ #cite minsky_k-lines_1979 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-61" id="summaryabstract-61">Summary/Abstract</a></h1>
<div>Most theories of memory suggest that when  we learn or memorize something, some  representation of that something is  constructed, stored and later retrieved. This  raises questions like: How is information  represented? How is it stored? How is it  retrieved? Then, how is it use? This paper  tries to deal with all these at once. When you  get an idea and want to remember it, you  create a K-line for it. When later activated, the  K-line induces a partial mental state  resembling the one that created it. A partial  mental state is a subset of those mental  agencies operating at one moment. This view  leads to many ideas about the development,  structure and physiology of Memory, and  about how to implement frame-like  representations in a distributed processor.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sejnowski_deep_2018" class=ref>
<summary class=citation>
<a id="sejnowski_deep_2018">[sejnowski_deep_2018]</a> - Sejnowski, Terrence J. - <cite>The Deep Learning Revolution</cite>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite sejnowski_deep_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-62" id="summaryabstract-62">Summary/Abstract</a></h1>
<div>How deep learning—from Google Translate to driverless cars to personal cognitive assistants—is changing our lives and transforming every sector of the economy.The deep learning revolution has brought us driverless cars, the greatly improved Google Translate, fluent conversations with Siri and Alexa, and enormous profits from automated trading on the New York Stock Exchange. Deep learning networks can play poker better than professional poker players and defeat a world champion at Go. In this book, Terry Sejnowski explains how deep learning went from being an arcane academic field to a disruptive technology in the information economy.Sejnowski played an important role in the founding of deep learning, as one of a small group of researchers in the 1980s who challenged the prevailing logic-and-symbol based version of {AI}. The new version of {AI} Sejnowski and others developed, which became deep learning, is fueled instead by data. Deep networks learn from data in the same way that babies experience the world, starting with fresh eyes and gradually acquiring the skills needed to navigate novel environments. Learning algorithms extract information from raw data; information can be used to create knowledge; knowledge underlies understanding; understanding leads to wisdom. Someday a driverless car will know the road better than you do and drive with more skill; a deep learning network will diagnose your illness; a personal cognitive assistant will augment your puny human brain. It took nature many millions of years to evolve human intelligence; {AI} is on a trajectory measured in decades. Sejnowski prepares us for a deep learning future.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="besold_neural-symbolic_2017" class=ref>
<summary class=citation>
<a id="besold_neural-symbolic_2017">[besold_neural-symbolic_2017]</a> - Besold, Tarek R., Garcez, Artur d&#x27;Avila, Bader, Sebastian, Bowman, Howard, Domingos, Pedro, Hitzler, Pascal, Kuehnberger, Kai-Uwe, Lamb, Luis C., Lowd, Daniel, Lima, Priscila Machado Vieira, de Penning, Leo, Pinkas, Gadi, Poon, Hoifung, Zaverucha, Gerson - <a href="http://arxiv.org/abs/1711.03902" target="_blank"><cite>Neural-Symbolic Learning and Reasoning: A Survey and Interpretation</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite besold_neural-symbolic_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-63" id="summaryabstract-63">Summary/Abstract</a></h1>
<div>The study and understanding of human behaviour is relevant to computer science, artificial intelligence, neural computation, cognitive science, philosophy, psychology, and several other areas. Presupposing cognition as basis of behaviour, among the most prominent tools in the modelling of behaviour are computational-logic systems, connectionist models of cognition, and models of uncertainty. Recent studies in cognitive science, artificial intelligence, and psychology have produced a number of cognitive models of reasoning, learning, and language that are underpinned by computation. In addition, efforts in computer science research have led to the development of cognitive computational systems integrating machine learning and automated reasoning. Such systems have shown promise in a range of applications, including computational biology, fault diagnosis, training and assessment in simulators, and software verification. This joint survey reviews the personal ideas and views of several researchers on neural-symbolic learning and reasoning. The article is organised in three parts: Firstly, we frame the scope and goals of neural-symbolic computation and have a look at the theoretical foundations. We then proceed to describe the realisations of neural-symbolic computation, systems, and applications. Finally we present the challenges facing the area and avenues for further research.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="akama_elements_2015" class=ref>
<summary class=citation>
<a id="akama_elements_2015">[akama_elements_2015]</a> - Akama, Seiki - <a href="http://link.springer.com/10.1007/978-3-319-08284-4" target="_blank"><cite>Elements of Quantum Computing</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite akama_elements_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-64" id="summaryabstract-64">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="minaee_deep_2021-1" class=ref>
<summary class=citation>
<a id="minaee_deep_2021-1">[minaee_deep_2021-1]</a> - Minaee, Shervin, Kalchbrenner, Nal, Cambria, Erik, Nikzad, Narjes, Chenaghlu, Meysam, Gao, Jianfeng - <a href="http://arxiv.org/abs/2004.03705" target="_blank"><cite>Deep Learning Based Text Classification: A Comprehensive Review</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite minaee_deep_2021-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-65" id="summaryabstract-65">Summary/Abstract</a></h1>
<div>Deep learning based models have surpassed classical machine learning based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this paper, we provide a comprehensive review of more than 150 deep learning based models for text classification developed in recent years, and discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and discuss future research directions.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="minsky_framework_1974" class=ref>
<summary class=citation>
<a id="minsky_framework_1974">[minsky_framework_1974]</a> - Minsky, Marvin - <a href="https://web.media.mit.edu/~minsky/papers/Frames/frames.html" target="_blank"><cite>A Framework for Representing Knowledge</cite></a>. - 1974. -
<button onclick="copyToClipboard('\{\{ #cite minsky_framework_1974 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-66" id="summaryabstract-66">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="pearl_book_2020" class=ref>
<summary class=citation>
<a id="pearl_book_2020">[pearl_book_2020]</a> - Pearl, Judea, Mackenzie, Dana - <cite>The Book of Why: The New Science of Cause and Effect</cite>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite pearl_book_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-67" id="summaryabstract-67">Summary/Abstract</a></h1>
<div>A Turing Award-winning computer scientist and statistician shows how understanding causality has revolutionized science and will revolutionize artificial intelligence Correlation is not causation. This mantra, chanted by scientists for more than a century, has led to a virtual prohibition on causal talk. Today, that taboo is dead. The causal revolution, instigated by Judea Pearl and his colleagues, has cut through a century of confusion and established causality -- the study of cause and effect -- on a firm scientific basis. His work explains how we can know easy things, like whether it was rain or a sprinkler that made a sidewalk wet; and how to answer hard questions, like whether a drug cured an illness. Pearl&#x27;s work enables us to know not just whether one thing causes another: it lets us explore the world that is and the worlds that could have been. It shows us the essence of human thought and key to artificial intelligence. Anyone who wants to understand either needs The Book of Why.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="radford_language_nodate" class=ref>
<summary class=citation>
<a id="radford_language_nodate">[radford_language_nodate]</a> - Radford, Alec, Wu, Jeffrey, Child, Rewon, Luan, David, Amodei, Dario, Sutskever, Ilya - <cite>Language Models are Unsupervised Multitask Learners</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite radford_language_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-68" id="summaryabstract-68">Summary/Abstract</a></h1>
<div>Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspeciﬁc datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called {WebText}. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the {CoQA} dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, {GPT}-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underﬁts {WebText}. Samples from the model reﬂect these improvements and contain coherent paragraphs of text. These ﬁndings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wang_linformer_2020" class=ref>
<summary class=citation>
<a id="wang_linformer_2020">[wang_linformer_2020]</a> - Wang, Sinong, Li, Belinda Z., Khabsa, Madian, Fang, Han, Ma, Hao - <a href="http://arxiv.org/abs/2006.04768" target="_blank"><cite>Linformer: Self-Attention with Linear Complexity</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite wang_linformer_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-69" id="summaryabstract-69">Summary/Abstract</a></h1>
<div>Large transformer models have shown extraordinary success in achieving state-of-the-art results in many natural language processing applications. However, training and deploying these models can be prohibitively costly for long sequences, as the standard self-attention mechanism of the Transformer uses \$O(n{\textasciicircum}2)\$ time and space with respect to sequence length. In this paper, we demonstrate that the self-attention mechanism can be approximated by a low-rank matrix. We further exploit this finding to propose a new self-attention mechanism, which reduces the overall self-attention complexity from \$O(n{\textasciicircum}2)\$ to \$O(n)\$ in both time and space. The resulting linear transformer, the {\textbackslash}textit\{Linformer\}, performs on par with standard Transformer models, while being much more memory- and time-efficient.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="biesialska_continual_2020" class=ref>
<summary class=citation>
<a id="biesialska_continual_2020">[biesialska_continual_2020]</a> - Biesialska, Magdalena, Biesialska, Katarzyna, Costa-jussà, Marta R. - <a href="http://arxiv.org/abs/2012.09823" target="_blank"><cite>Continual Lifelong Learning in Natural Language Processing: A Survey</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite biesialska_continual_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-70" id="summaryabstract-70">Summary/Abstract</a></h1>
<div>Continual learning ({CL}) aims to enable information systems to learn from a continuous data stream across time. However, it is difficult for existing deep learning architectures to learn a new task without largely forgetting previously acquired knowledge. Furthermore, {CL} is particularly challenging for language learning, as natural language is ambiguous: it is discrete, compositional, and its meaning is context-dependent. In this work, we look at the problem of {CL} through the lens of various {NLP} tasks. Our survey discusses major challenges in {CL} and current methods applied in neural network models. We also provide a critical review of the existing {CL} evaluation methods and datasets in {NLP}. Finally, we present our outlook on future research directions.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="gupta_effective_2020" class=ref>
<summary class=citation>
<a id="gupta_effective_2020">[gupta_effective_2020]</a> - Gupta, Aakriti, Thadani, Kapil, O&#x27;Hare, Neil - <a href="https://www.aclweb.org/anthology/2020.coling-main.92" target="_blank"><cite>Effective Few-Shot Classification with Transfer Learning</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite gupta_effective_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-71" id="summaryabstract-71">Summary/Abstract</a></h1>
<div>Few-shot learning addresses the the problem of learning based on a small amount of training data. Although more well-studied in the domain of computer vision, recent work has adapted the Amazon Review Sentiment Classification ({ARSC}) text dataset for use in the few-shot setting. In this work, we use the {ARSC} dataset to study a simple application of transfer learning approaches to few-shot classification. We train a single binary classifier to learn all few-shot classes jointly by prefixing class identifiers to the input text. Given the text and class, the model then makes a binary prediction for that text/class pair. Our results show that this simple approach can outperform most published results on this dataset. Surprisingly, we also show that including domain information as part of the task definition only leads to a modest improvement in model accuracy, and zero-shot classification, without further fine-tuning on few-shot domains, performs equivalently to few-shot classification. These results suggest that the classes in the {ARSC} few-shot task, which are defined by the intersection of domain and rating, are actually very similar to each other, and that a more suitable dataset is needed for the study of few-shot text classification.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="al-rfou_character-level_2018" class=ref>
<summary class=citation>
<a id="al-rfou_character-level_2018">[al-rfou_character-level_2018]</a> - Al-Rfou, Rami, Choe, Dokook, Constant, Noah, Guo, M, y, Jones, Llion - <a href="http://arxiv.org/abs/1808.04444" target="_blank"><cite>Character-Level Language Modeling with Deeper Self-Attention</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite al-rfou_character-level_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-72" id="summaryabstract-72">Summary/Abstract</a></h1>
<div>{LSTMs} and other {RNN} variants have shown strong performance on character-level language modeling. These models are typically trained using truncated backpropagation through time, and it is common to assume that their success stems from their ability to remember long-term contexts. In this paper, we show that a deep (64-layer) transformer model with fixed context outperforms {RNN} variants by a large margin, achieving state of the art on two popular benchmarks: 1.13 bits per character on text8 and 1.06 on enwik8. To get good results at this depth, we show that it is important to add auxiliary losses, both at intermediate network layers and intermediate sequence positions.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="goodfellow_deep_2016" class=ref>
<summary class=citation>
<a id="goodfellow_deep_2016">[goodfellow_deep_2016]</a> - Goodfellow, Ian, Bengio, Yoshua, Courville, Aaron - <cite>Deep Learning</cite>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite goodfellow_deep_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-73" id="summaryabstract-73">Summary/Abstract</a></h1>
<div>An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.“Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.”—Elon Musk, cochair of {OpenAI}; cofounder and {CEO} of Tesla and {SpaceXDeep} learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="shoeybi_megatron-lm:_2019" class=ref>
<summary class=citation>
<a id="shoeybi_megatron-lm:_2019">[shoeybi_megatron-lm:_2019]</a> - Shoeybi, Mohammad, Patwary, Mostofa, Puri, Raul, {LeGresley}, Patrick, Casper, Jared, Catanzaro, Bryan - <a href="https://arxiv.org/abs/1909.08053v3" target="_blank"><cite>Megatron-{LM}: Training Multi-Billion Parameter Language Models Using Model Parallelism</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite shoeybi_megatron-lm:_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-74" id="summaryabstract-74">Summary/Abstract</a></h1>
<div>Recent work in unsupervised language modeling demonstrates that training
large neural language models advances the state of the art in Natural Language
Processing applications. However, for very large models, memory constraints
limit the size of models that can be practically trained. Model parallelism
allows us to train larger models, because the parameters can be split across
multiple processors. In this work, we implement a simple, efficient intra-layer
model parallel approach that enables training state of the art transformer
language models with billions of parameters. Our approach does not require a
new compiler or library changes, is orthogonal and complimentary to pipeline
model parallelism, and can be fully implemented with the insertion of a few
communication operations in native {PyTorch}. We illustrate this approach by
converging an 8.3 billion parameter transformer language model using 512 {GPUs},
making it the largest transformer model ever trained at 24x times the size of
{BERT} and 5.6x times the size of {GPT}-2. We sustain up to 15.1 {PetaFLOPs} per
second across the entire application with 76\% scaling efficiency, compared to a
strong single processor baseline that sustains 39 {TeraFLOPs} per second, which
is 30\% of peak {FLOPs}. The model is trained on 174GB of text, requiring 12
{ZettaFLOPs} over 9.2 days to converge. Transferring this language model achieves
state of the art ({SOTA}) results on the {WikiText}103 (10.8 compared to {SOTA}
perplexity of 16.4) and {LAMBADA} (66.5\% compared to {SOTA} accuracy of 63.2\%)
datasets. We release training and evaluation code, as well as the weights of
our smaller portable model, for reproducibility.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="mikolov_efficient_2013" class=ref>
<summary class=citation>
<a id="mikolov_efficient_2013">[mikolov_efficient_2013]</a> - Mikolov, Tomas, Chen, Kai, Corrado, Greg, Dean, Jeffrey - <a href="http://arxiv.org/abs/1301.3781" target="_blank"><cite>Efficient Estimation of Word Representations in Vector Space</cite></a>. - 2013. -
<button onclick="copyToClipboard('\{\{ #cite mikolov_efficient_2013 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-75" id="summaryabstract-75">Summary/Abstract</a></h1>
<div>We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wolfram_class_2020" class=ref>
<summary class=citation>
<a id="wolfram_class_2020">[wolfram_class_2020]</a> - Wolfram, Stephen - <a href="http://arxiv.org/abs/2004.08210" target="_blank"><cite>A Class of Models with the Potential to Represent Fundamental Physics</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite wolfram_class_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-76" id="summaryabstract-76">Summary/Abstract</a></h1>
<div>A class of models intended to be as minimal and structureless as possible is introduced. Even in cases with simple rules, rich and complex behavior is found to emerge, and striking correspondences to some important core known features of fundamental physics are seen, suggesting the possibility that the models may provide a new approach to finding a fundamental theory of physics.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zaheer_big_2020" class=ref>
<summary class=citation>
<a id="zaheer_big_2020">[zaheer_big_2020]</a> - Zaheer, Manzil, Guruganesh, Guru, Dubey, Avinava, Ainslie, Joshua, Alberti, Chris, Ontanon, Santiago, Pham, Philip, Ravula, Anirudh, Wang, Qifan, Yang, Li, Ahmed, Amr - <a href="http://arxiv.org/abs/2007.14062" target="_blank"><cite>Big Bird: Transformers for Longer Sequences</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite zaheer_big_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-77" id="summaryabstract-77">Summary/Abstract</a></h1>
<div>Transformers-based models, such as {BERT}, have been one of the most successful deep learning models for {NLP}. Unfortunately, one of their core limitations is the quadratic dependency (mainly in terms of memory) on the sequence length due to their full attention mechanism. To remedy this, we propose, {BigBird}, a sparse attention mechanism that reduces this quadratic dependency to linear. We show that {BigBird} is a universal approximator of sequence functions and is Turing complete, thereby preserving these properties of the quadratic, full attention model. Along the way, our theoretical analysis reveals some of the benefits of having \$O(1)\$ global tokens (such as {CLS}), that attend to the entire sequence as part of the sparse attention mechanism. The proposed sparse attention can handle sequences of length up to 8x of what was previously possible using similar hardware. As a consequence of the capability to handle longer context, {BigBird} drastically improves performance on various {NLP} tasks such as question answering and summarization. We also propose novel applications to genomics data.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="clark_electra_2019" class=ref>
<summary class=citation>
<a id="clark_electra_2019">[clark_electra_2019]</a> - Clark, Kevin, Luong, Minh-Thang, Le, Quoc V., Manning, Christopher D. - <a href="https://openreview.net/forum?id&#x3D;r1xMH1BtvB" target="_blank"><cite>{ELECTRA}: Pre-training Text Encoders as Discriminators Rather Than Generators</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite clark_electra_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-78" id="summaryabstract-78">Summary/Abstract</a></h1>
<div>Masked language modeling ({MLM}) pre-training methods such as {BERT} corrupt the input by replacing some tokens with [{MASK}] and then train a model to reconstruct the original tokens. While they produce...</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="huszar_quadratic_2017" class=ref>
<summary class=citation>
<a id="huszar_quadratic_2017">[huszar_quadratic_2017]</a> - Huszár, Ferenc - <a href="http://arxiv.org/abs/1712.03847" target="_blank"><cite>On Quadratic Penalties in Elastic Weight Consolidation</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite huszar_quadratic_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-79" id="summaryabstract-79">Summary/Abstract</a></h1>
<div>Elastic weight consolidation ({EWC}, Kirkpatrick et al, 2017) is a novel algorithm designed to safeguard against catastrophic forgetting in neural networks. {EWC} can be seen as an approximation to Laplace propagation (Eskin et al, 2004), and this view is consistent with the motivation given by Kirkpatrick et al (2017). In this note, I present an extended derivation that covers the case when there are more than two tasks. I show that the quadratic penalties in {EWC} are inconsistent with this derivation and might lead to double-counting data from earlier tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="karpathy_visualizing_2015" class=ref>
<summary class=citation>
<a id="karpathy_visualizing_2015">[karpathy_visualizing_2015]</a> - Karpathy, Andrej, Johnson, Justin, Fei-Fei, Li - <a href="http://arxiv.org/abs/1506.02078" target="_blank"><cite>Visualizing and Understanding Recurrent Networks</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite karpathy_visualizing_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-80" id="summaryabstract-80">Summary/Abstract</a></h1>
<div>Recurrent Neural Networks ({RNNs}), and specifically a variant with Long Short-Term Memory ({LSTM}), are enjoying renewed interest as a result of successful applications in a wide range of machine learning problems that involve sequential data. However, while {LSTMs} provide exceptional results in practice, the source of their performance and their limitations remain rather poorly understood. Using character-level language models as an interpretable testbed, we aim to bridge this gap by providing an analysis of their representations, predictions and error types. In particular, our experiments reveal the existence of interpretable cells that keep track of long-range dependencies such as line lengths, quotes and brackets. Moreover, our comparative analysis with finite horizon n-gram models traces the source of the {LSTM} improvements to long-range structural dependencies. Finally, we provide analysis of the remaining errors and suggests areas for further study.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="mccloskey_catastrophic_1989" class=ref>
<summary class=citation>
<a id="mccloskey_catastrophic_1989">[mccloskey_catastrophic_1989]</a> - {McCloskey}, Michael, Cohen, Neal J. - <a href="https://www.sciencedirect.com/science/article/pii/S0079742108605368" target="_blank"><cite>Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem</cite></a>. - 1989. -
<button onclick="copyToClipboard('\{\{ #cite mccloskey_catastrophic_1989 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-81" id="summaryabstract-81">Summary/Abstract</a></h1>
<div>Connectionist networks in which information is stored in weights on connections among simple processing units have attracted considerable interest in cognitive science. Much of the interest centers around two characteristics of these networks. First, the weights on connections between units need not be prewired by the model builder but rather may be established through training in which items to be learned are presented repeatedly to the network and the connection weights are adjusted in small increments according to a learning algorithm. Second, the networks may represent information in a distributed fashion. This chapter discusses the catastrophic interference in connectionist networks. Distributed representations established through the application of learning algorithms have several properties that are claimed to be desirable from the standpoint of modeling human cognition. These properties include content-addressable memory and so-called automatic generalization in which a network trained on a set of items responds correctly to other untrained items within the same domain. New learning may interfere catastrophically with old learning when networks are trained sequentially. The analysis of the causes of interference implies that at least some interference will occur whenever new learning may alter weights involved in representing old learning, and the simulation results demonstrate only that interference is catastrophic in some specific networks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="nakkiran_deep_2019" class=ref>
<summary class=citation>
<a id="nakkiran_deep_2019">[nakkiran_deep_2019]</a> - Nakkiran, Preetum, Kaplun, Gal, Bansal, Yamini, Yang, Tristan, Barak, Boaz, Sutskever, Ilya - <a href="http://arxiv.org/abs/1912.02292" target="_blank"><cite>Deep Double Descent: Where Bigger Models and More Data Hurt</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite nakkiran_deep_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-82" id="summaryabstract-82">Summary/Abstract</a></h1>
<div>We show that a variety of modern deep learning tasks exhibit a double-descent phenomenon where, as we increase model size, performance first gets worse and then gets better. Moreover, we show that double descent occurs not just as a function of model size, but also as a function of the number of training epochs. We unify the above phenomena by defining a new complexity measure we call the effective model complexity and conjecture a generalized double descent with respect to this measure. Furthermore, our notion of model complexity allows us to identify certain regimes where increasing (even quadrupling) the number of train samples actually hurts test performance.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="goldberg_word2vec_2014" class=ref>
<summary class=citation>
<a id="goldberg_word2vec_2014">[goldberg_word2vec_2014]</a> - Goldberg, Yoav, Levy, Omer - <a href="http://arxiv.org/abs/1402.3722" target="_blank"><cite>word2vec Explained: deriving Mikolov et al.&#x27;s negative-sampling word-embedding method</cite></a>. - 2014. -
<button onclick="copyToClipboard('\{\{ #cite goldberg_word2vec_2014 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-83" id="summaryabstract-83">Summary/Abstract</a></h1>
<div>The word2vec software of Tomas Mikolov and colleagues (https://code.google.com/p/word2vec/ ) has gained a lot of traction lately, and provides state-of-the-art word embeddings. The learning models behind the software are described in two research papers. We found the description of the models in these papers to be somewhat cryptic and hard to follow. While the motivations and presentation may be obvious to the neural-networks language-modeling crowd, we had to struggle quite a bit to figure out the rationale behind the equations. This note is an attempt to explain equation (4) (negative sampling) in Distributed Representations of Words and Phrases and their Compositionality by Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado and Jeffrey Dean.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="liu_roberta:_2019" class=ref>
<summary class=citation>
<a id="liu_roberta:_2019">[liu_roberta:_2019]</a> - Liu, Yinhan, Ott, Myle, Goyal, Naman, Du, Jingfei, Joshi, M, ar, Chen, Danqi, Levy, Omer, Lewis, Mike, Zettlemoyer, Luke, Stoyanov, Veselin - <a href="http://arxiv.org/abs/1907.11692" target="_blank"><cite>{RoBERTa}: A Robustly Optimized {BERT} Pretraining Approach</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite liu_roberta:_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-84" id="summaryabstract-84">Summary/Abstract</a></h1>
<div>Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of {BERT} pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that {BERT} was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on {GLUE}, {RACE} and {SQuAD}. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wang_dueling_2016" class=ref>
<summary class=citation>
<a id="wang_dueling_2016">[wang_dueling_2016]</a> - Wang, Ziyu, Schaul, Tom, Hessel, Matteo, van Hasselt, Hado, Lanctot, Marc, de Freitas, N, o - <a href="http://arxiv.org/abs/1511.06581" target="_blank"><cite>Dueling Network Architectures for Deep Reinforcement Learning</cite></a>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite wang_dueling_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-85" id="summaryabstract-85">Summary/Abstract</a></h1>
<div>In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional networks, {LSTMs}, or auto-encoders. In this paper, we present a new neural network architecture for model-free reinforcement learning. Our dueling network represents two separate estimators: one for the state value function and one for the state-dependent action advantage function. The main benefit of this factoring is to generalize learning across actions without imposing any change to the underlying reinforcement learning algorithm. Our results show that this architecture leads to better policy evaluation in the presence of many similar-valued actions. Moreover, the dueling architecture enables our {RL} agent to outperform the state-of-the-art on the Atari 2600 domain.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lample_cross-lingual_2019" class=ref>
<summary class=citation>
<a id="lample_cross-lingual_2019">[lample_cross-lingual_2019]</a> - Lample, Guillaume, Conneau, Alexis - <a href="http://arxiv.org/abs/1901.07291" target="_blank"><cite>Cross-lingual Language Model Pretraining</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite lample_cross-lingual_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-86" id="summaryabstract-86">Summary/Abstract</a></h1>
<div>Recent studies have demonstrated the efficiency of generative pretraining for English natural language understanding. In this work, we extend this approach to multiple languages and show the effectiveness of cross-lingual pretraining. We propose two methods to learn cross-lingual language models ({XLMs}): one unsupervised that only relies on monolingual data, and one supervised that leverages parallel data with a new cross-lingual language model objective. We obtain state-of-the-art results on cross-lingual classification, unsupervised and supervised machine translation. On {XNLI}, our approach pushes the state of the art by an absolute gain of 4.9\% accuracy. On unsupervised machine translation, we obtain 34.3 {BLEU} on {WMT}&#x27;16 German-English, improving the previous state of the art by more than 9 {BLEU}. On supervised machine translation, we obtain a new state of the art of 38.5 {BLEU} on {WMT}&#x27;16 Romanian-English, outperforming the previous best approach by more than 4 {BLEU}. Our code and pretrained models will be made publicly available.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lopez-paz_gradient_2017" class=ref>
<summary class=citation>
<a id="lopez-paz_gradient_2017">[lopez-paz_gradient_2017]</a> - Lopez-Paz, David, Ranzato, Marc&#x27;Aurelio - <a href="http://arxiv.org/abs/1706.08840" target="_blank"><cite>Gradient Episodic Memory for Continual Learning</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite lopez-paz_gradient_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-87" id="summaryabstract-87">Summary/Abstract</a></h1>
<div>One major obstacle towards {AI} is the poor ability of models to solve new problems quicker, and without forgetting previously acquired knowledge. To better understand this issue, we study the problem of continual learning, where the model observes, once and one by one, examples concerning a sequence of tasks. First, we propose a set of metrics to evaluate models learning over a continuum of data. These metrics characterize models not only by their test accuracy, but also in terms of their ability to transfer knowledge across tasks. Second, we propose a model for continual learning, called Gradient Episodic Memory ({GEM}) that alleviates forgetting, while allowing beneficial transfer of knowledge to previous tasks. Our experiments on variants of the {MNIST} and {CIFAR}-100 datasets demonstrate the strong performance of {GEM} when compared to the state-of-the-art.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="clark_what_2019" class=ref>
<summary class=citation>
<a id="clark_what_2019">[clark_what_2019]</a> - Clark, Kevin, Kh, elwal, Urvashi, Levy, Omer, Manning, Christopher D. - <a href="http://arxiv.org/abs/1906.04341" target="_blank"><cite>What Does {BERT} Look At? An Analysis of {BERT}&#x27;s Attention</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite clark_what_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-88" id="summaryabstract-88">Summary/Abstract</a></h1>
<div>Large pre-trained neural networks such as {BERT} have had great recent success in {NLP}, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to {BERT}. {BERT}&#x27;s attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in {BERT}&#x27;s attention.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zenke_continual_2017" class=ref>
<summary class=citation>
<a id="zenke_continual_2017">[zenke_continual_2017]</a> - Zenke, Friedemann, Poole, Ben, Ganguli, Surya - <a href="https://arxiv.org/abs/1703.04200v3" target="_blank"><cite>Continual Learning Through Synaptic Intelligence</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite zenke_continual_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-89" id="summaryabstract-89">Summary/Abstract</a></h1>
<div>While deep learning has led to remarkable advances across diverse
applications, it struggles in domains where the data distribution changes over
the course of learning. In stark contrast, biological neural networks
continually adapt to changing domains, possibly by leveraging complex molecular
machinery to solve many tasks simultaneously. In this study, we introduce
intelligent synapses that bring some of this biological complexity into
artificial neural networks. Each synapse accumulates task relevant information
over time, and exploits this information to rapidly store new memories without
forgetting old ones. We evaluate our approach on continual learning of
classification tasks, and show that it dramatically reduces forgetting while
maintaining computational efficiency.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="minaee_deep_2021" class=ref>
<summary class=citation>
<a id="minaee_deep_2021">[minaee_deep_2021]</a> - Minaee, Shervin, Kalchbrenner, Nal, Cambria, Erik, Nikzad, Narjes, Chenaghlu, Meysam, Gao, Jianfeng - <a href="http://arxiv.org/abs/2004.03705" target="_blank"><cite>Deep Learning Based Text Classification: A Comprehensive Review</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite minaee_deep_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-90" id="summaryabstract-90">Summary/Abstract</a></h1>
<div>Deep learning based models have surpassed classical machine learning based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this paper, we provide a comprehensive review of more than 150 deep learning based models for text classification developed in recent years, and discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and discuss future research directions.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="garcez_neural-symbolic_2019" class=ref>
<summary class=citation>
<a id="garcez_neural-symbolic_2019">[garcez_neural-symbolic_2019]</a> - Garcez, Artur d&#x27;Avila, Gori, Marco, Lamb, Luis C., Serafini, Luciano, Spranger, Michael, Tran, Son N. - <a href="http://arxiv.org/abs/1905.06088" target="_blank"><cite>Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite garcez_neural-symbolic_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-91" id="summaryabstract-91">Summary/Abstract</a></h1>
<div>Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of {AI} have been raised by influential thinkers. In spite of the recent impact of {AI}, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable {AI} systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable {AI} systems.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="liu_multi-task_2019" class=ref>
<summary class=citation>
<a id="liu_multi-task_2019">[liu_multi-task_2019]</a> - Liu, Xiaodong, He, Pengcheng, Chen, Weizhu, Gao, Jianfeng - <a href="https://www.aclweb.org/anthology/P19-1441" target="_blank"><cite>Multi-Task Deep Neural Networks for Natural Language Understanding</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite liu_multi-task_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-92" id="summaryabstract-92">Summary/Abstract</a></h1>
<div>In this paper, we present a Multi-Task Deep Neural Network ({MT}-{DNN}) for learning representations across multiple natural language understanding ({NLU}) tasks. {MT}-{DNN} not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations to help adapt to new tasks and domains. {MT}-{DNN} extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as {BERT} (Devlin et al., 2018). {MT}-{DNN} obtains new state-of-the-art results on ten {NLU} tasks, including {SNLI}, {SciTail}, and eight out of nine {GLUE} tasks, pushing the {GLUE} benchmark to 82.7\% (2.2\% absolute improvement) as of February 25, 2019 on the latest {GLUE} test set. We also demonstrate using the {SNLI} and {SciTail} datasets that the representations learned by {MT}-{DNN} allow domain adaptation with substantially fewer in-domain labels than the pre-trained {BERT} representations. Our code and pre-trained models will be made publicly available.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="van_hasselt_deep_2015" class=ref>
<summary class=citation>
<a id="van_hasselt_deep_2015">[van_hasselt_deep_2015]</a> - van Hasselt, Hado, Guez, Arthur, Silver, David - <a href="http://arxiv.org/abs/1509.06461" target="_blank"><cite>Deep Reinforcement Learning with Double Q-learning</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite van_hasselt_deep_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-93" id="summaryabstract-93">Summary/Abstract</a></h1>
<div>The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent {DQN} algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the {DQN} algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="schaul_prioritized_2015" class=ref>
<summary class=citation>
<a id="schaul_prioritized_2015">[schaul_prioritized_2015]</a> - Schaul, Tom, Quan, John, Antonoglou, Ioannis, Silver, David - <a href="https://arxiv.org/abs/1511.05952v4" target="_blank"><cite>Prioritized Experience Replay</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite schaul_prioritized_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-94" id="summaryabstract-94">Summary/Abstract</a></h1>
<div>Experience replay lets online reinforcement learning agents remember and
reuse experiences from the past. In prior work, experience transitions were
uniformly sampled from a replay memory. However, this approach simply replays
transitions at the same frequency that they were originally experienced,
regardless of their significance. In this paper we develop a framework for
prioritizing experience, so as to replay important transitions more frequently,
and therefore learn more efficiently. We use prioritized experience replay in
Deep Q-Networks ({DQN}), a reinforcement learning algorithm that achieved
human-level performance across many Atari games. {DQN} with prioritized
experience replay achieves a new state-of-the-art, outperforming {DQN} with
uniform replay on 41 out of 49 games.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="molnar_interpretable_nodate" class=ref>
<summary class=citation>
<a id="molnar_interpretable_nodate">[molnar_interpretable_nodate]</a> - Molnar, Christoph - <a href="https://christophm.github.io/interpretable-ml-book/" target="_blank"><cite>Interpretable Machine Learning</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite molnar_interpretable_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-95" id="summaryabstract-95">Summary/Abstract</a></h1>
<div>Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="cappelletti_polyadic_2020" class=ref>
<summary class=citation>
<a id="cappelletti_polyadic_2020">[cappelletti_polyadic_2020]</a> - Cappelletti, William, Erbanni, Rebecca, Keller, Joaquín - <a href="http://arxiv.org/abs/2007.14044" target="_blank"><cite>Polyadic Quantum Classifier</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite cappelletti_polyadic_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-96" id="summaryabstract-96">Summary/Abstract</a></h1>
<div>We introduce here a supervised quantum machine learning algorithm for multi-class classification on {NISQ} architectures. A parametric quantum circuit is trained to output a specific bit string corresponding to the class of the input datapoint. We train and test it on an {IBMq} 5-qubit quantum computer and the algorithm shows good accuracy –compared to a classical machine learning model– for ternary classification of the Iris dataset and an extension of the {XOR} problem. Furthermore, we evaluate with simulations how the algorithm fares for a binary and a quaternary classification on resp. a known binary dataset and a synthetic dataset.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="agarwal_neural_2020" class=ref>
<summary class=citation>
<a id="agarwal_neural_2020">[agarwal_neural_2020]</a> - Agarwal, Rishabh, Frosst, Nicholas, Zhang, Xuezhou, Caruana, Rich, Hinton, Geoffrey E. - <a href="http://arxiv.org/abs/2004.13912" target="_blank"><cite>Neural Additive Models: Interpretable Machine Learning with Neural Nets</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite agarwal_neural_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-97" id="summaryabstract-97">Summary/Abstract</a></h1>
<div>Deep neural networks ({DNNs}) are powerful black-box predictors that have achieved impressive performance on a wide variety of tasks. However, their accuracy comes at the cost of intelligibility: it is usually unclear how they make their decisions. This hinders their applicability to high stakes decision-making domains such as healthcare. We propose Neural Additive Models ({NAMs}) which combine some of the expressivity of {DNNs} with the inherent intelligibility of generalized additive models. {NAMs} learn a linear combination of neural networks that each attend to a single input feature. These networks are trained jointly and can learn arbitrarily complex relationships between their input feature and the output. Our experiments on regression and classification datasets show that {NAMs} are more accurate than widely used intelligible models such as logistic regression and shallow decision trees. They perform similarly to existing state-of-the-art generalized additive models in accuracy, but can be more easily applied to real-world problems.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="caruana_multitask_1997" class=ref>
<summary class=citation>
<a id="caruana_multitask_1997">[caruana_multitask_1997]</a> - Caruana, Rich - <a href="http://reports-archive.adm.cs.cmu.edu/anon/1997/CMU-CS-97-203.pdf" target="_blank"><cite>Multitask Learning</cite></a>. - 1997. -
<button onclick="copyToClipboard('\{\{ #cite caruana_multitask_1997 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-98" id="summaryabstract-98">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="kitaev_reformer_2020" class=ref>
<summary class=citation>
<a id="kitaev_reformer_2020">[kitaev_reformer_2020]</a> - Kitaev, Nikita, Kaiser, Łukasz, Levskaya, Anselm - <a href="http://arxiv.org/abs/2001.04451" target="_blank"><cite>Reformer: The Efficient Transformer</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite kitaev_reformer_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-99" id="summaryabstract-99">Summary/Abstract</a></h1>
<div>Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O(\$L{\textasciicircum}2\$) to O(\$L{\textbackslash}log L\$), where \$L\$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of \$N\$ times, where \$N\$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="tan_survey_2018" class=ref>
<summary class=citation>
<a id="tan_survey_2018">[tan_survey_2018]</a> - Tan, Chuanqi, Sun, Fuchun, Kong, Tao, Zhang, Wenchang, Yang, Chao, Liu, Chunfang - <a href="http://arxiv.org/abs/1808.01974" target="_blank"><cite>A Survey on Deep Transfer Learning</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite tan_survey_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-100" id="summaryabstract-100">Summary/Abstract</a></h1>
<div>As a new classification platform, deep learning has recently received increasing attention from researchers and has been successfully applied to many domains. In some domains, like bioinformatics and robotics, it is very difficult to construct a large-scale well-annotated dataset due to the expense of data acquisition and costly annotation, which limits its development. Transfer learning relaxes the hypothesis that the training data must be independent and identically distributed (i.i.d.) with the test data, which motivates us to use transfer learning to solve the problem of insufficient training data. This survey focuses on reviewing the current researches of transfer learning by using deep neural network and its applications. We defined deep transfer learning, category and review the recent research works based on the techniques used in deep transfer learning.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_explainable_nodate" class=ref>
<summary class=citation>
<a id="noauthor_explainable_nodate">[noauthor_explainable_nodate]</a> - N/A - <a href="https://www.darpa.mil/program/explainable-artificial-intelligence" target="_blank"><cite>Explainable Artificial Intelligence</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_explainable_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-101" id="summaryabstract-101">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="ruffy_state_2019" class=ref>
<summary class=citation>
<a id="ruffy_state_2019">[ruffy_state_2019]</a> - Ruffy, Fabian, Chahal, Karanbir - <a href="https://arxiv.org/abs/1912.10850v1" target="_blank"><cite>The State of Knowledge Distillation for Classification</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite ruffy_state_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-102" id="summaryabstract-102">Summary/Abstract</a></h1>
<div>We survey various knowledge distillation ({KD}) strategies for simple
classification tasks and implement a set of techniques that claim
state-of-the-art accuracy. Our experiments using standardized model
architectures, fixed compute budgets, and consistent training schedules
indicate that many of these distillation results are hard to reproduce. This is
especially apparent with methods using some form of feature distillation.
Further examination reveals a lack of generalizability where these techniques
may only succeed for specific architectures and training settings. We observe
that appropriately tuned classical distillation in combination with a data
augmentation training scheme gives an orthogonal improvement over other
techniques. We validate this approach and open-source our code.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="dai_transformer-xl:_2019" class=ref>
<summary class=citation>
<a id="dai_transformer-xl:_2019">[dai_transformer-xl:_2019]</a> - Dai, Zihang, Yang, Zhilin, Yang, Yiming, Carbonell, Jaime, Le, Quoc V., Salakhutdinov, Ruslan - <a href="http://arxiv.org/abs/1901.02860" target="_blank"><cite>Transformer-{XL}: Attentive Language Models Beyond a Fixed-Length Context</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite dai_transformer-xl:_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-103" id="summaryabstract-103">Summary/Abstract</a></h1>
<div>Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-{XL} that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-{XL} learns dependency that is 80\% longer than {RNNs} and 450\% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on {WikiText}-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on {WikiText}-103, Transformer-{XL} manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and {PyTorch}.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zenke_continual_2017-1" class=ref>
<summary class=citation>
<a id="zenke_continual_2017-1">[zenke_continual_2017-1]</a> - Zenke, Friedemann, Poole, Ben, Ganguli, Surya - <a href="https://arxiv.org/abs/1703.04200v3" target="_blank"><cite>Continual Learning Through Synaptic Intelligence</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite zenke_continual_2017-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-104" id="summaryabstract-104">Summary/Abstract</a></h1>
<div>While deep learning has led to remarkable advances across diverse applications, it struggles in domains where the data distribution changes over the course of learning. In stark contrast, biological neural networks continually adapt to changing domains, possibly by leveraging complex molecular machinery to solve many tasks simultaneously. In this study, we introduce intelligent synapses that bring some of this biological complexity into artificial neural networks. Each synapse accumulates task relevant information over time, and exploits this information to rapidly store new memories without forgetting old ones. We evaluate our approach on continual learning of classification tasks, and show that it dramatically reduces forgetting while maintaining computational efficiency.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="schwarz_progress_2018" class=ref>
<summary class=citation>
<a id="schwarz_progress_2018">[schwarz_progress_2018]</a> - Schwarz, Jonathan, Luketina, Jelena, Czarnecki, Wojciech M., Grabska-Barwinska, Agnieszka, Teh, Yee Whye, Pascanu, Razvan, Hadsell, Raia - <a href="http://arxiv.org/abs/1805.06370" target="_blank"><cite>Progress \&amp; Compress: A scalable framework for continual learning</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite schwarz_progress_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-105" id="summaryabstract-105">Summary/Abstract</a></h1>
<div>We introduce a conceptually simple and scalable framework for continual learning domains where tasks are learned sequentially. Our method is constant in the number of parameters and is designed to preserve performance on previously encountered tasks while accelerating learning progress on subsequent problems. This is achieved by training a network with two components: A knowledge base, capable of solving previously encountered problems, which is connected to an active column that is employed to efficiently learn the current task. After learning a new task, the active column is distilled into the knowledge base, taking care to protect any previously acquired skills. This cycle of active learning (progression) followed by consolidation (compression) requires no architecture growth, no access to or storing of previous data or tasks, and no task-specific parameters. We demonstrate the progress \&amp; compress approach on sequential classification of handwritten alphabets as well as two reinforcement learning domains: Atari games and 3D maze navigation.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sun_how_2020" class=ref>
<summary class=citation>
<a id="sun_how_2020">[sun_how_2020]</a> - Sun, Chi, Qiu, Xipeng, Xu, Yige, Huang, Xuanjing - <a href="http://arxiv.org/abs/1905.05583" target="_blank"><cite>How to Fine-Tune {BERT} for Text Classification?</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite sun_how_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-106" id="summaryabstract-106">Summary/Abstract</a></h1>
<div>Language model pre-training has proven to be useful in learning universal language representations. As a state-of-the-art language model pre-training model, {BERT} (Bidirectional Encoder Representations from Transformers) has achieved amazing results in many language understanding tasks. In this paper, we conduct exhaustive experiments to investigate different fine-tuning methods of {BERT} on text classification task and provide a general solution for {BERT} fine-tuning. Finally, the proposed solution obtains new state-of-the-art results on eight widely-studied text classification datasets.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="minsky_perceptrons_1987" class=ref>
<summary class=citation>
<a id="minsky_perceptrons_1987">[minsky_perceptrons_1987]</a> - Minsky, Marvin, Papert, Seymour A. - <cite>Perceptrons: An Introduction to Computational Geometry, Expanded Edition</cite>. - 1987. -
<button onclick="copyToClipboard('\{\{ #cite minsky_perceptrons_1987 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-107" id="summaryabstract-107">Summary/Abstract</a></h1>
<div>Perceptrons - the first systematic study of parallelism in computation - has remained a classical work on threshold automata networks for nearly two decades. It marked a historical turn in artificial intelligence, and it is required reading for anyone who wants to understand the connectionist counterrevolution that is going on today. Artificial-intelligence research, which for a time concentrated on the programming of ton Neumann computers, is swinging back to the idea that intelligence might emerge from the activity of networks of neuronlike entities. Minsky and Papert&#x27;s book was the first example of a mathematical analysis carried far enough to show the exact limitations of a class of computing machines that could seriously be considered as models of the brain. Now the new developments in mathematical tools, the recent interest of physicists in the theory of disordered matter, the new insights into and psychological models of how the brain works, and the evolution of fast computers that can simulate networks of automata have given Perceptrons new importance.Witnessing the swing of the intellectual pendulum, Minsky and Papert have added a new chapter in which they discuss the current state of parallel computers, review developments since the appearance of the 1972 edition, and identify new research directions related to connectionism. They note a central theoretical challenge facing connectionism: the challenge to reach a deeper understanding of how objects or agents with individuality can emerge in a network. Progress in this area would link connectionism with what the authors have called society theories of mind. Marvin L. Minsky is Donner Professor of Science in M.I.T.&#x27;s Electrical Engineering and Computer Science Department. Seymour A. Papert is Professor of Media Technology at M.I.T. .</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="pan_survey_2010" class=ref>
<summary class=citation>
<a id="pan_survey_2010">[pan_survey_2010]</a> - Pan, Sinno Jialin, Yang, Qiang - <a href="http://ieeexplore.ieee.org/document/5288526/" target="_blank"><cite>A Survey on Transfer Learning</cite></a>. - 2010. -
<button onclick="copyToClipboard('\{\{ #cite pan_survey_2010 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-108" id="summaryabstract-108">Summary/Abstract</a></h1>
<div>A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classiﬁcation task in one domain of interest, but we only have sufﬁcient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classiﬁcation, regression and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as co-variate shift. We also explore some potential future issues in transfer learning research.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="gong_hierarchical_2020" class=ref>
<summary class=citation>
<a id="gong_hierarchical_2020">[gong_hierarchical_2020]</a> - Gong, Jibing, Liu, Mingsheng, Ma, Hongyuan, Teng, Zhiyong, Teng, Qi, Zhang, Hekai, Du, Linfeng, Chen, Shuai, Bhuiyan, Md, Li, Jianhua - <cite>Hierarchical Graph Transformer Based Deep Learning Model for Large-Scale Multi-Label Text Classification</cite>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite gong_hierarchical_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-109" id="summaryabstract-109">Summary/Abstract</a></h1>
<div>Traditional methods of multi-label text classification, particularly deep learning, have achieved remarkable results. However, most of these methods use word2vec technology to represent sequential text information, while ignoring the logic and internal hierarchy of the text itself. Although these approaches can learn the hypothetical hierarchy and logic of the text, it is unexplained. In addition, the traditional approach treats labels as independent individuals and ignores the relationships between them, which not only does not reflect reality but also causes significant loss of semantic information. In this paper, we propose a novel Hierarchical Graph Transformer based deep learning model for large-scale multi-label text classification. We first model the text into a graph structure that can embody the different semantics of the text and the connections between them. We then use a multi-layer transformer structure with a multi-head attention mechanism at the word, sentence, and graph levels to fully capture the features of the text and observe the importance of the separate parts. Finally, we use the hierarchical relationship of the labels to generate the representation of the labels, and design a weighted loss function based on the semantic distances of the labels. Extensive experiments conducted on three benchmark datasets demonstrated that the proposed model can realistically capture the hierarchy and logic of text and improve performance compared with the state-of-the-art methods.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="rebuffel_controlling_2021" class=ref>
<summary class=citation>
<a id="rebuffel_controlling_2021">[rebuffel_controlling_2021]</a> - Rebuffel, Clément, Roberti, Marco, Soulier, Laure, Scoutheeten, Geoffrey, Cancelliere, Rossella, Gallinari, Patrick - <a href="http://arxiv.org/abs/2102.02810" target="_blank"><cite>Controlling Hallucinations at Word Level in Data-to-Text Generation</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite rebuffel_controlling_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-110" id="summaryabstract-110">Summary/Abstract</a></h1>
<div>Data-to-Text Generation ({DTG}) is a subfield of Natural Language Generation aiming at transcribing structured data in natural language descriptions. The field has been recently boosted by the use of neural-based generators which exhibit on one side great syntactic skills without the need of hand-crafted pipelines; on the other side, the quality of the generated text reflects the quality of the training data, which in realistic settings only offer imperfectly aligned structure-text pairs. Consequently, state-of-art neural models include misleading statements - usually called hallucinations - in their outputs. The control of this phenomenon is today a major challenge for {DTG}, and is the problem addressed in the paper. Previous work deal with this issue at the instance level: using an alignment score for each table-reference pair. In contrast, we propose a finer-grained approach, arguing that hallucinations should rather be treated at the word level. Specifically, we propose a Multi-Branch Decoder which is able to leverage word-level labels to learn the relevant parts of each training instance. These labels are obtained following a simple and efficient scoring procedure based on co-occurrence analysis and dependency parsing. Extensive evaluations, via automated metrics and human judgment on the standard {WikiBio} benchmark, show the accuracy of our alignment labels and the effectiveness of the proposed Multi-Branch Decoder. Our model is able to reduce and control hallucinations, while keeping fluency and coherence in generated texts. Further experiments on a degraded version of {ToTTo} show that our model could be successfully used on very noisy settings.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="de_lange_continual_2020" class=ref>
<summary class=citation>
<a id="de_lange_continual_2020">[de_lange_continual_2020]</a> - De Lange, Matthias, Aljundi, Rahaf, Masana, Marc, Parisot, Sarah, Jia, Xu, Leonardis, Ales, Slabaugh, Gregory, Tuytelaars, Tinne - <a href="http://arxiv.org/abs/1909.08383" target="_blank"><cite>A continual learning survey: Defying forgetting in classification tasks</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite de_lange_continual_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-111" id="summaryabstract-111">Summary/Abstract</a></h1>
<div>Artificial neural networks thrive in solving the classification problem for a particular rigid task, acquiring knowledge through generalized learning behaviour from a distinct training phase. The resulting network resembles a static entity of knowledge, with endeavours to extend this knowledge without targeting the original task resulting in a catastrophic forgetting. Continual learning shifts this paradigm towards networks that can continually accumulate knowledge over different tasks without the need to retrain from scratch. We focus on task incremental classification, where tasks arrive sequentially and are delineated by clear boundaries. Our main contributions concern 1) a taxonomy and extensive overview of the state-of-the-art, 2) a novel framework to continually determine the stability-plasticity trade-off of the continual learner, 3) a comprehensive experimental comparison of 11 state-of-the-art continual learning methods and 4 baselines. We empirically scrutinize method strengths and weaknesses on three benchmarks, considering Tiny Imagenet and large-scale unbalanced {iNaturalist} and a sequence of recognition datasets. We study the influence of model capacity, weight decay and dropout regularization, and the order in which the tasks are presented, and qualitatively compare methods in terms of required memory, computation time, and storage.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_ganfather_nodate" class=ref>
<summary class=citation>
<a id="noauthor_ganfather_nodate">[noauthor_ganfather_nodate]</a> - N/A - <a href="https://www.technologyreview.com/2018/02/21/145289/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/" target="_blank"><cite>The {GANfather}: The man who’s given machines the gift of imagination</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_ganfather_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-112" id="summaryabstract-112">Summary/Abstract</a></h1>
<div>One night in 2014, Ian Goodfellow went drinking to celebrate with a fellow doctoral student who had just graduated. At Les 3 Brasseurs (The Three Brewers), a favorite Montreal watering hole, some friends asked for his help with a thorny project they were working on: a computer that could create photos by itself. Researchers were…</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="hinton_distilling_2015" class=ref>
<summary class=citation>
<a id="hinton_distilling_2015">[hinton_distilling_2015]</a> - Hinton, Geoffrey, Vinyals, Oriol, Dean, Jeff - <a href="http://arxiv.org/abs/1503.02531" target="_blank"><cite>Distilling the Knowledge in a Neural Network</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite hinton_distilling_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-113" id="summaryabstract-113">Summary/Abstract</a></h1>
<div>A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on {MNIST} and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zhu_transfer_2020" class=ref>
<summary class=citation>
<a id="zhu_transfer_2020">[zhu_transfer_2020]</a> - Zhu, Zhuangdi, Lin, Kaixiang, Zhou, Jiayu - <a href="http://arxiv.org/abs/2009.07888" target="_blank"><cite>Transfer Learning in Deep Reinforcement Learning: A Survey</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite zhu_transfer_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-114" id="summaryabstract-114">Summary/Abstract</a></h1>
<div>This paper surveys the field of transfer learning in the problem setting of Reinforcement Learning ({RL}). {RL} has been a key solution to sequential decision-making problems. Along with the fast advances of {RL} in various domains, such as robotics and game-playing, transfer learning arises as an important technique to assist {RL} by leveraging and transferring external expertise to boost the learning process of {RL}. In this survey, we review the central issues of transfer learning in the {RL} domain, providing a systematic categorization of its state-of-the-art techniques. We analyze their goals, methodologies, applications, and the {RL} frameworks under which the transfer learning techniques are approachable. We discuss the relationship between transfer learning and other relevant topics from the {RL} perspective and also explore the potential challenges as well as future development directions for transfer learning in {RL}.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="keitakurita_intuitive_2018" class=ref>
<summary class=citation>
<a id="keitakurita_intuitive_2018">[keitakurita_intuitive_2018]</a> - keitakurita, Author - <a href="http://mlexplained.com/2018/01/10/an-intuitive-explanation-of-why-batch-normalization-really-works-normalization-in-deep-learning-part-1/" target="_blank"><cite>An Intuitive Explanation of Why Batch Normalization Really Works (Normalization in Deep Learning Part 1)</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite keitakurita_intuitive_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-115" id="summaryabstract-115">Summary/Abstract</a></h1>
<div>Batch normalization is one of the reasons why deep learning has made such outstanding progress in recent years. Batch normalization enables the use of higher learning rates, greatly accelerating th…</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sukhbaatar_adaptive_2019" class=ref>
<summary class=citation>
<a id="sukhbaatar_adaptive_2019">[sukhbaatar_adaptive_2019]</a> - Sukhbaatar, Sainbayar, Grave, Edouard, Bojanowski, Piotr, Joulin, Arm,  - <a href="http://arxiv.org/abs/1905.07799" target="_blank"><cite>Adaptive Attention Span in Transformers</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite sukhbaatar_adaptive_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-116" id="summaryabstract-116">Summary/Abstract</a></h1>
<div>We propose a novel self-attention mechanism that can learn its optimal attention span. This allows us to extend significantly the maximum context size used in Transformer, while maintaining control over their memory footprint and computational time. We show the effectiveness of our approach on the task of character level language modeling, where we achieve state-of-the-art performances on text8 and enwiki8 by using a maximum context of 8k characters.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="vaswani_attention_2017" class=ref>
<summary class=citation>
<a id="vaswani_attention_2017">[vaswani_attention_2017]</a> - Vaswani, Ashish, Shazeer, Noam, Parmar, Niki, Uszkoreit, Jakob, Jones, Llion, Gomez, Aidan N., Kaiser, Lukasz, Polosukhin, Illia - <a href="http://arxiv.org/abs/1706.03762" target="_blank"><cite>Attention Is All You Need</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite vaswani_attention_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-117" id="summaryabstract-117">Summary/Abstract</a></h1>
<div>The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.8 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="ba_layer_2016" class=ref>
<summary class=citation>
<a id="ba_layer_2016">[ba_layer_2016]</a> - Ba, Jimmy Lei, Kiros, Jamie Ryan, Hinton, Geoffrey E. - <a href="http://arxiv.org/abs/1607.06450" target="_blank"><cite>Layer Normalization</cite></a>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite ba_layer_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-118" id="summaryabstract-118">Summary/Abstract</a></h1>
<div>Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="ioffe_batch_2015" class=ref>
<summary class=citation>
<a id="ioffe_batch_2015">[ioffe_batch_2015]</a> - Ioffe, Sergey, Szegedy, Christian - <a href="http://arxiv.org/abs/1502.03167" target="_blank"><cite>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite ioffe_batch_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-119" id="summaryabstract-119">Summary/Abstract</a></h1>
<div>Training Deep Neural Networks is complicated by the fact that the distribution of each layer&#x27;s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on {ImageNet} classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="mnih_human-level_2015" class=ref>
<summary class=citation>
<a id="mnih_human-level_2015">[mnih_human-level_2015]</a> - Mnih, Volodymyr, Kavukcuoglu, Koray, Silver, David, Rusu, Andrei A., Veness, Joel, Bellemare, Marc G., Graves, Alex, Riedmiller, Martin, Fidjel, , Andreas K., Ostrovski, Georg, Petersen, Stig, Beattie, Charles, Sadik, Amir, Antonoglou, Ioannis, King, Helen, Kumaran, Dharshan, Wierstra, Daan, Legg, Shane, Hassabis, Demis - <a href="http://www.nature.com/articles/nature14236" target="_blank"><cite>Human-level control through deep reinforcement learning</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite mnih_human-level_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-120" id="summaryabstract-120">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="blank_quantum_2020" class=ref>
<summary class=citation>
<a id="blank_quantum_2020">[blank_quantum_2020]</a> - Blank, Carsten, Park, Daniel K., Rhee, June-Koo Kevin, Petruccione, Francesco - <a href="https://www.nature.com/articles/s41534-020-0272-6" target="_blank"><cite>Quantum classifier with tailored quantum kernel</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite blank_quantum_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-121" id="summaryabstract-121">Summary/Abstract</a></h1>
<div>Kernel methods have a wide spectrum of applications in machine learning. Recently, a link between quantum computing and kernel theory has been formally established, opening up opportunities for quantum techniques to enhance various existing machine-learning methods. We present a distance-based quantum classifier whose kernel is based on the quantum state fidelity between training and test data. The quantum kernel can be tailored systematically with a quantum circuit to raise the kernel to an arbitrary power and to assign arbitrary weights to each training data. Given a specific input state, our protocol calculates the weighted power sum of fidelities of quantum data in quantum parallel via a swap-test circuit followed by two single-qubit measurements, requiring only a constant number of repetitions regardless of the number of data. We also show that our classifier is equivalent to measuring the expectation value of a Helstrom operator, from which the well-known optimal quantum state discrimination can be derived. We demonstrate the performance of our classifier via classical simulations with a realistic noise model and proof-of-principle experiments using the {IBM} quantum cloud platform.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="keitakurita_building_2019" class=ref>
<summary class=citation>
<a id="keitakurita_building_2019">[keitakurita_building_2019]</a> - keitakurita, Author - <a href="https://mlexplained.com/2019/07/04/building-the-transformer-xl-from-scratch/" target="_blank"><cite>Building the Transformer {XL} from Scratch</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite keitakurita_building_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-122" id="summaryabstract-122">Summary/Abstract</a></h1>
<div>With the release of {XLNet}, the Transformer {XL} is the new cool kid on the block. Although the Transformer {XL} is simple in concept, actually understanding the details is harder than might meet the ey…</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="keskar_ctrl:_nodate" class=ref>
<summary class=citation>
<a id="keskar_ctrl:_nodate">[keskar_ctrl:_nodate]</a> - Keskar, Nitish Shirish, {McCann}, Bryan, Varshney, Lav R, Xiong, Caiming, Socher, Richard - <cite>{CTRL}: A {CONDITIONAL} {TRANSFORMER} {LANGUAGE} {MODEL} {FOR} {CONTROLLABLE} {GENERATION}</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite keskar_ctrl:_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-123" id="summaryabstract-123">Summary/Abstract</a></h1>
<div>Large-scale language models show promising text generation capabilities, but users cannot easily control particular aspects of the generated text. We release {CTRL}, a 1.63 billion-parameter conditional transformer language model, trained to condition on control codes that govern style, content, and task-speciﬁc behavior. Control codes were derived from structure that naturally co-occurs with raw text, preserving the advantages of unsupervised learning while providing more explicit control over text generation. These codes also allow {CTRL} to predict which parts of the training data are most likely given a sequence. This provides a potential method for analyzing large amounts of data via model-based source attribution. We have released multiple full-sized, pretrained versions of {CTRL} at https://github.com/salesforce/ctrl.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="peters_deep_2018" class=ref>
<summary class=citation>
<a id="peters_deep_2018">[peters_deep_2018]</a> - Peters, Matthew E., Neumann, Mark, Iyyer, Mohit, Gardner, Matt, Clark, Christopher, Lee, Kenton, Zettlemoyer, Luke - <a href="http://arxiv.org/abs/1802.05365" target="_blank"><cite>Deep contextualized word representations</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite peters_deep_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-124" id="summaryabstract-124">Summary/Abstract</a></h1>
<div>We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model ({biLM}), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging {NLP} problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="domingos_master_2015" class=ref>
<summary class=citation>
<a id="domingos_master_2015">[domingos_master_2015]</a> - Domingos, Pedro - <cite>The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World</cite>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite domingos_master_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-125" id="summaryabstract-125">Summary/Abstract</a></h1>
<div>A thought-provoking and wide-ranging exploration of machine learning and the race to build computer intelligences as flexible as our {ownIn} the world&#x27;s top research labs and universities, the race is on to invent the ultimate learning algorithm: one capable of discovering any knowledge from data, and doing anything we want, before we even ask. In The Master Algorithm, Pedro Domingos lifts the veil to give us a peek inside the learning machines that power Google, Amazon, and your smartphone. He assembles a blueprint for the future universal learner--the Master Algorithm--and discusses what it will mean for business, science, and society. If data-ism is today&#x27;s philosophy, this book is its bible.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="van_de_ven_brain-inspired_2020" class=ref>
<summary class=citation>
<a id="van_de_ven_brain-inspired_2020">[van_de_ven_brain-inspired_2020]</a> - van de Ven, Gido M., Siegelmann, Hava T., Tolias, Andreas S. - <a href="https://www.nature.com/articles/s41467-020-17866-2" target="_blank"><cite>Brain-inspired replay for continual learning with artificial neural networks</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite van_de_ven_brain-inspired_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-126" id="summaryabstract-126">Summary/Abstract</a></h1>
<div>Artificial neural networks suffer from catastrophic forgetting. Unlike humans, when these networks are trained on something new, they rapidly forget what was learned before. In the brain, a mechanism thought to be important for protecting memories is the reactivation of neuronal activity patterns representing those memories. In artificial neural networks, such memory replay can be implemented as ‘generative replay’, which can successfully – and surprisingly efficiently – prevent catastrophic forgetting on toy examples even in a class-incremental learning scenario. However, scaling up generative replay to complicated problems with many tasks or complex inputs is challenging. We propose a new, brain-inspired variant of replay in which internal or hidden representations are replayed that are generated by the network’s own, context-modulated feedback connections. Our method achieves state-of-the-art performance on challenging continual learning benchmarks (e.g., class-incremental learning on {CIFAR}-100) without storing data, and it provides a novel model for replay in the brain.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wooldridge_brief_2021" class=ref>
<summary class=citation>
<a id="wooldridge_brief_2021">[wooldridge_brief_2021]</a> - Wooldridge, Michael - <cite>A Brief History of Artificial Intelligence: What It Is, Where We Are, and Where We Are Going</cite>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite wooldridge_brief_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-127" id="summaryabstract-127">Summary/Abstract</a></h1>
<div>From Oxford&#x27;s leading {AI} researcher comes a fun and accessible tour through the history and future of one of the most cutting edge and misunderstood field in science: Artificial {IntelligenceThe} somewhat ill-defined long-term aim of {AI} is to build machines that are conscious, self-aware, and sentient; machines capable of the kind of intelligent autonomous action that currently only people are capable of. As an {AI} researcher with 25 years of experience, professor Mike Wooldridge has learned to be obsessively cautious about such claims, while still promoting an intense optimism about the future of the field. There have been genuine scientific breakthroughs that have made {AI} systems possible in the past decade that the founders of the field would have hailed as miraculous. Driverless cars and automated translation tools are just two examples of {AI} technologies that have become a practical, everyday reality in the past few years, and which will have a huge impact on our world.While the dream of conscious machines remains, Professor Wooldridge believes, a distant prospect, the floodgates for {AI} have opened. Wooldridge&#x27;s A Brief History of Artificial Intelligence is an exciting romp through the history of this groundbreaking field--a one-stop-shop for {AI}&#x27;s past, present, and world-changing future.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="bengio_neural_2003" class=ref>
<summary class=citation>
<a id="bengio_neural_2003">[bengio_neural_2003]</a> - Bengio, Yoshua, Ducharme, Réjean, Vincent, Pascal, Janvin, Christian - <cite>A neural probabilistic language model</cite>. - 2003. -
<button onclick="copyToClipboard('\{\{ #cite bengio_neural_2003 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-128" id="summaryabstract-128">Summary/Abstract</a></h1>
<div>A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sutton_reinforcement_1998" class=ref>
<summary class=citation>
<a id="sutton_reinforcement_1998">[sutton_reinforcement_1998]</a> - Sutton, Richard S., Barto, Andrew G. - <cite>Reinforcement learning: an introduction</cite>. - 1998. -
<button onclick="copyToClipboard('\{\{ #cite sutton_reinforcement_1998 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-129" id="summaryabstract-129">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lundberg_unified_2017" class=ref>
<summary class=citation>
<a id="lundberg_unified_2017">[lundberg_unified_2017]</a> - Lundberg, Scott, Lee, Su-In - <a href="http://arxiv.org/abs/1705.07874" target="_blank"><cite>A Unified Approach to Interpreting Model Predictions</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite lundberg_unified_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-130" id="summaryabstract-130">Summary/Abstract</a></h1>
<div>Understanding why a model makes a certain prediction can be as crucial as the prediction&#x27;s accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, {SHAP} ({SHapley} Additive {exPlanations}). {SHAP} assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_state_nodate" class=ref>
<summary class=citation>
<a id="noauthor_state_nodate">[noauthor_state_nodate]</a> - N/A - <a href="https://ruder.io/state-of-transfer-learning-in-nlp/" target="_blank"><cite>The State of Transfer Learning in {NLP}</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_state_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-131" id="summaryabstract-131">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
        
        

    </body>
</html>
