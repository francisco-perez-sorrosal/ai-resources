<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>AI Resources</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
        <!-- MathJax -->
        <script async type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded "><a href="overview.html"><strong aria-hidden="true">1.</strong> Overview</a></li><li class="chapter-item expanded "><a href="history.html"><strong aria-hidden="true">2.</strong> Timeline/History</a></li><li class="chapter-item expanded "><a href="applications.html"><strong aria-hidden="true">3.</strong> Applications</a></li><li class="chapter-item expanded "><a href="multidisciplinary_approach.html"><strong aria-hidden="true">4.</strong> A Multidisciplinary Approach</a></li><li class="chapter-item expanded "><a href="approaches.html"><strong aria-hidden="true">5.</strong> Approaches</a></li><li class="chapter-item expanded "><a href="classical_ml.html"><strong aria-hidden="true">6.</strong> &quot;Classical&quot; Machine Learning</a></li><li class="chapter-item expanded "><a href="topics.html"><strong aria-hidden="true">7.</strong> Advanced Machine and Deep Learning Topics</a></li><li class="chapter-item expanded "><a href="nlp.html"><strong aria-hidden="true">8.</strong> NLP</a></li><li class="chapter-item expanded "><a href="system_design.html"><strong aria-hidden="true">9.</strong> System Design</a></li><li class="chapter-item expanded "><a href="productionizing.html"><strong aria-hidden="true">10.</strong> To Production</a></li><li class="chapter-item expanded "><a href="tools_and_frameworks.html"><strong aria-hidden="true">11.</strong> Tools and Frameworks</a></li><li class="chapter-item expanded "><a href="books_and_resources.html"><strong aria-hidden="true">12.</strong> Books and Resources</a></li><li class="chapter-item expanded "><a href="conferences.html"><strong aria-hidden="true">13.</strong> Conferences</a></li><li class="chapter-item expanded "><a href="vocabulary.html"><strong aria-hidden="true">14.</strong> Vocabulary</a></li><li class="chapter-item expanded "><a href="people.html"><strong aria-hidden="true">15.</strong> People</a></li><li class="chapter-item expanded affix "><a href="bibliography.html">Bibliography</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">AI Resources</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#overview" id="overview">Overview</a></h1>
<p>At the beginning of 2021, it's been some years by now that we are immersed in the world of data, the Big Data. In the last few years, <a href="https://www.forbes.com/sites/bernardmarr/2018/05/21/how-much-data-do-we-create-every-day-the-mind-blowing-stats-everyone-should-read/?sh=4a82404a60ba">we've 
generated and collected more data than in all the previous history of mankind</a>.
This fact, joint with the recent improvements in computing power in the last decades, and the advances in a wide 
diversity of fields related to cognitive sciences have propelled Artificial Intelligence and Machine Learning to a new
status of preponderance in the modern world. Modern ML has already impacted our lives, and the impact will be higher in the
forthcoming years.</p>
<p>I love AI/ML because is a very complex topic which has to be approached with a multi-disciplinary view. It's a compendium 
of the advances and applications of well proven knowledge and battle-tested technology in many other fields, including:</p>
<ul>
<li>Mathematics &amp; Statistics</li>
<li>Neuroscience</li>
<li>Computer Science</li>
<li>Philosophy</li>
<li>Psychology</li>
<li>Medicine</li>
<li>Biology</li>
<li>Physics</li>
<li>Economics</li>
<li>Algorithmic Biology</li>
</ul>
<p>However, as it is true with most of the things in life, and despite the current advances and breakthroughs in the field, 
nothing is set in stone; we are and we'll continue being forever human &amp; machine learners. As Newton stated in 1675, 
&quot;If I have seen further it is by standing on the shoulders of Giants.&quot; The only thing that is potentially different 
today from that Newton's assertion back in those days is that from now on, maybe the Giants won't be only other humans; 
maybe they'll be also artificially created machines, algorithms or models.</p>
<p>A few years ago, I found in Jorge Luis Borges' Funes the Memorious, what I thought it was a beautiful unconscious 
portrait in the form of words that I think summarizes quite well the current State of the Art of Artificial Intelligence/Machine 
Learning at the begining of the XXI century:</p>
<pre><code class="language-text">&quot;Había aprendido sin esfuerzo el inglés, el francés, el portugués, 
el latín. Sospecho, sin embargo, que no era muy capaz de pensar. 
Pensar es olvidar diferencias, es generalizar, es abstraer. En 
el abarrotado mundo de Funes no había sino detalles, casi inmediatos.&quot;

Funes el Memorioso (1944) - Jorge Luís Borges
</code></pre>
<pre><code class="language-text">&quot;With no effort, he had learned English, French, Portuguese and
Latin. I suspect, however, that he was not very capable of thought.
To think is to forget differences, generalize, make abstractions. In
the teeming world of Funes, there were only details, almost
immediate in their presence.&quot;

Funes the Memorious (1944) - Jorge Luís Borges
</code></pre>
<p>There are interesting times ahead of us. This field, joint with the advances in another promising multidisciplinary
scientific field, <a href="https://en.wikipedia.org/wiki/Bioinformatics">bioinformatics</a> and the possible fast development of
quantum computing in the next few years, guarantee endless fun for scientist and engineers in the next decades. This 
book pretends to be my modest log and diary on the topics depicted above and others that will arise along the way.</p>
<h1><a class="header" href="#mindmap" id="mindmap">Mindmap</a></h1>
<iframe width='853' height='480' src='https://gitmind.com/app/doc/0f62047898' frameborder='0' allowfullscreen></iframe><h1><a class="header" href="#timelinehistory" id="timelinehistory">Timeline/History</a></h1>
<h1><a class="header" href="#applications" id="applications">Applications</a></h1>
<ul>
<li><a href="https://research.fb.com/wp-content/uploads/2016/11/deepface-closing-the-gap-to-human-level-performance-in-face-verification.pdf">DeepFace</a> always remind me of how Schwarzenegger is framed for the murder of almost a hundred unarmed civilians in <a href="https://www.imdb.com/title/tt0093894/">The Running Man</a></li>
</ul>
<h2><a class="header" href="#prediction" id="prediction">Prediction</a></h2>
<h2><a class="header" href="#regression" id="regression">Regression</a></h2>
<h2><a class="header" href="#classification" id="classification">Classification</a></h2>
<h3><a class="header" href="#binary-classification" id="binary-classification">Binary Classification</a></h3>
<p>In this kind of applications there are only two possible classes or outcomes. The task is to assign an instance to one of these two classes, so the output is a single class label indicating one of the two possible outcomes.</p>
<p><strong>Examples</strong></p>
<ul>
<li>Spam detection (spam vs. not spam)</li>
<li>Disease diagnosis (positive vs. negative)</li>
</ul>
<p><strong>Algorithms</strong>
Logistic Regression, Support Vector Machine (SVM), Decision Trees, Random Forest, etc.</p>
<p><strong>Evaluation Metrics</strong>
Accuracy, Precision, Recall, F1-Score, Area Under the Receiver Operating Characteristic Curve (AUC-ROC).</p>
<h3><a class="header" href="#multiclass-classification" id="multiclass-classification">Multiclass Classification</a></h3>
<p>These appplications involve the classification of two or more disjoint classes The output is a single class label indicating one of the multiple possible classes.</p>
<p><strong>Examples</strong></p>
<ul>
<li>Handwritten digit recognition (digits 0-9)</li>
<li>Animal classification (cat, dog, bird, etc.)</li>
<li>Sentiment analysis (positive, negative, neutral)</li>
</ul>
<p><strong>Algorithms</strong>
Logistic Regression (softmax for multiclass), k-Nearest Neighbors (k-NN), Decision Trees, Random Forest, Neural Networks, etc.</p>
<p><strong>Evaluation Metrics</strong>
Accuracy, Precision, Recall, F1-Score (macro, micro, and weighted versions), Confusion Matrix.</p>
<h3><a class="header" href="#multilabel-classification" id="multilabel-classification">Multilabel Classification</a></h3>
<p>In multilabel classification applications, each instance can belong to multiple classes simultaneously. Unlike binary and multiclass classification, where an instance is assigned a single label, multilabel classification assigns multiple labels; so the output will be a set of class labels indicating multiple possible classes for each instance.</p>
<p><strong>Examples</strong></p>
<ul>
<li>Document categorization (e.g., a document could be about &quot;Sports&quot; and &quot;Health&quot; simultaneously)</li>
<li>Image tagging (an image could be tagged as &quot;Beach,&quot; &quot;Sunset,&quot; and &quot;Vacation&quot;)</li>
<li>Music genre classification (a song could belong to both &quot;Jazz&quot; and &quot;Blues&quot;)</li>
</ul>
<p><strong>Algorithms</strong></p>
<p>Problem Transformation Methods (e.g., One-vs-Rest, Classifier Chains), Adapted Algorithms (e.g., Adapted k-NN, Adapted Decision Trees), Deep Learning models (e.g., Convolutional Neural Networks (CNNs) with sigmoid activation in the output layer).</p>
<p><strong>Evaluation Metrics</strong></p>
<p>Hamming Loss, Precision, Recall, F1-Score (macro, micro, weighted), Subset Accuracy, Coverage Error, Ranking Loss.</p>
<h2><a class="header" href="#personalizationrecommender-systems" id="personalizationrecommender-systems">Personalization/Recommender systems</a></h2>
<p>Make decisions is a key part of what we consider intelligence. Learn from limited samples to make good decissions.</p>
<p>Multi-arm banditds (Contextual) Subcase of RL</p>
<p>Emma Brunskill</p>
<p><a href="https://prs2021.splashthat.com/">Personalization, Recommendation and Search (PRS) Workshop by Netflix</a></p>
<h2><a class="header" href="#recognition-images-audiospeech-text" id="recognition-images-audiospeech-text">Recognition (images, audio/speech, text)</a></h2>
<p>Initial techniques for image/audio/text recognition were based on lots of feature engineering that were fed to a
classical ML model such as SVM. With the advent of DL these features have been discovered automatically by using
huge datasets such as ImageNet and NN architectures based on convolutions. And further that, we now are in the
position of searching automatically for more efficient architectures (meta-architecture discovery).</p>
<p>In the same way, speech recognition used to require a lot of experts in language, preprocessing, Gaussian or Hidden
Markov models etc. but with the democratization of NN almost all those techniques are not needed anymore.</p>
<h2><a class="header" href="#computer-vision" id="computer-vision">Computer vision</a></h2>
<h2><a class="header" href="#clustering-and-anomaly-detection" id="clustering-and-anomaly-detection">Clustering and anomaly detection</a></h2>
<h2><a class="header" href="#natural-language-processing-generation-and-understanding" id="natural-language-processing-generation-and-understanding">Natural language processing, generation, and understanding</a></h2>
<p>For a more in depth analysis of the SotA in NLP see <a href="nlp.html">the corresponding chapter</a>.</p>
<h2><a class="header" href="#translation" id="translation">Translation</a></h2>
<p>Being one of the initial fields for research in NLP, traditionally, machine translation was based on sentence-based
statistical techniques. With the advent of big data and computing power, neural networks have taken over the field. </p>
<p>For example, along 2016/2017 Google switched from sentence-based/linguistic expert-based algorithmic approach to deep
-learning based methods (what is called Neural Machine Translation, or NMT.) The leap in quality of the transations
was massive:</p>
<ul>
<li><a href="https://blog.google/products/translate/found-translation-more-accurate-fluent-sentences-google-translate/">Found in translation: More accurate, fluent sentences in Google Translate (Barak Turovsky, Google Translate Product Lead, Nov 2016</a></li>
<li><a href="https://www.blog.google/products/translate/higher-quality-neural-translations-bunch-more-languages/">Higher quality neural translations for a bunch more languages (Barak Turovsky, Google Translate Product Lead, Mar 2017)</a></li>
<li><a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html">A Neural Network for Machine Translation, at Production Scale</a></li>
<li><a href="https://www.theatlantic.com/technology/archive/2018/01/the-shallowness-of-google-translate/551570/">The Shallowness of Google Translate (Douglas Hofstadter)</a></li>
</ul>
<p>Most of those models are also multilingual, meaning that a single model is capable of translating from any source
language to any target language.</p>
<h2><a class="header" href="#financial" id="financial">Financial</a></h2>
<p>Models like FinBERT have been finetuned with a large financial corpora of articles [<a href="bibliography.html#yang_finbert_2020">yang_finbert_2020</a>]</p>
<h2><a class="header" href="#medicine" id="medicine">Medicine</a></h2>
<p>Dermatology - Detect skin cancer or problematic skin-related diseases.</p>
<h2><a class="header" href="#legallaw" id="legallaw">Legal/Law</a></h2>
<h2><a class="header" href="#gaming" id="gaming">Gaming</a></h2>
<p>Games have been always been a center of attention for AI, being backgamon, chess or Go, probably the most popular
examples. Initially, most of the approaches were rule-based expert systems. There were some exceptions such as
[Unknown bib ref: sejknowsy_deep_2018] Since the success of Deep Blue and more recently AlphaGo and AlphaZero beating grandmasters, the
field of AI/ML has even had more impact.</p>
<p>But the success in board games is not only the only focus of attention of the game industry. StarCraft is another
popular game strategy/intereactive game where the researchers in AI have done amazing improvements in playing against
humans.</p>
<h3><a class="header" href="#programing-languages" id="programing-languages">Programing Languages</a></h3>
<ul>
<li><a href="https://www.oreilly.com/radar/automated-coding-and-the-future-of-programming/?sfmc_id=85378584&amp;utm_medium=email&amp;utm_source=platform+b2b&amp;utm_campaign=engagement&amp;utm_content=whats+new+thinking+20200831">Automated Coding article (O'Reilly)</a></li>
<li><a href="https://arxiv.org/pdf/2006.03511.pdf">Unsupervised Translation of Programming Languages</a></li>
</ul>
<h3><a class="header" href="#databases" id="databases">Databases</a></h3>
<p>Even traditional fields of Computer Science such as DBMSs can't escape from the influence of AI these days. In [Unknown bib ref: krasa_case_2017] the authors replace DBMS core components with NNs being able to improve the performance of caches of classical data structures for data management -such as B-Trees- while using less system resources such as memory/disk space.</p>
<h1><a class="header" href="#ai-as-a-multidisciplinary-approach" id="ai-as-a-multidisciplinary-approach">AI as a Multidisciplinary Approach</a></h1>
<p>This chapter is devoted to describe high level concepts, topics and discussions that other disciplines around ML are
providing.</p>
<h1><a class="header" href="#brain---computer" id="brain---computer">Brain -&gt; Computer</a></h1>
<p>With what we have now know about the brain, we can definitely say that does not operate on logical functions.
The brain is a compound of deeply intertwined subsystems based on neurons that mix the properties of analog and digital
signals.</p>
<h2><a class="header" href="#error-correction-in-the-brain" id="error-correction-in-the-brain">Error Correction in the Brain</a></h2>
<p>Apart from studying information <a href="people.html#John_von_Neumann">John von Neumman</a> studied the brain and how can it be reliable
most of the time out of unreliable components (e.g. neurons misfiring in a particular region of the brain) He concluded
that redundancy was the key to make the brain correct mistakes. Redundancy is also key to build reliable centralized and distributed systems in computer
software.</p>
<h1><a class="header" href="#algorithms-and-dl" id="algorithms-and-dl">Algorithms and DL</a></h1>
<p>In Chapter 13 of his [The Deep Learning Revolution] book, T. Segnosky talks about the work of <a href="people.html#Stephen_Wolfgram">Stephen Wolfgram</a>
and mentions what he calls Wofgram's law in the realm of neural networks. In April 2020, Wofgram presented his theory about
a new approach to find a fundamental theory of physics joint with an <a href="https://www.wolframphysics.org/">accompanying project</a>
to the world in an extensive <a href="https://writings.stephenwolfram.com/2020/04/finally-we-may-have-a-path-to-the-fundamental-theory-of-physics-and-its-beautiful/">blog post</a>.
He blog post points to with a document of more than 400 pages {{ cite wolfgram_class_2020 }} where he details all his ideas.</p>
<p>Since then, <a href="https://www.scientificamerican.com/article/physicists-criticize-stephen-wolframs-theory-of-everything/#:%7E:text=Stephen%20Wolfram%20blames%20himself%20for%20not%20changing%20the%20face%20of%20physics%20sooner.&amp;text=At%20its%20heart%2C%20Wolfram&#x27;s%20new,resemble%20lines%20of%20computer%20code.">researchers haven't been very receptive</a>
with his ideas. However, if from his theory we distill the idea that a meta-algorithm could be defined and used
to find other neural networks, that seems to smell to what <a href="https://francisco-perez-sorrosal.github.io/qc-resources/">Quantum Computing</a>
may bring to the table in the future if it develops its full potential. In particular, Sejnowsky raises the question of
whether it would be possible to find a region of the algorithm space faster than with gradient descent and how that
may not be that crazy if it's compared with what nature has done to evolve organisms (he cites Stephen Jay Gould and Niles
Eldredge and the process they described in 1972 as <a href="https://en.wikipedia.org/wiki/Punctuated_equilibrium">&quot;punctuated equilibria&quot;</a>.</p>
<iframe width='853' height='480' src='https://en.wikipedia.org/wiki/Punctuated_equilibrium#/media/File:Fossils_in_Evolutionary_Biology.png' frameborder='3' allowfullscreen>Example of Punctuated Equilibrium in Fossils</iframe>
<h1><a class="header" href="#aproaches-and-flavors-in-aiml" id="aproaches-and-flavors-in-aiml">Aproaches and Flavors in AI/ML</a></h1>
<h2><a class="header" href="#approaches-to-ml" id="approaches-to-ml">Approaches to ML</a></h2>
<p>The following categorization is done for simplification and is based on the one done by Pedro Domingos in 
[<a href="bibliography.html#domingos_master_2015">domingos_master_2015</a>]. The influence of each one of them has varied along the evolution of machine learning, 
but in the end all them influence each other in some way or another; so, many times, the &quot;boundaries&quot; we humans
tend to trace among them (or in any other categorization) they only exist in our imagination.</p>
<h3><a class="header" href="#symbolist" id="symbolist">Symbolist</a></h3>
<p>Learning is viewed as a kind of inverse approach of deduction. Very influenced by logic and the need of humans
to try to represent abstract problems in a human-readable way to facilitate communication with each other. It had early 
successes in early AI computer programs, in particular in the era of [expert systems](vocabulary.md#Expert System).</p>
<h3><a class="header" href="#connectionist" id="connectionist">Connectionist</a></h3>
<p>Basically this approach is based on studying the recent advances in cognitive sciences related to how the brain works 
and try to do a reverse engineering process of what has been learn. In cognitive sciences there have been and still
are many  researchers that advocate for ToMs that posits that the mind is only made up of randomly arranged neurons. We 
can say Artificial Neural Networks (ANNs) were the main result of this line of though.</p>
<p>However, this view is a very restricted one for many other researchers, for example <a href="people.html#gary-marcus">Gary Marcus</a> 
There are other trends like Neural-Symbolic systems that try to combine ANN and logic
{{ cite besold_neural-symbolic_2018 }} to try to build systems able to learn and reason.</p>
<p>As neuroscience is indeed influenced by physics
the connectionists, may model also the artificial neurons based on the physical properties observed in real neurons
. That's why in this approach we can include also the neuromorphic approach, which models neurons in a more similar
fashion to the neurons in the brain. For example, a neuromorphic neuron uses  just 1-bit spike to communicate with other neurons. 
Neurons can send these spikes in order to activate more or less neurons connected to them. <a href="people.html#carver-mead">Carver Mead</a>
was one of the initial contributors in developing this approach. More recently, <a href="https://www.ibm.com/blogs/research/category/neuromorphic-computing/?mhsrc=ibmsearch_a&amp;mhq=neuromorphic%20computing">IBM</a> 
or the <a href="http://e-lab.github.io/index.html">e-lab</a> at Purdue university have continued developing these ideas of this
field, now called <a href="vocabulary.html#neuromorphic-computing">neuromorphic computing</a>. Although there are <a href="http://apt.cs.manchester.ac.uk/projects/SpiNNaker/">simulators
</a> 
in conventional hardware for modelling this approach, this is highly ineficient, as for example, among other limitations
, 32-bits are used to model 1-bit spikes, so in order to fully develop neurorphic computing special hardware is needed. </p>
<h4><a class="header" href="#from-the-early-days-in-connectionism-towards-deep-learning" id="from-the-early-days-in-connectionism-towards-deep-learning">From the Early Days in Connectionism, towards Deep Learning</a></h4>
<pre><code class="language-textmate">Alan Turing's Intelligence Machinery (1948) -&gt; Perceptron (1962) -&gt; Hopfield Net (1982) -&gt; Bolzman Machines(1985) -&gt; Backprop (1986) -&gt; First NIPS Conf. (1987) -&gt; Deep Learning matures as a field on its own in NIPS Conf. (2012)
</code></pre>
<h3><a class="header" href="#evolutionary" id="evolutionary">Evolutionary</a></h3>
<p>Influenced by genetics and evolutionary biology, this approach tries to simulate this evolutionary environment
through computers. </p>
<h3><a class="header" href="#bayesian" id="bayesian">Bayesian</a></h3>
<p>This approach is based mainly in applying probabilistic inference to mimic the learning process and of course is
strongly influenced by mathematics and statistics. </p>
<p><a href="topics.html#Causality">Causal inference</a> can also be included in this approach. Human beings we tend to approach situations in terms of
cause and effect; this framework of thinking often modifies our behaviour when we find (or at least we think we've 
found) WHY a certain event has occurred and what are its consequences.</p>
<p>Some of the main advocates of this approach in its modern conception is <a href="people.html#Judea_Pearl">Judea Pearl</a>.</p>
<h4><a class="header" href="#analogizers" id="analogizers">Analogizers</a></h4>
<p>They consider that learning is done by abstracting and reconciling experiences. Influenced by psychology and cognitive
sciences in general and math optimization.</p>
<h3><a class="header" href="#actioninst" id="actioninst">Actioninst</a></h3>
<p>The approach is based on the fact that a limited set of basic behaviours or states in a system can lead to more complex 
ones, by correcting themselves through observation and subsequent action. This has to do to what is known as [reinforcement learning](#Reinforcement Learning)
and <a href="https://en.wikipedia.org/wiki/Behavior-based_robotics">behavioral robotics</a>. 
In the case of robots, this paradigm advocates that the most effective mechanism to learn sensory-motor cognitive 
abilities like walking, should be based on interactions with the environment. After all, this is more or less how toddlers
learn to walk; model these kind of interactions programmatically through abstract reasoning based on rules, 
it's inefficient and prone to errors. </p>
<h3><a class="header" href="#autonomicsurvivalistic" id="autonomicsurvivalistic">Autonomic/Survivalistic</a></h3>
<p>The approach is based on the fact that intelligent complex systems like humans, are able to survive on their own. In
order to do that, we rely in parts of the brain that either are not well understood now or they haven't taken into account
yet in the artificial systems implemented. This can be related to the field of <a href="https://en.wikipedia.org/wiki/Autonomic_computing">autonomic computing</a>.</p>
<p>Some of these brain areas are:</p>
<ul>
<li>
<p>Hypothalamus, which controls basic non-conscious subsystems related to maintaining body temperature, thirst, hunger 
and other homeostatic systems. Some of these could be mimicked by a computer system; e.g. the case of feeding, an 
intelligent ingestion data pipeline could be feeding a self-adaptive a neural network.</p>
</li>
<li>
<p>Cerabellum, which is located near the brainstem, and is responsible to coordinate movements. In the case of robotics,
this is related to the field of <a href="https://en.wikipedia.org/wiki/Behavior-based_robotics">behavioral robotics</a> and all the
advances done by companies such as <a href="https://www.bostondynamics.com/">Boston Dynamics</a>, Samsung STAR Labs or NASA.</p>
</li>
</ul>
<h3><a class="header" href="#adaptable" id="adaptable">Adaptable</a></h3>
<p>Kind of similar to the <a href="approaches.html#Autonomic/Survivalistic">Autonomic/Survivalistic</a> approach but taken from the 
point of view of computer science instead of the survival of species.
When modeling learning in with an artificial machine/algorithms, why be limited by Turing Machines? Human computational
power is way beyond what a Turing machine is capable to do and this approach tries to mimic that. The adaptable approach
is related to what is known as the Super-Turing Computation or [Lifelong Learning](topics.md#Continual Learning and Catastrophic Forgetting). 
This is also related to the <a href="https://www.darpa.mil/program/time-aware-machine-intelligence">Time-Aware Machine Intelligence (TAMI) program</a> at DARPA, 
which aims to model meta-learning.</p>
<h2><a class="header" href="#flavors-in-ml" id="flavors-in-ml">Flavors in ML</a></h2>
<h3><a class="header" href="#reinforcement-learning" id="reinforcement-learning">Reinforcement Learning</a></h3>
<p>A branch of machine learning that was influenced by the associative learning approach observed in animals and
newborns/young adults.</p>
<h1><a class="header" href="#classical-machine-learning" id="classical-machine-learning">&quot;Classical&quot; Machine Learning</a></h1>
<h2><a class="header" href="#overview-of-machine-learning" id="overview-of-machine-learning">Overview of Machine Learning</a></h2>
<p>Machine learning (ML) has been traditionally the field of artificial intelligence (AI) that enables systems to learn from data and make decisions with minimal human intervention. Unlike traditional programming, where rules are explicitly programmed, ML models identify patterns in data to make predictions or decisions.</p>
<p>In the recent years, the term <em>&quot;Classical Machine Learning&quot;</em> has been coined to refer and encompass the initial set of algorithms and techniques that, till the begininig of thew century, have been foundational in the field of machine learning for decades. These methods typically include:</p>
<ul>
<li>linear regression</li>
<li>logistic regression</li>
<li>decision trees</li>
<li>support vector machines (SVM)</li>
<li>k-nearest neighbors (KNN)</li>
</ul>
<p>Most of these classical ML methods often require the so-called feature engineering, where domain knowledge is used to create meaningful input features from raw data. These models are generally effective for structured data, that is, those where relationships between input features and output labels are relatively straightforward.</p>
<p>As of 2024, the now so-called Classical Machine Learning serve as the foundational bedrock of more modern ML techniques. The algorithm and methods in this context still provide very robust and interpretable models supporting a wide range of applications. As we will see later, Deep Learning (DL) partly builds on these foundational techniques, and has enabled more recently new breakthroughs in fields that require processing even more complex, high-dimensional data. Finally, the term Generative AI has been introduced in the last few years to take DL methods a step further, allowing machines not just to learn from data, but to create new content that mimics or enhances human creativity. As we will see, each of these areas has its unique strengths, limitations, and use cases. Toghether, they form the broad and rapidly evolving landscape of the modern artificial intelligence.</p>
<h3><a class="header" href="#types-of-machine-learning" id="types-of-machine-learning">Types of Machine Learning</a></h3>
<p>TODO Add the Supervised vs Unsupervised vs Semi-Sup</p>
<h2><a class="header" href="#key-algorithms-in-classical-machine-learning" id="key-algorithms-in-classical-machine-learning">Key Algorithms in Classical Machine Learning</a></h2>
<p>TODO Complement with the new stuff</p>
<ul>
<li>
<p><strong>Linear Regression</strong>:</p>
<ul>
<li>A method used for predicting a continuous dependent variable based on one or more independent variables. The model assumes a linear relationship between the input variables and the output.</li>
<li><strong>Formula</strong>: ( y = \beta_0 + \beta_1x_1 + \ldots + \beta_nx_n + \epsilon )</li>
<li><strong>Applications</strong>: Predicting house prices, stock market trends, and other scenarios where the relationship between variables is assumed to be linear.</li>
</ul>
</li>
<li>
<p><strong>Logistic Regression</strong>:</p>
<ul>
<li>A classification algorithm used for binary classification problems (i.e., where the output can be one of two classes). It predicts the probability that a given input belongs to a certain class.</li>
<li><strong>Formula</strong>: ( \text{logit}(p) = \log\left(\frac{p}{1-p}\right) = \beta_0 + \beta_1x_1 + \ldots + \beta_nx_n )</li>
<li><strong>Applications</strong>: Spam detection, disease diagnosis, and credit scoring.</li>
</ul>
</li>
<li>
<p><strong>Decision Trees</strong>:</p>
<ul>
<li>A non-parametric supervised learning algorithm used for classification and regression. The model splits the data into subsets based on the value of input features, creating a tree-like structure.</li>
<li><strong>Key Concepts</strong>: Nodes, branches, and leaves. Each internal node represents a decision based on a feature, each branch represents the outcome of the decision, and each leaf node represents the final prediction.</li>
<li><strong>Applications</strong>: Customer segmentation, fraud detection, and decision-making processes.</li>
</ul>
</li>
<li>
<p><strong>Support Vector Machines (SVM)</strong>:</p>
<ul>
<li>A supervised learning model that finds the optimal hyperplane that best separates the data into classes in a high-dimensional space. SVM can be used for both classification and regression tasks.</li>
<li><strong>Key Concepts</strong>: Hyperplane, support vectors, margin. SVM aims to maximize the margin between the data points of different classes.</li>
<li><strong>Applications</strong>: Image classification, text categorization, and bioinformatics.</li>
</ul>
</li>
<li>
<p><strong>K-Nearest Neighbors (KNN)</strong>:</p>
<ul>
<li>A simple, non-parametric algorithm used for classification and regression. The model classifies a data point based on the majority class among its k nearest neighbors in the feature space.</li>
<li><strong>Key Concepts</strong>: Distance metrics (e.g., Euclidean, Manhattan), choosing k (number of neighbors).</li>
<li><strong>Applications</strong>: Handwritten digit recognition, recommendation systems, and medical diagnosis.</li>
</ul>
</li>
<li>
<p><strong>Naive Bayes</strong>:</p>
<ul>
<li>A probabilistic classifier based on Bayes' theorem, assuming independence between the features. Despite the naive assumption of independence, it performs well in many real-world applications.</li>
<li><strong>Formula</strong>: ( P(C|X) = \frac{P(X|C)P(C)}{P(X)} )</li>
<li><strong>Applications</strong>: Spam filtering, sentiment analysis, and document classification.</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#model-evaluation-and-validation" id="model-evaluation-and-validation">Model Evaluation and Validation</a></h2>
<p>TODO Complement with the new stuff</p>
<ul>
<li><strong>Train-Test Split</strong>: The dataset is divided into a training set (used to train the model) and a test set (used to evaluate the model's performance).</li>
<li><strong>Cross-Validation</strong>: A technique where the dataset is split into multiple subsets, and the model is trained and evaluated multiple times, each time using a different subset as the validation set. This helps in getting a more reliable estimate of model performance.</li>
<li><strong>Performance Metrics</strong>:
<ul>
<li><strong>Accuracy</strong>: The ratio of correctly predicted instances to the total instances.</li>
<li><strong>Precision, Recall, and F1-Score</strong>: Metrics particularly important for imbalanced datasets.</li>
<li><strong>Confusion Matrix</strong>: A matrix that shows the actual versus predicted classifications, helping to identify true positives, false positives, false negatives, and true negatives.</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#regularization-techniques" id="regularization-techniques">Regularization Techniques</a></h2>
<p>TODO Complement with the new stuff</p>
<ul>
<li><strong>Purpose</strong>: Regularization techniques are used to prevent overfitting by adding a penalty to the loss function for more complex models.</li>
<li><strong>Types</strong>:
<ul>
<li><strong>L1 Regularization (Lasso)</strong>: Adds the absolute value of coefficients as a penalty to the loss function. Encourages sparsity in the model (some coefficients become exactly zero).</li>
<li><strong>L2 Regularization (Ridge)</strong>: Adds the square of the coefficients as a penalty to the loss function. Encourages smaller coefficients, but all coefficients remain in the model.</li>
<li><strong>Elastic Net</strong>: A combination of L1 and L2 regularization, balancing sparsity and small coefficients.</li>
</ul>
</li>
</ul>
<h2><a class="header" href="#feature-engineering" id="feature-engineering">Feature Engineering</a></h2>
<p>TODO Complement with the new stuff</p>
<ul>
<li><strong>Feature Selection</strong>: The process of selecting the most relevant features for the model to improve accuracy and reduce overfitting.</li>
<li><strong>Feature Scaling</strong>: Techniques like normalization and standardization to ensure that all features contribute equally to the model, especially important for algorithms like SVM and KNN.</li>
<li><strong>Feature Transformation</strong>: Applying mathematical transformations to features, such as logarithms or polynomial expansions, to capture nonlinear relationships.</li>
</ul>
<h2><a class="header" href="#summary-and-next-steps" id="summary-and-next-steps">Summary and Next Steps</a></h2>
<p>Machine learning is a vast and continuously evolving field getting feedback from many different areas, so it's important to keep learning and exploring new concepts and techniques. With new algorithms, techniques, and applications emerging regularly, staying up-to-data with the latest research papers, attend conferences and webinars, and follow reputable blogs and forums will keep yourself informed about the latest advancements in the field.</p>
<p>However, as we showed in this chapter a strong grasp of the fundamentals of the so-called &quot;classical machine learning&quot; algorithms, model evaluation techniques, and feature engineering is crucial not only for understanding and building new and robust machine learning models that conform (or will conform) many modern (future) software applications, but to continue this learning process.</p>
<p>With a good understanding of the foundations, the next steps will be exploring more recent advanced ML Techniques: For example, dive deeper into more complex algorithms such as ensemble methods (e.g., random forests, gradient boosting), support vector machines, and neural networks. These techniques can provide more powerful models for complex and high-dimensional data.</p>
<p>Also gaining practical hands-on experience is crucial. Applying the acquired knowledge by working on real-world ML projects, finding datasets and problem statements that interest you, and start building and evaluating machine learning models will be very helpful to solidify your understanding and develop practical skills.</p>
<h1><a class="header" href="#advanced-machine-and-deep-learning-topics" id="advanced-machine-and-deep-learning-topics">Advanced Machine and Deep Learning Topics</a></h1>
<h1><a class="header" href="#nlp" id="nlp">NLP</a></h1>
<p>Initially, the NLP or Computational Linguistics field was focused on applying the generative grammar approach described by <a href="people.html#noam_comsky">Noam Chomsky</a> in <a href="https://en.wikipedia.org/wiki/Generative_grammar">the mid 60s</a>.
However, the results of applying that approach was never impressive.</p>
<p>Since then, other approachs like tagging Part of Speech (PoS) in sentences and applying statistical techniques have been demostrated to be more successful in the NLP field. As it's usually described in any other modern ML field, the successful application of these techniques has been only possible due to the increase in computing power and the tagging and recollection
of big datasets that have occurred in the last coupule of decades.</p>
<p>Nowadays, in the start of the third decade of the XXI century, the so called language models are predominant and applied in many of the problems related to NLP.</p>
<h2><a class="header" href="#frameworks" id="frameworks">Frameworks</a></h2>
<ul>
<li><a href="https://huggingface.co/">Huggingface</a> The de-facto standard framework for modern NLP.</li>
<li><a href="https://github.com/lucidrains/x-transformers">X-Transformers</a> A new repo, implementing also the later
advances in the spectrum of Transformer-based models.</li>
<li><a href="https://github.com/NervanaSystems/nlp-architect">NLP Architect</a></li>
</ul>
<h2><a class="header" href="#websites-blogs--repos" id="websites-blogs--repos">Websites, Blogs &amp; Repos</a></h2>
<ul>
<li><a href="https://paperswithcode.com/">Papers with Code</a></li>
<li><a href="http://nlpprogress.com/">NLP Progress</a></li>
<li><a href="https://github.com/neubig/lowresource-nlp-bootcamp-2020">NLP Bootcamp</a> CMU lectures on NLP by visitors to the
Language Technologies Institute.</li>
</ul>
<h1><a class="header" href="#nlp-topics" id="nlp-topics">NLP Topics</a></h1>
<h2><a class="header" href="#text-categorization" id="text-categorization">Text Categorization</a></h2>
<p>One of the classical problems in NLP.</p>
<p><strong>Goal</strong>: Assign labels/tags to text examples (e.g. sentences, paragraphs, documents...)
<strong>Options for doing text annotation</strong>:</p>
<ul>
<li>Manual - Reliess on humnans; Because of that fact this approachss doesn't scale, is costly, and error prone.</li>
<li>Automatic - The current trend due to the increasingly amount of text examples required for many applications in the
industry.
<ul>
<li>Rule-based methods
<ul>
<li>Use a set of predefined rules</li>
<li>Require domain knowledge from experts</li>
</ul>
</li>
<li>ML-driven methods
<ul>
<li>Use a set of prelabeled examples to train models.</li>
<li>Learn -during a training phase- based on observations of data contrasted against the true/gold labels already
tagged by domain experts for a certain number of the so-called train examples.</li>
<li>The final model obtained with this method has learned associations between the text and the labels</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>We will focus on this approach only, and mainly on the ML-driven methods.</p>
<p><strong>Applications</strong>:</p>
<ol>
<li>Sentiment analysis</li>
<li>News classification</li>
<li>Content moderation</li>
<li>Spam filtering</li>
<li>Question-answering</li>
<li>Natural language inference
...</li>
</ol>
<h3><a class="header" href="#procedure" id="procedure">Procedure</a></h3>
<p>The traditional way of doing text classification consists of these steps:</p>
<ol start="0">
<li><strong>Dataset creation</strong> - Create (or download, if a well-know industry used dataset is considered to be used) at least
two datasets from the text examples available: train and test. See <a href="datasets.html">Datasets</a> section for more information.</li>
<li><strong>Preprocessing</strong> - Some handcrafted <a href="vocabulary.html#feature">features</a> are [extracted](vocabulary.md#feature
-engineering) from the train and test datasets. This may require also to do some transformations on the raw input data.</li>
<li><strong>Training</strong> - From each train example, use the features extracted + its associated label, as input to train a model
that will
learn associations from the features and the labels to make predictions on new input features.</li>
<li><strong>Testing</strong> - Feed a model with the features extracted from each test example to the train model to obtain a
prediction.</li>
<li><strong>Evaluation</strong> - Take each prediction obtained and contrast it with the corresponding true/gold label for test
examples and calculate the required <a href="metrics.html">metrics</a> for the classification problem at hand.</li>
</ol>
<p>Popular Algorithms used for text classification are <a href="algorithms_and_model_architectures.html#naive-bayes">Naive Bayes</a>,
<a href="algorithms_and_model_architectures.html#support-vector-machines">SVMs</a>, <a href="algorithms_and_model_architectures.html#hidden-markov-models">HMMs</a>,
<a href="algorithms_and_model_architectures.html#gradient-boosting-trees">GBTs</a> and <a href="algorithms_and_model_architectures.html#random-forests">random forests
</a></p>
<h2><a class="header" href="#entity-recognition" id="entity-recognition">Entity Recognition</a></h2>
<h2><a class="header" href="#question-answering" id="question-answering">Question-Answering</a></h2>
<h1><a class="header" href="#nlp-architectures" id="nlp-architectures">NLP Architectures</a></h1>
<h1><a class="header" href="#nlp-papers" id="nlp-papers">NLP Papers</a></h1>
<h2><a class="header" href="#recent-origins" id="recent-origins">Recent Origins</a></h2>
<p>These papers influenced a paradigm shift towards what will be called <a href="vocabulary.html#deep-learning">Deep Learning</a>, which will imply the massive adoption of neural networks for ML tasks.</p>
<h3><a class="header" href="#word2vec" id="word2vec">Word2Vec</a></h3>
<p>&quot;Efficient Estimation of Word Representations in Vector Space&quot; [<a href="bibliography.html#mikolov_efficient_2013">mikolov_efficient_2013</a>] and &quot;Distributed 
Representations of Words and Phrases and their Compositionality&quot; [Unknown bib ref: mikolov_distributed_2013] or simply the
Word2Vec papers by Mikolov et al. at Google marked a paradigm shift in NLP, as it showed the potential of an embedding
model trained in large amounts of data (1.6 Billion data words). In particular, they showed the quality of the </p>
<p>representations obtained after training by using a word similarity task.
A deeper explanation can be found in &quot;word2vec Explained: deriving Mikolov et al.'s negative-sampling word-embedding
method&quot; {{ cite goldbert_word2vec_2014 }}</p>
<p><a href="https://code.google.com/archive/p/word2vec/">Google Source code</a> 
<a href="https://github.com/tmikolov/word2vec">Source code</a></p>
<p>The following is an amazing explanation of the W2V paper: <a href="https://jalammar.github.io/illustrated-word2vec/">Illustrated Word2Vec</a></p>
<h3><a class="header" href="#glove" id="glove">Glove</a></h3>
<p>Problem with Word Embeddings is that the representations that are spit out of them, despite they are powerful (e.g. 
you can do vector arithmetic with them), they are very shallow; shallow in the sense that only the first layer
(called the embedding layer) has seen all the huge corpus where where the vector representations were trained on. The
rest of the layers of the potentially deep NN model (e.g. LSTM or GRU) will be trained only on a (probably) way small
dataset for the application at hand.</p>
<p>So, why not pretrain more layers in order to learn grammar, disambiguate words based on context, etc.? This question
lead to the development of the so called <a href="vocabulary.html#language-model">Language Models</a>.</p>
<h3><a class="header" href="#elmo" id="elmo">Elmo</a></h3>
<p>&quot;Deep contextualized word representations&quot; {{ cite peters_deep_2018 }} a.k.a. the &quot;Elmo&quot; paper, improved the results
obtained by Word2Vec. The main difference is that Elmo adds context to word representations. Word vectors are
learned functions of the internal states of a deep bidirectional language model (biLM), pre-trained also on a large
text corpus. Essentially the model architecture is a stacked LSTM. This marked the start of the &quot;Sesame Street Saga&quot;.</p>
<p><a href="https://www.slideshare.net/shuntaroy/a-review-of-deep-contextualized-word-representations-peters-2018">Slides</a></p>
<h3><a class="header" href="#ulmfit" id="ulmfit">ULMFit</a></h3>
<p>A 2018 LM from <a href="people.html#jeremy-howard">Jeremy Howard</a> and other <a href="http://fast.ai/">fast.ai</a> guys.</p>
<h2><a class="header" href="#attention" id="attention">Attention</a></h2>
<p>This was a game changer paper when it appeared in 2017 {{ cite vaswani_attention_2017 }}.
The concept of attention is taken, as many others, from cognitive sciences (e.g. psycology, neuroscience, education.) It
describes the process of focusing on certain concrete stimulus/stimuli while ignoring the rest of stimuli in an
environment. In the case of NLP for example, the context/environment can be a sentence and the stimulus a word.</p>
<ul>
<li><a href="">Attention and Memory-Augmented Networks for Dual-View Sequential Learning (KDD 2020)</a></li>
</ul>
<p>Encoder Components:</p>
<ol>
<li>(Masked) Self-Attention</li>
</ol>
<p>Input: Sequence of tensors (e.g. representing words in a sentence)
Output: Sequence of tensors; each one is a weighted sum of the input sequence</p>
<p>See <a href="vocabulary.html#normalization">Normalization</a> for more info on normalization.</p>
<ol start="2">
<li>Positional Encoding</li>
</ol>
<p>As word order is an important factor in LMs, Transformers combine word embeddings with position embeddings in its
input. This encoding will take into account the order of words when doing the computations. </p>
<ol start="3">
<li>Layer Normalization</li>
</ol>
<p>More resources on Transformers:</p>
<p><a href="http://peterbloem.nl/blog/transformers">Peter Bloem's Blog Entry</a></p>
<p>Apart from the attention mechanism, in there's been some recent research focus on how changing the attention layer
<a href="https://medium.com/syncedreview/google-replaces-bert-self-attention-with-fourier-transform-92-accuracy-7-times-faster-on-gpus-7a78e3e4ac0e">for a FFT</a>
can sped up the Transformer encoder architectures [Unknown bib ref: leethorp_fnet_2021]. </p>
<h4><a class="header" href="#sparse-transformers" id="sparse-transformers">Sparse Transformers</a></h4>
<ul>
<li><a href="refs.html#sparse">Sparse Tansformer</a> Self-attention complexity from O(n2) to O(n*sqrt(n)).</li>
<li><a href="refs.html#reformer">Reformer</a> Self-attention complexity O(L2) to O(LlogL), where L is the length of the sequence.</li>
<li><a href="refs.html#linformer">Linformer</a> Self-attention complexity from O(n2) to O(n) in both time and space.</li>
</ul>
<h2><a class="header" href="#transformers" id="transformers">Transformers</a></h2>
<p>Despite the Transformers architecture is very popular, it still has its drawbacks; for example it is
expensive to use with long sequences, e.g. with n &gt; 512. This makes this kind of models limited for certain NLP
tasks such as QA or summarization. More recent models such as Longformer, Performer, Reformer
, or Clustered attention have tried to address this problem by approximating the otherwise potentially huge attention
matrix. Out of those models, <a href="nlp.html#big-bird">BigBird</a> seems to be the one that has achieve this goal more
effectively.</p>
<h3><a class="header" href="#sesame-street-saga" id="sesame-street-saga">Sesame Street Saga</a></h3>
<p>The <a href="nlp.html#elmo">ELMO</a> paper started a trend to name many NLP model architectures and variations after the characters of
Sesame Street/Muppets. Some refer to this fenomenon as <a href="https://www.theverge.com/2019/12/11/20993407/ai-language-models-muppets-sesame-street-muppetware-elmo-bert-ernie">&quot;Muppetware&quot;</a>
These are the most relevant ones.</p>
<p>TODO mention at least <del>ELMo,</del> BERT, Grover, Big BIRD, Rosita, RoBERTa, ERNIEs, and KERMIT.</p>
<h4><a class="header" href="#bert" id="bert">BERT</a></h4>
<p>By 2018 Google developed what is still as of 2021, the SotA of embedding-based models for the majority of the industry.
Based on the Transformer architecture, it was trained on 3.3 billion words. Comming in two different flavours, base
and large, they mainly differ on the number of parameters.</p>
<p>BERT [<a href="bibliography.html#devlin_bert_2019">devlin_bert_2019</a>] has become the de-facto reference model for NLP since 2018.</p>
<h4><a class="header" href="#roberta-unknown-bib-ref-liu_roberta_2019" id="roberta-unknown-bib-ref-liu_roberta_2019">RoBERTa [Unknown bib ref: liu_roberta_2019]</a></h4>
<p>Replication study of BERT pretraining that measures the impact of many key hyperparameters (Bigger Batch size and LR) and training data size (10X).
It shows improvements on most of the SotA results by BERT and followers. Questions the results of some post-BERT models.
It uses a single sentence for the document-level input like SpanBERT.</p>
<p><a href="https://github.com/pytorch/fairseq">Original Code</a></p>
<ul>
<li><a href="https://arxiv.org/abs/1810.04805">BERT</a> The reference model for NLP since 2018.</li>
<li><a href="https://arxiv.org/pdf/1907.10529.pdf">SpanBERT</a>
Masks spans of words instead of random subwords. Spans of words refers to global entities or loca/domain-specific meaning (e.g. American Football)
Span Boundary Objective(SBO) predicts the span context from boundary token representations. Uses single sentence document-level inputs instead of
the two sentences in BERT.
Code: <a href="https://github.com/facebookresearch/SpanBERT">https://github.com/facebookresearch/SpanBERT</a></li>
<li><a href="https://arxiv.org/abs/1907.11692">RoBERTa</a>
Replication study of BERT pretraining that measures the impact of many key hyperparameters (Bigger Batch size and LR) and training data size (10X).
It shows improvements on most of the SotA results by BERT and followers. Questions the results of some post-BERT models.
It uses a single sentence for the document-level input like SpanBERT.
Code: <a href="https://github.com/pytorch/fairseq">https://github.com/pytorch/fairseq</a></li>
</ul>
<h4><a class="header" href="#sparse-transformers-1" id="sparse-transformers-1">Sparse Transformers</a></h4>
<ul>
<li><a href="refs.html#sparse">Sparse Tansformer</a> Self-attention complexity from O(n2) to O(n*sqrt(n)).</li>
<li><a href="refs.html#reformer">Reformer</a> Self-attention complexity O(L2) to O(LlogL), where L is the length of the sequence.</li>
<li><a href="refs.html#linformer">Linformer</a> Self-attention complexity from O(n2) to O(n) in both time and space.</li>
</ul>
<h4><a class="header" href="#a-hrefhttpsarxivorgpdf190710529pdfspanberta" id="a-hrefhttpsarxivorgpdf190710529pdfspanberta"><a href="https://arxiv.org/pdf/1907.10529.pdf">SpanBERT</a></a></h4>
<p>Masks spans of words instead of random subwords. Spans of words refers to global entities or loca/domain-specific meaning (e.g. American Football)
Span Boundary Objective(SBO) predicts the span context from boundary token representations. Uses single sentence document-level inputs instead of
the two sentences in BERT.</p>
<p><a href="https://github.com/facebookresearch/SpanBERT">Original Code</a></p>
<h4><a class="header" href="#reformer" id="reformer">Reformer</a></h4>
<p>The main advantage of this model is that provides an attention mechanism for long sequences with O(Nlog(N))</p>
<h4><a class="header" href="#performer" id="performer">Performer</a></h4>
<h4><a class="header" href="#big-bird" id="big-bird">Big Bird</a></h4>
<p>The main questions according the authors of Big Bird that the paper addresses successfully are:</p>
<ul>
<li>&quot;Can we achieve the empirical benefits of a fully quadratic self-attention scheme using fewer inner-products?&quot;</li>
<li>&quot;Do these sparse attention mechanisms preserve the expressivity and flexibility of the original network?&quot;</li>
</ul>
<p>This model [<a href="bibliography.html#zaheer_big_2020">zaheer_big_2020</a>] relies on what the authors call block sparse attention instead of the regular
O(N^2) attention mechanism. The attention in Big Bird is summarized in the following picture:</p>
<p><img src="images/big_bird_att.png" alt="Big Bird Attention" /></p>
<h5><a class="header" href="#small-modelssmall-devices" id="small-modelssmall-devices">Small Models/Small Devices</a></h5>
<ul>
<li><a href="refs.html#lite">Lite transformer with Long-Short Range Attention</a>
Uses Long-Short Range Attention (LSRA) in which a group of heads specializes in
the local context (using convolution) and another group specializes in the
long-distance relationships (ussing the attention mechanism.) Focus on edge (mobile) devices.</li>
</ul>
<details>
  <summary>Small Models</summary>
 * [Distilbert](https://arxiv.org/abs/1910.01108)
 Check it out in https://huggingface.co/
</details>
<details>
  <summary>Other Sesame Street Papers</summary>
<ul>
<li><a href="https://arxiv.org/abs/1908.10063">FinBERT</a> Bert applied to Financial Sentiment Analysis.
Code: <a href="https://github.com/ProsusAI/finBERT">https://github.com/ProsusAI/finBERT</a>]</li>
<li><a href="refs.html#abcd">FinBERT</a></li>
</ul>
</details>
<h3><a class="header" href="#non-sesame-street-environment" id="non-sesame-street-environment">Non-Sesame Street Environment</a></h3>
<p>** <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/">Turing NLG</a>
&quot;Turing Natural Language Generation (T-NLG) is a 17 billion parameter language model by Microsoft that outperforms the state of the art on many downstream NLP
tasks. We present a demo of the model, including its freeform generation, question answering, and summarization capabilities, to academics for feedback and
research purposes. &lt;|endoftext|&gt;&quot; - Summary generated by itself.</p>
<h2><a class="header" href="#gpt-family" id="gpt-family">GPT Family</a></h2>
<p>Generative Pre-trained Transformer.
In the same way as <a href="nlp.html#elmo">ELMO</a> and <a href="nlp.html#umlfit">UMLFit</a> learns to predict the next word in a sentence. The main
difference with those two is that GPT, as BERT, uses an embedding layer and transformer layers instead of LSTMs.
It uses masked self-attention as it conditions only on preceding words.</p>
<p>GPT-2 was trained on 8M Web pages and comes in different sizes. It was considered at that time (2019) &quot;too 
dangerous&quot; to be publicly available. One of the tasks it was able to perform relatively well was the 
<a href="people.html#winograd">Winograd</a> Schema challenge for common sense reasoning, and in particular, pronoun dissambiguation.</p>
<p><a href="https://app.inferkit.com/demo">Talk to Transformer (Now inferkit)</a></p>
<h3><a class="header" href="#gpt-3" id="gpt-3">GPT-3</a></h3>
<p>175 Billion parameters, several thousands of GPUs to train and more than a month of training.
Weights weren't released due to concerns in potential misuses. There's a global effort by <a href="https://www.eleuther.ai/">EleutherAI</a> to make the
training and publish the weights open sourced.</p>
<h2><a class="header" href="#t5" id="t5">T5</a></h2>
<p>Text-To-Text Transfer Transformer, hence T5 [<a href="bibliography.html#raffel_exploring_2020">raffel_exploring_2020</a>]. And because of the Text-To-Text part
, input is a string and output is too.</p>
<p>Some of the figures are impressive:</p>
<ul>
<li>Released on early 2020</li>
<li>Trained on C4 corpus (100x bigger than Wikipedia)</li>
<li>11 Billion params</li>
<li>SotA in GLUE, SuperGlue and SQuAD</li>
</ul>
<p>Google Switch Transformer, has 1.6 Trillion parameters. </p>
<h3><a class="header" href="#lifelong-learning-in-nlp" id="lifelong-learning-in-nlp">Lifelong learning in NLP</a></h3>
<ul>
<li><a name="biesialska"><a href="https://www.aclweb.org/anthology/2020.coling-main.574.pdf">Continual Lifelong Learning in Natural Language Processing: A Survey</a> Colling, 2020</a></li>
</ul>
<h3><a class="header" href="#few-shot-learning-in-nlp" id="few-shot-learning-in-nlp">Few-Shot Learning in NLP</a></h3>
<p><a href="vocabulary.html#few-shot-learning">FSL</a> in NLP has been used successfully in applications like parsing translation
, sentence completion, sentiment classification from reviews, user intent classification for dialog systems, 
criminal charge prediction, word similarity tasks such as nonce definition, and multi-label text classification.
Recently, a new relation classification data set called FewRel [52] is released. </p>
<p>This compensates for the lack of benchmark data set for FSL tasks in natural language processing.</p>
<h2><a class="header" href="#text-generation" id="text-generation">Text Generation</a></h2>
<p>Data-to-Text Generation (DTG) or simpy, text generation is a subfield of NLP which pursues the automatic generation of
human-readable text using computational linguistics and AI.</p>
<p>Approaches to text generation use a <a href="vocabulary.html#language-model">language model (LM)</a> to generate the probability
distribution from we can sample to generate the next token in a sentence.</p>
<p>In the last few years, one of the most used generative models is the so-called Recurrent Neural Networks (RNN) that
have been used successfully also for other NLP task such as classification.</p>
<p>However, LMs per-se, despite promising for text generation, are limited in the control terms that humans
have for &quot;influencing&quot; the generated content. The problem relies on the fact that, once the models are trained
, it becomes difficult add control attributes without modifying the architecture to allow extra input
attributes or tuning with extra data. The prompts written by humans or generated automatically act just a starting
cue for the generator, but does not allow to control other properties such as define the topic of the generated
text.</p>
<p>Without these control attributes, models tend to <a href="vocabulary.html#hallucination">&quot;hallucinate&quot;</a>.
More recent approaches to text generation include these control mechanism: CTRL [Unknown bib ref: shirish_ctrl_2019] and PPLM
[<a href="bibliography.html#dathathri_plug_2020">dathathri_plug_2020</a>].</p>
<p><a href="https://github.com/salesforce/ctrl">Conditional Transformer Language (CTRL)</a> introduces control codes to condition the
language model. These control
codes govern
the style, content, and task-specific
behavior of the generated text. More specifically, the control codes allow 1) preserve the advantages of unsupervise
learning; 2) seamless
integration in the structure of the raw while providing the required control over generation, and 3) predict which
parts  of the training data are most likely given a sequence.</p>
<p>CTRL is trained on control codes that co-occur narurally with the original text typically used for training LMs.
Big datasets such Wikipedia are assigned with a domain-related control code; other smaller datasets (e.g. content from
specific online communities in Reddit are assigned to a broader domain name (Reddit) and with subdomain information
(e.g. r/politics.) All control codes can be traced to a particular subset of the training data.
Moreover, the codes can be combined with codes during generation to cross-over task-specific and domain/content
behaviors.</p>
<p>As CTRL, Plug and Play Language Model (PPLM) combines a pretrained LM with n &quot;attribute classifiers&quot; which allow to
drive the text generation process externally without architectural changes. This work was influenced by the
Plug &amp; Play Generative Networks (PPGN) work in computer vision (2017). In PPGN a discriminator (attribute model)
[ p(a|x) ] is plugged with a generative model p(x), so that sampling from the resulting [ p(x|a) \propto p(a|x
)p(x) ], effectively creates a generative model conditioned from the provided attribute a.
As the attribute is plugged post facto in the activation space, no further fine-tuning is required.</p>
<p>Another recent work is {{ cite rebuffel_controlling_2021 }}, based on RNNs. This work addresses hallucination by
treating it at a
word level, which is a more fine-grained approach than other works, which deal with hallucination at the instance
level. It proposes a procedure that consist of: 1) a word-level labeling procedure built on dependency parsing and
based on co-ocurrences and sentence structure; 2) a weighted multi-branch decoder which, guided by the alignment
labels from the previous step, will used them as word-level control factors. At a training time, the decoder
will learn generating descriptions without being misled by un-factual reference information. This is due to
the fact that the model will be able to distinguish between aligned and unaligned words.</p>
<h2><a class="header" href="#evaluation" id="evaluation">Evaluation</a></h2>
<p>In NLP, there are many different tasks that can be evaluated to test different aspects of the language. Some of
them are:</p>
<ul>
<li>Named Entity Recognition (NER): identify the different entities out of the words of a text: e.g. which words are a
proper name of a person or an organization.</li>
<li>Textual Entailment: when 2 sentences are provided to the LM, the first one entails or contradicts the other?</li>
<li>Coreference Resolution: when a pronoun appears in a text (e.g. “it”) that may possibly refer to multiple objects, try
to dissambiguate which object the pronoun refers to.</li>
</ul>
<p>The following are some of the main benchmarks used in NLP around this time (2021).</p>
<h3><a class="header" href="#squad" id="squad">SQuAD</a></h3>
<ul>
<li>Original paper: [<a href="bibliography.html#rajpurkar_squad_2016">rajpurkar_squad_2016</a>]</li>
<li>Task: Question answering</li>
<li>Details: 
<ul>
<li>100K question-answer pairs with the answer included in the question</li>
</ul>
</li>
<li>Example: </li>
</ul>
<p>&quot;In meteorology, precipitation is any product
of the condensation of atmospheric water vapor
that falls under gravity. The main forms of precipitation include drizzle, rain, sleet, snow, graupel and hail... 
Precipitation forms as smaller
droplets coalesce via collision with other rain
drops or ice crystals within a cloud. Short, intense periods of rain in scattered locations are
called “showers”.</p>
<p>What causes precipitation to fall?
gravity&quot;</p>
<ul>
<li><a href="https://towardsdatascience.com/the-quick-guide-to-squad-cae08047ebee">Blog Entry about SQuAD</a></li>
</ul>
<h3><a class="header" href="#snli" id="snli">SNLI</a></h3>
<ul>
<li>Original paper: [<a href="bibliography.html#bowman_large_2015">bowman_large_2015</a>]</li>
<li>Task: Natural Language Inference</li>
<li>Details: 
<ul>
<li>Output the relationship between a piece of text and a hypothesis.</li>
<li>570K pairs</li>
</ul>
</li>
<li>Example:</li>
</ul>
<p>&quot;A black race car starts up in front of a crowd of people.</p>
<p>contradiction
C C C C C</p>
<p>A man is driving down a lonely road&quot;</p>
<h3><a class="header" href="#glue" id="glue">GLUE</a></h3>
<ul>
<li>Original Paper: [<a href="bibliography.html#wang_glue_2019">wang_glue_2019</a>]</li>
<li>Task: 9 tasks
<ul>
<li>Is sentence grammatical or not</li>
<li>Sentiment analysis (+,-,=)</li>
<li>Sentence B paraphrase of A?</li>
<li>Sentence similarity</li>
<li>Two questions similar?</li>
<li>Sentence Entailment</li>
<li>Entailment or contradiction?</li>
<li>B contains answer of question A?</li>
<li>Correct/incorrect referents (pronoums)?</li>
</ul>
</li>
<li>Details:
<ul>
<li><a href="https://mccormickml.com/2019/11/05/GLUE/">Blog Entry</a></li>
</ul>
</li>
</ul>
<h3><a class="header" href="#superglue" id="superglue">SuperGLUE</a></h3>
<p>TODO</p>
<h1><a class="header" href="#designing-machinedeep-learning-systems" id="designing-machinedeep-learning-systems">Designing Machine/Deep Learning Systems</a></h1>
<p>When a business problem involves machine learning and deep learning system, designing such a system to be suitable for production involves much more than just choosing the right model. Several components and/or third party systems will need to be designed, developed and/or integrated in order to ensure a sytem meeting the business expectations and ready to deliver real value.</p>
<p>On one side, careful consideration of the entire training/evaluation/deployment lifecycle will be required, from data collection and preprocessing to model training, deployment, and maintenance.</p>
<p>On the oter side, taking into consideration non-functional features, like ensuring that the system is scalable, secure, and compliant with regulations will be also critical. By taking a holistic approach, you can build a robust, efficient, and effective machine learning system that delivers real value to the business.</p>
<p>So, as we will see below, putting a complex system like that into production can be really challenging and convoluted.</p>
<p>In the sections below, I will outline whay I consider the main topics to address when designing an ML system. These guidelines can also serve as a useful reference for interviews.</p>
<p>Designing a machine learning (ML) system involves a thoughtful balance of various considerations to ensure the system is effective, scalable, and maintainable. Below there is a set of general considerations (described as a sequential pipeline of tasks) when designing an ML system, explained in an educational manner:</p>
<h2><a class="header" href="#problem-definition-and-scope" id="problem-definition-and-scope">Problem Definition and Scope</a></h2>
<h3><a class="header" href="#understanding-the-business-objective" id="understanding-the-business-objective">Understanding the Business Objective</a></h3>
<p>Way before diving into the technical aspects, it is critical to understand the problem at hand. The initial question we should ask is, &quot;What is the business need?&quot; Following that, &quot;How will success be measured?&quot;, which would allow us determine how to determine the success of the solution. Only once we have a high-level view of the business objective and understand the basic success criteria, can we proceed with more technical aspects such as the selection of data, models, and evaluation metrics.</p>
<h3><a class="header" href="#project-scope-and-constraints" id="project-scope-and-constraints">Project Scope and Constraints</a></h3>
<p>As with any software project, it is essential to understand the <strong>scope and constraints</strong> of the task at hand. Defining the scope of the problem is critical to avoid setting unrealistic expectations. Also, it is important to identify any constraints, such as time, budget, or computational resources, that could poetentially impact our project's scope. This comprehensive understanding is key to establishing <em>realistic goals and expectations</em> for our project.</p>
<h2><a class="header" href="#data-management" id="data-management">Data Management</a></h2>
<h3><a class="header" href="#data-collection" id="data-collection">Data Collection</a></h3>
<p>Data is critical for (almost) any ML/DL problem. So, <strong>identify the sources  where the data will come from</strong> is one of the first things we'll need to figure out. Do we already have that data, is it generated internally from our current systems?, is it sourced from third-party APIs, or collected from sensors? are the kind of questions we'll have to answer here.</p>
<p>If the data sources are key, its <strong>quality</strong> is even more important. Ensuring the data is of high quality—clean, complete, and relevant will be the next step, as poor data quality will most likely lead to unreliable and useless models.</p>
<h3><a class="header" href="#data-preprocessing" id="data-preprocessing">Data Preprocessing</a></h3>
<p>If the data is of poor quality we most likely will have to do some <strong>data clieaning</strong>; this involves for example handle missing values, remove duplicates, or correct inconsistencies.</p>
<p>In addition to that we will probably need to do certain <strong>data transformations</strong> to prepare the data as input to the different building blocks of our training/production systems. This encompasses tasks liken normalize/standardize the data, or apply feature engineering to make the data suitable for certain models.</p>
<p>Very close to the tasks above will be the consideration of <strong>data storage</strong> solutions that suit each part of the process best. Choosing appropriately these solutions depending on the data volume and access speed requirements may be influenced by the constrains identified at the begining. Options include shared/cloud fault-tolerant filesystems, data streams, relational databases, NoSQL databases, data lakes, etc.</p>
<h2><a class="header" href="#model-selection-and-training" id="model-selection-and-training">Model Selection and Training</a></h2>
<p>The tasks of <strong>choosing an algorithm/model</strong> may come next. The algorithm/model(s) should align with the problem at hand: type—regression, classification, clustering, etc. For example, linear regression for continuous output prediction, or decision trees for classification.</p>
<p>Along with this, a <strong>trade-off between model complexity and interpretability</strong> may be necessary to consider, again, depending on the project constraints. Complex models like the ones involved in deep learning, may offer higher accuracy but may harder to interpret if there's no budget for the adequate tools.</p>
<p>The <strong>training process</strong> shoule be examined next. The <strong>infrastructure</strong> used will need to be considered. Deciding whether to use on-premise servers (if available,) cloud-based solutions, or a hybrid approach for training the model will be put under perspective here. These decisions again will depend on the available computational resources.</p>
<p><strong>Hyperparameter tuning</strong>, that is, adjust the model’s hyperparameters to optimize performance will have to be considered too at some point. Do we think that the off-the shelf model standard training process will be enough to meet the identified metrics, or we would have to apply techniques like grid search or random search to boost those?</p>
<p>This step will link the training to the <strong>evaluation process</strong>. Here, the <strong>metrics</strong> identified in the first step will be the guiding principle. As we showed, those were selected appropriately based on the problem, but may need to be revisited or complemented here, in case we missed someting. For example, for classification problems, accuracy, precision, recall, and F1-score are commonly used. In regression problems, mean squared error (MSE) or R-squared are more relevant.</p>
<p>Also, in classical ML problems, applying techniques such as <strong>cross-validation</strong> (described in Chapter <a href="classical_ml.html">Classical ML</a>)-e.g. k-fold cross-validation- to ensure that the <strong>model generalizes well to unseen data</strong> may be encouraged. Deep learning-based solutions will have their own protocols, such as proper creation of high quality train/dev/test splits.</p>
<h2><a class="header" href="#deployment" id="deployment">Deployment</a></h2>
<p>The next step in the pipeline turns around thinking the proper infrastructure bells and whistles for deploying the trained model.</p>
<h3><a class="header" href="#model-serving" id="model-serving">Model Serving</a></h3>
<p>Here, the <strong>serving infrastructure</strong> will need to be evaluated. Decisions on how the model will be served need to be considered here. Options may include REST APIs, batch processing, real-time streaming predictions or ad-hoc approaches, depending on the problem at hand.</p>
<p>Close to the serving infrastructure decision will come questions related to the <strong>scalability of the system</strong>. These questions will have to do to with ensuring that the system can scale to handle increased loads. Techniques like load balancing and horizontal scaling are of essential consideration here.</p>
<p><strong>Latency and Throughput</strong> may determine also the quality of the final solution for certain problems. <strong>Optimizing</strong> the model and/or certain architectural solutions considering latency requirements —how quickly does the system need to respond? will need to be adressed here. <strong>Caching</strong> mechanisms may help also to reduce load and speed up response times for frequently requested predictions.</p>
<h2><a class="header" href="#monitoring-and-maintenance" id="monitoring-and-maintenance">Monitoring and Maintenance</a></h2>
<p>This involves mainly the following tasks:</p>
<h3><a class="header" href="#performance-monitoring" id="performance-monitoring">Performance Monitoring</a></h3>
<p>In the Context of ML/DL, performance monitoring refers to the process of continuously tracking and evaluating the performance of the ML model deployed in the system. It involves monitoring various metrics and indicators to ensure that the model is functioning as expected and delivering accurate results. It is an essential non-functional aspect of ML systems design as it is aimed to guarantee that the current model deployed continues to deliver accurate results over time. It enables proactive measures to maintain the model's accuracy, diagnose issues, optimize performance, and enhance the overall system's reliability.</p>
<p>More in detail, this monitoring serves:</p>
<h4><a class="header" href="#model-drift-detection" id="model-drift-detection">Model Drift Detection</a></h4>
<p>Identifying model drift is maybe the most important aspect of ML monitoring. A model drift is said to occur when the input data distribution feeding the model changes over time, which may lead to a decline in the model's accuracy. A good monitoring can detect that degradation and raise the alarms or trigger the appropriate actions to maintain the model's accuracy.</p>
<h4><a class="header" href="#logging-and-error-tracking" id="logging-and-error-tracking">Logging and Error Tracking</a></h4>
<p>Monitoring has implied recording predictions, errors, and other key performance metrics along the inference pipeline. This information will be critical for diagnosing issues, optimizing performance, and enhancing the overall system's reliability. It will also allow us to track the model's behavior, identify patterns, and troubleshoot any errors or anomalies that may arise during the life of the system.</p>
<h4><a class="header" href="#optimization-and-improvement" id="optimization-and-improvement">Optimization and Improvement</a></h4>
<p>Overall, by monitoring the performance of the ML system, we will gain insights into its strengths and weaknesses. This information can be used to optimize the model, fine-tune hyperparameters, and improve the overall system's performance. Performance monitoring helps you identify areas where the model may be underperforming or where there is room for improvement.</p>
<h3><a class="header" href="#continual-learning-automated-retraining" id="continual-learning-automated-retraining">Continual Learning (Automated Retraining)</a></h3>
<p>This concept is also know continuous learning or lifelong learning; it refers to the capability of a ML/DL model to continually update and adapt over time as it receives new data, without needing to be retrained from scratch. If a process like this is incorporated into our final system, it will ensure that the model can &quot;evolve&quot; and stay resilient to data distribution changes or as new patterns emerge in the real world input data.</p>
<p>This concept is particularly important in dynamic environments where the data is not static, and the model’s utility depends on its ability to keep learning from (aligning to) &quot;new experiences&quot; encoded in the new data distributions coming into the system.</p>
<p>This will be implemented generally by setting up automated retraining pipelines to update the model as new data becomes available. A proactive approach will help maintain the metrics in shape by adapting the model weights to the evolving data patterns. Also during the retraining we need to keep an eye on preserving the past knowledge to avoid the so-called <a href="advanced_ml_dl_topics.html#continual-learning-and-catastrophic-forgetting"><em>catastrophic forgetting</em></a></p>
<h3><a class="header" href="#alerts-and-notifications" id="alerts-and-notifications">Alerts and Notifications</a></h3>
<p>Any system is suitable from having sudden drops in model accuracy, unusual input data, or unexpected output patterns, or having some of the resources saturated/underutilized; when this happens, having a good notification subsystem is vital to the life of the system. This will enable our teams to give prompt response to those alerts.</p>
<h3><a class="header" href="#security-and-privacy" id="security-and-privacy">Security and Privacy</a></h3>
<p>When designing a ML/DL learning system, it is paramount to consider security and privacy non-functional aspects to protect sensitive data and comply with relevant regulations. </p>
<p>We will have to consider at least:</p>
<h3><a class="header" href="#data-security" id="data-security">Data Security</a></h3>
<p>Incorporating security and privacy considerations into the design of a ML/DL system, will allow us to safeguard sensitive data, protect against unauthorized access, and ensure compliance with applicable regulations/policies. This will help building trust with our users and stakeholders and mitigate potential risks associated with data breaches and/or privacy violations.</p>
<h4><a class="header" href="#access-control" id="access-control">Access Control</a></h4>
<p>Strict access control policies will ensure that only authorized users can access sensitive data and the system itself. This will help preventing unauthorized access and potential data breaches.</p>
<h4><a class="header" href="#encryption" id="encryption">Encryption</a></h4>
<p>Implement encryption techniques to protect data both at rest and in transit will complement the point above. This ensures that even if eavesdroppers gain access to the data, they won't be able to decipher it.</p>
<h3><a class="header" href="#privacy-compliance" id="privacy-compliance">Privacy Compliance</a></h3>
<p>Regulatory Compliance will ensure that the ML/DL system complies with relevant (and relative new since 2018) data protection regulations, such as the General Data Protection Regulation (GDPR) or the California Consumer Privacy Act (CCPA). This is particularly important when dealing with personal data. Compliance with these regulations helps protect individuals' privacy rights and ensures that their data is handled appropriately.</p>
<h2><a class="header" href="#collaboration-and-documentation" id="collaboration-and-documentation">Collaboration and Documentation</a></h2>
<p>Collaboration and documentation go hand in hand in ML/DL system design and are essential to the success of the final system. Both will ensure that the system is well-integrated, meets business needs, and can be easily maintained and updated.</p>
<h3><a class="header" href="#cross-functional-collaboration" id="cross-functional-collaboration">Cross-functional Collaboration</a></h3>
<p>As it happens with any complex system, building an ML/DL system is an humoungous effort. So building an effective collaboration process will ensure us that all team members are aligned and working towards a common goal. Involving stakeholders from various departments, such as data curators, data engineers, software developers, and domain experts, will be crucial in our endeavor to designing and implementing a successful system. Each team member will bring unique expertise and perspectives, contributing to the overall effectiveness and efficiency of the final system. Collaborating across functions helps ensure that the system aligns with business objectives and addresses the needs of different stakeholders.</p>
<h3><a class="header" href="#documentation" id="documentation">Documentation</a></h3>
<p>Having a comprehensive knowledge base of documentation of the entire ML/DL system is essential for future updates, maintenance, or onboarding our new new team members. It should cover various aspects, including data sources, preprocessing steps, model selection rationale, deployment processes, and maintenance plans. With these details documented, the team can easily refer back to them, understand the system's design choices, and make more informed decisions. </p>
<p>Comprehensive documentation also facilitates knowledge sharing and collaboration among team members, enabling smoother transitions and reducing the risk of knowledge gaps.</p>
<h2><a class="header" href="#ethics-and-bias" id="ethics-and-bias">Ethics and Bias</a></h2>
<p>In the context of ML/DL system design, it is crucial to address ethics and bias considerations.
By addressing ethics and bias, we will ensure that our system is fair, unbiased, and accountable. It will prevent discriminatory outcomes and will promote trust and confidence in the outputs delivered by our system. Incorporating, fairness and transparency in our design process will ground and align us more with the ethical considerations our users and stakeholders may have.</p>
<p>Some concepts to consider are related to <strong>Bias Mitigation</strong>. &quot;Bias&quot; in this context refers to systematic errors or prejudices that can affect the performance, fairness, and outcomes of a ML/DL system.</p>
<h3><a class="header" href="#fairness" id="fairness">Fairness</a></h3>
<p>When designing such a system, it is important to ensure fairness. Fairness in this context means analyzing and mitigating any biases that could result from the data or model design. These biases can arise from various sources, such as the training data itself or other biased features used in the model.</p>
<p>The main forms in which biases can manifest are:</p>
<h4><a class="header" href="#data-bias" id="data-bias">Data Bias</a></h4>
<p>The training data used to develop our system does not represent the real-world population or contains inherent biases.</p>
<h4><a class="header" href="#algorithmic" id="algorithmic">Algorithmic</a></h4>
<p>Our models produce results that are systematically prejudiced, most likely due to erroneous assumptions in the machine learning system design process</p>
<h4><a class="header" href="#user-bias" id="user-bias">User Bias</a></h4>
<p>The final design of a system reflects the biases either of its designers or of their users, potentially leading to exclusion or unfair treatment of certain groups.</p>
<p>So it will be essential to carefully examine our data and final model to identify and address  potential biases to ensure fair and equitable outcomes.</p>
<h3><a class="header" href="#transparency" id="transparency">Transparency</a></h3>
<p>Transparency is the other important aspect for addressing ethics and bias considerations in our ML system design. </p>
<p>Being transparent about how decisions are made by the model, especially in high-stakes applications like finance or healthcare will build trust with our users. </p>
<p>In the same way, providing explanations for our model's predictions or decisions can help building trust and understanding among our users and stakeholders. </p>
<p>Finally, transparency can also help us identifying and rectifying any biases or unfairness in the system.</p>
<h2><a class="header" href="#resources" id="resources">Resources</a></h2>
<h3><a class="header" href="#books" id="books">Books</a></h3>
<h4><a class="header" href="#overall-system-design" id="overall-system-design">Overall System Design</a></h4>
<p><a href="https://www.manning.com/books/acing-the-system-design-interview">Acing the System Design Interview, Zhiyong Tan</a></p>
<p><a href="https://www.amazon.com/System-Design-Interview-insiders-Second/dp/B08CMF2CQF">System Design Interview – An insider's guide, Alex Xu</a></p>
<p><a href="https://www.amazon.com/System-Design-Interview-Insiders-Guide/dp/1736049119">System Design Interview – An insider's guide Vol.2, Alex Xu</a></p>
<h4><a class="header" href="#machine-learning-system-design" id="machine-learning-system-design">Machine Learning System Design</a></h4>
<p><a href="https://www.oreilly.com/library/view/designing-machine-learning/9781098107956/">Designing Machine Learning Systems, Chip Huyen</a></p>
<ul>
<li><a href="https://github.com/chiphuyen/machine-learning-systems-design">DMLS Booklet</a></li>
</ul>
<p><a href="https://www.amazon.com/Machine-Learning-System-Design-Interview/dp/1736049127">Machine Learning System Design Interview, Ali Aminian, Alex Xu</a></p>
<p><a href="https://www.oreilly.com/library/view/ai-engineering/9781098166298/">AI Engineering, Chip Huyen</a></p>
<p><a href="https://mlsysbook.ai/">Machine Learning Systems Principles and Practices of Engineering Artificially Intelligent Systems (Harvard Univ.)</a></p>
<h3><a class="header" href="#github-resources" id="github-resources">Github Resources</a></h3>
<p><a href="https://github.com/alirezadir/Machine-Learning-Interviews/tree/main/src/MLSD">Interview Questions</a></p>
<h1><a class="header" href="#productionizing-mldl" id="productionizing-mldl">Productionizing ML/DL</a></h1>
<p>The software infrastructure stack that is required for ML projects in general, is quite different from the current stack
of non-ML projects. <a href="people.html#Andrej-Karpathy">Andrej Karpathy</a></p>
<p>These 2 papers from Sculley et al. from 2014 &amp; 2015 at NIPS [<a href="bibliography.html#sculley_machine_2014">sculley_machine_2014</a>] 
[<a href="bibliography.html#sculley_hidden_2015">sculley_hidden_2015</a>] already pointed out the complexity in building the scaffolding surrounding a machine 
learning model when has to be put into production.</p>
<p><img src="images/ml_infra.png" alt="ML Infrastructure (Source: http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf)" /></p>
<p>As it can be in the picture above, the ML model is just a very small part of the puzzle.</p>
<h2><a class="header" href="#challenges-in-putting-a-ml-model-into-production" id="challenges-in-putting-a-ml-model-into-production">Challenges in Putting a ML Model into Production</a></h2>
<ul>
<li><strong>Infrastructure and Tooling</strong>: As of 2021, current tools and platforms, mainly CI/CD do not have great support for data and/or
ML specific computing resources (e.g. GPUs/TPUs) which causes problems when trying to integrate the tasks and necessary
steps that conform a modern ML pipeline for any use case at hand.</li>
<li><strong>Culture and Organizational Structure</strong>: Companies should reorganize their divisions to accommodate this new way of producing
software systems based on a ML model. The standard model for software development does not fit here. But that doesn't mean
that data scientists should not adopt norms, techniques and tools from the traditional software development (such as 
testing) and adapt them to their needs.</li>
<li><strong>Decision Making</strong>: How to decide that a model is &quot;good enough&quot;? Check <a href="topics.html#model-interpretability">Interpretability</a> </li>
</ul>
<h1><a class="header" href="#data" id="data">Data</a></h1>
<h2><a class="header" href="#data-management-at-scale" id="data-management-at-scale">Data Management At Scale</a></h2>
<p>Data management is one of the new problems many companies in the industry are facing. Usually managed by individual teams
in isolation and with very different policies in terms of versioning, privacy and accesibility and location, with the
increasing sources of data, this has become a problem in modern companies.</p>
<p>In the past, solutions like Data Warehouses -built out of multiple of ETL processes- or its evolution, the Data Lake where the norm. 
The trend in 2021 is to evolve the Data Lake view towards the so-called <a href="https://martinfowler.com/articles/data-monolith-to-mesh.html">Data Mesh</a> are the tendency.
The idea is to scale up the </p>
<h2><a class="header" href="#datasets" id="datasets">Datasets</a></h2>
<p>It's well know that the main datasets involved in any ML process for creating a model are:</p>
<ul>
<li><strong>Train</strong>, which is the data your model will train on</li>
<li><strong>Dev</strong>, which is a representation of the test dataset used to do hyperparameter tuning, select features or make any other
decision over the model. In scikit-learn use to be called <strong>hold-out cross-validation set</strong>. </li>
<li><strong>Test</strong>, which is used exclusively for evaluating the metrics selected for the model. It should not be used to make any other
decision about the process of developing the final model.</li>
</ul>
<p>However there's more things to take into account, mainly: </p>
<ul>
<li>Main test set should mirror your online distribution</li>
<li>It's possible to collect alternative datasets
<ul>
<li>They don't have to come from the real distribution but will be useful to evaluate the model selected</li>
<li>When is this useful?
<ul>
<li>when there are certain edge cases that we need to actuate on</li>
<li>when the model has to run on multiple datasets with different modalities (e.g. English and Spanish datasets, wild and pet animals datasets)</li>
</ul>
</li>
</ul>
</li>
<li>Compare new model against:</li>
<li>
<ol>
<li>the previous model and </li>
</ol>
</li>
<li>
<ol start="2">
<li>a fixed older model (baseline)</li>
</ol>
</li>
<li>
<ol start="3">
<li>against the possible slices interesting for the business model</li>
</ol>
</li>
<li>
<ol start="4">
<li>against the alternative datasets</li>
</ol>
</li>
</ul>
<p>More information about dataset creation and quality can be found in the online book by Andrew Ng, <a href="https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf">Machine Learning Yearning</a></p>
<h2><a class="header" href="#versioning" id="versioning">Versioning</a></h2>
<p>One of the main problems that I found when I started working in the ML field 3 years ago was that there was almost no 
control of what data was used in some of experiments we were doing; the vast majority 
(if not all) of my colleagues were not using versioned data; they were just relying on the knowledge transmitted by the
old members of the team. As an outsider at that time coming from other computer science
disciplines and being more aware of software engineering techniques, that shocked me because I knew that working in a
context like that was to bring two well-known major pains for me:</p>
<ul>
<li>Back to old same problems back in the days for not having regular versioned code</li>
<li>Frustration when trying to communicate and explain that data versioning was helpful and we had to implement a policy
and use tools for keep track of the evolution of the data in our datasets </li>
</ul>
<p>But there's more when you introduce data versioning in your scope. Almost immediately it comes up to your mind that you
also have to keep track of the data-code version pairs to be able to reproduce exactly your experiments.</p>
<p>The next step is of course, find tools about version control for data. You can think immediately on Git/Github and similar
tools (Bitbucket, Gitlab, etc..) Sooner that later that those existing solutions might work for projects with
small datasets, but scalability is gonna become a problem (e.g. you can't store in git files bigger than a certain size).
Also because when building a dataset, you need certain flexibility
to manage the deltas you are adding; if you add data incrementally at some point you may create biases (e.g. by 
adding at some point many examples of a particular category in data for a classifier). It would be nice to use a tool that 
despite recognizing you added data to a dataset incrementally, it would allow you certain flexibility when building the datasets
for training/testing based on the deltas added (e.g. by skipping certain delta increments, combining only the base datasets
and two specific deltas, etc). This kind of tools that allow user to create versioned datasets and then aggregate them
by following a workflow-based data combination approach is what it would be nice to have to manage data used in ML model/experiments.</p>
<p>In Lecture 8, Slide 76 of the <a href="https://fullstackdeeplearning.com/">Full Stack DL of 2021</a> there a summary of the approaches that currently are followed
by the practitioners:</p>
<ul>
<li>Level 0 - No data versioning. Unfortunately, the most common approach.</li>
<li>Level 1 - Snapshot at training time. The next level if you are a little bit more careful when developing a new model.</li>
<li>Level 2 - Data is versioned as mix of assets and code. I pushed hard to follow this approach at least when I implemented my first ML training pipeline a couple of years ago.</li>
<li>Level 3 - New tools for integrated data versioning. An active space for developing new tools.</li>
</ul>
<h3><a class="header" href="#tools" id="tools">Tools</a></h3>
<ul>
<li></li>
<li><a href="https://dvc.org/">dvc Data Version Control</a></li>
</ul>
<h1><a class="header" href="#machine-learning-platforms-and-pipelines" id="machine-learning-platforms-and-pipelines">Machine Learning Platforms and Pipelines</a></h1>
<p>At some point, the main leaders in the software development industry decided to show off their ML platforms. Here there
are some of them.</p>
<h2><a class="header" href="#architectural-examples" id="architectural-examples">Architectural Examples</a></h2>
<ul>
<li><a href="https://eng.uber.com/michelangelo-machine-learning-platform/">Michelangelo (Uber)</a> - Uber's machine learning platform. Here, 
<a href="https://eng.uber.com/scaling-michelangelo/">there's another blogpost</a> with more details.</li>
<li><a href="https://www.youtube.com/watch?v=XV5VGddmP24">Metaflow (Netflix)</a> - They don't offer much details about the data-related
tasks (e.g. data-lake, versioning, preprocessing, etc.) available in the platform. Post about <a href="https://netflixtechblog.com/open-sourcing-metaflow-a-human-centric-framework-for-data-science-fa72e04a5d9">moving Metaflow to an open-source effort</a></li>
<li><a href="https://engineering.linkedin.com/blog/2019/01/scaling-machine-learning-productivity-at-linkedin">Pro-ML (Linkedin)</a> - Also
they don't provide much detail about the data part, which present as a silo on the left part of their architectural diagram,
and called Feature Marketplace.</li>
</ul>
<h2><a class="header" href="#regular-sw-vs-machine-learning-sw" id="regular-sw-vs-machine-learning-sw">Regular SW vs Machine Learning SW</a></h2>
<table><thead><tr><th>Traditional SW</th><th>Machine Learning</th></tr></thead><tbody>
<tr><td>Code + Config Data</td><td>Code + Data + Workflow + Config Data</td></tr>
<tr><td>Written by humans to be validated essentially by humans</td><td>Specified by humans, optimized by compilers to satisfy a proxy metric</td></tr>
<tr><td>Bugs &amp; Failures are perceived almost instantly by humans</td><td>Failures can be silent and system degradation can be imperceptible</td></tr>
<tr><td>Change according to versions</td><td>Change is almost a constant in this systems</td></tr>
</tbody></table>
<h2><a class="header" href="#errors-when-testing-ml-as-regular-sw" id="errors-when-testing-ml-as-regular-sw">Errors when Testing ML as Regular SW</a></h2>
<ol>
<li>Not analyzing sufficiently how the performance of the model is gonna be quantified and measured (metrics) and its
relation to the context where it's gonna be applied (business part)</li>
<li>Test only the model and not the system as a whole (as a consequence of 1.)</li>
<li>Missing data testing (also as a consequence of 1.)</li>
<li>Rely too much in automated testing and not in production testing</li>
<li>Lose sight of the possible divergence of the business measures against the model metrics observed (also as a consequence of 1. and 4.) </li>
</ol>
<h2><a class="header" href="#meet-the-testing-family-in-ml" id="meet-the-testing-family-in-ml">Meet The Testing Family in ML</a></h2>
<h3><a class="header" href="#label-tests" id="label-tests">Label Tests</a></h3>
<ul>
<li>Focus: Labeling system/editor tools/editors</li>
<li>Goal: Catch poor quality labels or parts of the dataset to avoid model corruption</li>
<li>Techniques:
<ul>
<li>Get trained labelers
<ul>
<li>We all are prone to biases so...</li>
</ul>
</li>
<li>Try to avoid human biases
<ul>
<li>by aggregating labels from multiple labelers</li>
</ul>
</li>
<li>Assign labelers a trust score based on how often they are wrong</li>
<li>Identify examples in training/testing processes which get different judgement from humans vs computers
<ul>
<li>Relabel those examples again and check if it's true that there were inconsistencies/errors in human and computer judgements</li>
</ul>
</li>
<li>Compare older models on new labels</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#data-tests" id="data-tests">Data Tests</a></h3>
<ul>
<li>a.k.a. Expectation Tests</li>
<li>Focus: Storage and Preprocessing Task</li>
<li>Goal: Catch bad data or data with quality issues before going to the train pipeline</li>
<li>Techniques:
<ul>
<li>Define expectations:
<ul>
<li>Assertions for data or</li>
<li>rules about properties of each of your data tables at each stage in your data cleaning/preprocessing pipeline</li>
<li>e.g. we should expect that Column X in Table A after preprocessing does not contain any null values</li>
<li>e.g. we should expect that the average value of Column Y in Table B after preprocessing should be between v1 and v2 </li>
</ul>
</li>
</ul>
</li>
<li>Tools:
<ul>
<li><a href="https://greatexpecations.io">Great Expectations</a></li>
</ul>
</li>
</ul>
<h3><a class="header" href="#infrastructure-test-aka-unit-tests-in-regular-sw-development" id="infrastructure-test-aka-unit-tests-in-regular-sw-development">Infrastructure Test (aka Unit tests in Regular SW development)</a></h3>
<ul>
<li>Focus: Training Task</li>
<li>Goal: Avoid bugs</li>
<li>Techniques:
<ul>
<li>Use unit test for the parts that are similar to regular sofware (e.g. data preparation and cleaning)</li>
<li>Extract a small sample of the dataset to test quickly over it</li>
<li>Add tests of a single epoch with the previous extracted small dataset</li>
<li>Run frequently</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#training-tests" id="training-tests">Training Tests</a></h3>
<ul>
<li>Focus: Storage and preprocessing Tasks and Training Task</li>
<li>Goal: Ensure reproducibility of training</li>
<li>Techniques:</li>
<li>Define a set of baseline metrics</li>
<li>Pull a fixed dataset representative of the full dataset</li>
<li>Check model performance remains consistent against the baseline metrics</li>
<li>Consider pulling a sliding window of data</li>
<li>As they're slow, run periodically (night or any other specific times)</li>
</ul>
<h3><a class="header" href="#functionality-tests" id="functionality-tests">Functionality Tests</a></h3>
<ul>
<li>Focus: Prediction Task</li>
<li>Goal: Avoid regressions in the code that makes up your prediction infrastructure</li>
<li>Techniques:
<ul>
<li>Unit test for the prediction code as for traditional software</li>
<li>Load model and test particular examples</li>
<li>Run frequently</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#evaluation-tests" id="evaluation-tests">Evaluation Tests</a></h3>
<ul>
<li>
<p>Focus: Training Task and Production Task</p>
</li>
<li>
<p>Goal: Validate the model to go into production by testing the integration of the two tasks above</p>
</li>
<li>
<p>Techniques:</p>
<ul>
<li>Evaluate model in all the important datasets, metrics and slices
<ul>
<li>Traditional metrics (Accuracy, Precision, Recall, etc.) </li>
<li><a href="https://github.com/francisco-perez-sorrosal/deep-learning-papers/tree/master/Beyond%20Accuracy">Behavioral Tests</a></li>
<li>Robustness Metrics
<ul>
<li>Related to <a href="productionizing.html#Errors_when_Testing_ML_as_Regular_SW">Step 5 here</a></li>
<li>I think is very important to asses the overall quality of the model and decide when it's time to react</li>
<li>Extract data to understand where the model is gonna perform well or bad</li>
<li>Study the feature importance</li>
<li>Densitivity to data staleness (vs old data)...</li>
<li>...and data drifts (training vs prod data or different prod data distributions)
<ul>
<li>Important to define metrics for particular data categories (e.g. metrics for the &quot;news&quot; category)</li>
</ul>
</li>
</ul>
</li>
<li>Privacy and fairness
<ul>
<li>Will become more important from now on</li>
</ul>
</li>
<li>Simulation tests
<ul>
<li>Understand the interaction of your model with the rest of the environment (&quot;the world&quot;)</li>
<li>Used in Robotics/Automated Vehicles</li>
<li>Hard to model &quot;the world&quot;</li>
</ul>
</li>
<li>Shadow tests
<ul>
<li>Testing in production and compare with the results in the offline</li>
<li>Detect issues in production</li>
<li>Apply the <a href="https://martinfowler.com/bliki/StranglerFigApplication.html">strangler fig pattern</a> to not impact users</li>
</ul>
</li>
</ul>
</li>
<li>Compare model against previous one and the baselines</li>
<li>This is done only at a particular point in time; so run these tests when you've selected a candidate
model from the training phase and you want to put it in production.</li>
</ul>
</li>
<li>
<p>Tools: </p>
<ul>
<li>Robustness: 
<ul>
<li><a href="https://pair-code.github.io/what-if-tool/">what-if-tool</a> </li>
<li><a href="https://research.google/pubs/pub47966/">Slice Finder</a></li>
</ul>
</li>
</ul>
</li>
</ul>
<h3><a class="header" href="#ab-tests" id="ab-tests">A/B Tests</a></h3>
<ul>
<li>Focus: Serving System</li>
<li>Goal: Check how the users react to the new model and how the business metrics are affected</li>
<li>Techniques:
<ul>
<li>Separate a fraction of the request and redirect it to the new model. The rest of the request will
still targeting the old model which will serve as a control</li>
<li>Compare the two cohorts</li>
<li>Use monitoring as a tool for evaluation!!!</li>
<li><a href="https://levelup.gitconnected.com/the-engineering-problem-of-a-b-testing-ac1adfd492a8">A/B Testing blog</a></li>
</ul>
</li>
</ul>
<h2><a class="header" href="#model-size-vs-efficiency" id="model-size-vs-efficiency">Model Size vs Efficiency</a></h2>
<p>Big models -&gt; Big problem for company at deploy time. Not to speak about deploying an ensemble of models, even if this
shows better performance overall. Several techniques, such as knowledge distillation, pruning and quantization, have 
been identified to reduce the number of parameters of a model without impacting significantly the quality of the model. 
In the end, most of the techniques described below, result in slightly degraded prediction metrics.</p>
<ul>
<li><a href="https://blog.roblox.com/2020/05/scaled-bert-serve-1-billion-daily-requests-cpus/">How We Scaled Bert To Serve 1+ Billion Daily Requests on CPUs (Roblox)</a></li>
</ul>
<h3><a class="header" href="#distilation" id="distilation">Distilation</a></h3>
<p>Hinton, Vinyals and Dean showed in [<a href="bibliography.html#hinton_distilling_2015">hinton_distilling_2015</a>] how to apply Caruana's model compression techniques described in [<a href="bibliography.html#bucilua_model_2006">bucilua_model_2006</a>].
Caruana et all showed how to take advantage of the property of ANN of being <a href="https://en.wikipedia.org/wiki/Universal_approximation_theorem">universal approximators</a>,
to train an ANN to mimic the function learned by an ensemble of models. The idea behind the universal approximator theorem
is that, with enough neurons and training data, a NN can approximate any function with enough precision. To do that,
basically they take a brand new (and usually big) <em>unlabeled</em> dataset and they label it using the ensemble. Then they
train an ANN using this brand new large (and recently labeled dataset,) so the resulting model mimics the ensemble, and
which, as they demonstrate, performs much better than the same ANN trained on the original dataset. </p>
<p>Hinton et all, in the aforementioned paper, prove Caruana's ensemble model distillation on MNIST and in a commercial
acoustic model. They also add a new composite ensemble with several specialist models (which can also be trained in 
parallel) that learn to distinguish classes that the full models confuse.</p>
<h3><a class="header" href="#pruning" id="pruning">Pruning</a></h3>
<h3><a class="header" href="#quantization" id="quantization">Quantization</a></h3>
<ul>
<li>Focused on inference</li>
<li>Focused on small devices/IoT</li>
</ul>
<p>Papers:</p>
<ul>
<li><a href="https://arxiv.org/abs/1910.06188">Q8BERT: Quantized 8Bit BERT (2019</a></li>
<li><a href="https://pytorch.org/tutorials/intermediate/dynamic_quantization_bert_tutorial.html">DYNAMIC QUANTIZATION ON BERT (BETA)</a></li>
</ul>
<p>It turns out that quantization is now now possible in ONNX models:</p>
<pre><code class="language-python">import onnx
from quantize import quantize, QuantizationMode
...
# Load onnx model
onnx_model = onnx.load('XXX_path')
# Quantize following a specific mode from https://github.com/microsoft/onnxruntime/tree/e26e11b9f7f7b1d153d9ce2ac160cffb241e4ded/onnxruntime/python/tools/quantization#examples-of-various-quantization-modes
q_onnx_model = quantize(onnx_model, quantization_mode=XXXXX)
# Save the quantized model
onnx.save(q_onnx_model, 'XXXX_path')
</code></pre>
<p><a href="https://docs.nvidia.com/deeplearning/tensorrt/developer-guide/index.html#work-with-qat-networks">Tensor RT supports the quantized models so, it should work</a></p>
<ul>
<li><a href="https://github.com/microsoft/DeepSpeed">Deep Speed (Microsoft)</a> ZeRO redundancy memory optimizer: Addresses the problems with high memory consumption of 
large models with pure data parallelism and the problem of using model parallelism.</li>
<li><a href="https://www.youtube.com/watch?v=n4bESjZ-VaY&amp;feature=youtu.be">Training BERT with Deep Speed</a></li>
<li><a href="https://pytorch.org/elastic">Torch Elastic</a></li>
<li><a href="https://pytorch.org/docs/stable/rpc.html">PyTorch RPC</a></li>
<li><a href="https://pytorch.org/serve">PyTorch Serve</a></li>
</ul>
<h1><a class="header" href="#tools-and-frameworks-for-ml" id="tools-and-frameworks-for-ml">Tools and Frameworks for ML</a></h1>
<h2><a class="header" href="#data-1" id="data-1">Data</a></h2>
<h3><a class="header" href="#storage" id="storage">Storage</a></h3>
<ul>
<li>Filesystem</li>
<li>Databases</li>
<li><a href="https://aws.amazon.com/s3/">Amazon S3</a> Provides object storage through a web service interface.</li>
</ul>
<h3><a class="header" href="#data-formats" id="data-formats">Data Formats</a></h3>
<ul>
<li><a href="https://parquet.apache.org/">Parquet</a> A column-oriented data storage format of the Apache Hadoop ecosystem.</li>
<li><a href="https://arrow.apache.org/">Arrow</a> A language-independent columnar memory format for flat and hierarchical data.</li>
</ul>
<h3><a class="header" href="#datawarehousingdatalakes" id="datawarehousingdatalakes">Datawarehousing/DataLakes</a></h3>
<ul>
<li><a href="https://www.snowflake.com/">Snowflake</a></li>
<li><a href="https://databricks.com/">Databricks</a> Tries to unify data, analytics, and AI in a common platform.</li>
</ul>
<h3><a class="header" href="#data-analysisprocessingpipelining" id="data-analysisprocessingpipelining">Data Analysis/Processing/Pipelining</a></h3>
<ul>
<li><a href="https://pandas.pydata.org">Pandas</a> Python lib. for data manipulation and analysis.</li>
<li><a href="https://github.com/modin-project/modin">Modin</a> Faster Pandas</li>
<li><a href="https://rapids.ai/about.html">Rapids</a> Suite of OSS libraries and APIs to 
execute end-to-end data pipelines entirely on GPUs.</li>
<li><a href="https://www.getdbt.com/">dbt</a> Dev environment for data management; from writing data transformation code to 
deployment and documentation. SQL based.</li>
<li><a href="https://spark.apache.org/">Spark/PySpark</a> A unified analytics engine for large-scale data processing.</li>
</ul>
<h3><a class="header" href="#data-versioning" id="data-versioning">Data Versioning</a></h3>
<ul>
<li><a href="https://www.pachyderm.com/">Pachiderm</a> Data layer for ML lifecycles.</li>
<li><a href="https://www.dolthub.com/">Liquidata/Dolt</a> SQL database that supports clone, branch and merge.</li>
<li><a href="https://dvc.org/">dvc Data Version Control</a></li>
</ul>
<h3><a class="header" href="#data-labeling" id="data-labeling">Data Labeling</a></h3>
<ul>
<li><a href="https://appen.com/blog/data-labeling/">Figure Eight/Appen</a></li>
<li><a href="https://www.aquariumlearning.com/">Aquarium</a> Data management platform to improve datasets</li>
<li><a href="https://scale.com/">Scale</a> Data-centric, end-to-end solution to manage the entire ML lifecycle.</li>
</ul>
<h3><a class="header" href="#dataset-frameworks" id="dataset-frameworks">Dataset Frameworks</a></h3>
<ul>
<li><a href="https://huggingface.co/datasets">Huggingface Datasets</a></li>
</ul>
<h2><a class="header" href="#model-training-and-testing" id="model-training-and-testing">Model Training and Testing</a></h2>
<h3><a class="header" href="#ml-frameworks" id="ml-frameworks">ML Frameworks</a></h3>
<ul>
<li><a href="">Scikit-learn</a></li>
<li><a href="">JAX</a></li>
<li><a href="">Caffe2</a></li>
</ul>
<h3><a class="header" href="#deep-learning-frameworks" id="deep-learning-frameworks">Deep Learning Frameworks</a></h3>
<ul>
<li><a href="https://pytorch.org/">Pytorch</a>
Recent trend in Research Community. Improving a lot to get into production.</li>
<li><a href="https://www.tensorflow.org/">Tensorflow/Keras</a>
Google's big hit in 2015.</li>
<li><a href="https://mxnet.apache.org/versions/1.6/">MxNet</a> Apache</li>
</ul>
<h3><a class="header" href="#nlp-frameworks" id="nlp-frameworks">NLP Frameworks</a></h3>
<ul>
<li><a href="https://huggingface.co/">Huggingface</a></li>
<li><a href="https://github.com/NervanaSystems/nlp-architect">NLP Architect</a></li>
<li><a href="https://github.com/dmlc/gluon-nlp">GluonNlp</a></li>
</ul>
<h3><a class="header" href="#distributed-environments" id="distributed-environments">Distributed Environments</a></h3>
<ul>
<li><a href="https://github.com/horovod/horovod">Horovod</a></li>
<li><a href="https://github.com/microsoft/DeepSpeed">DeepSpeed</a></li>
</ul>
<h2><a class="header" href="#deployment-1" id="deployment-1">Deployment</a></h2>
<h1><a class="header" href="#web-resources-for-learning-aimldl" id="web-resources-for-learning-aimldl">Web Resources for Learning AI/ML/DL</a></h1>
<ul>
<li><a href="https://wiki.pathmind.com/">AI &amp; DL Wiki</a> Wiki from Pathmind, a deep reinforcement learning company focused on improving efficiency, throughput and cost of operations and chains.</li>
<li><a href="https://thegradient.pub/">The Gradient</a> Magazine about research, recent developments and current/long-term trends in 
AI/ML. Origin: 2017 by students and researchers @ Stanford Artificial Intelligence Laboratory (SAIL).
Status: non-profit and volunteers in the AI community.</li>
<li><a href="https://www.deeplearning.ai/the-batch/">The Batch</a> From Andrew Ng/DeepLearning.ai</li>
<li><a href="https://jack-clark.net/">Import AI</a> Newsletter by Jack Clark, the ex OpenAI Policy Director.</li>
<li><a href="https://learn.xnextcon.com/">AI Camp Webminars</a></li>
<li><a href="https://www.topbots.com/">TopBots</a></li>
<li><a href="http://fast.ai/">fast.ai</a> A community which aims to make deep learning easier to use.</li>
<li><a href="https://www.youtube.com/channel/UCZHmQk67mSJgfCCTn7xBfew">Yannic Kilcher Youtube Channel</a></li>
<li><a href="https://www.youtube.com/c/K%C3%A1rolyZsolnai/search?query=machine%20learning">Two Minute Papers</a></li>
<li><a href="https://arxiv.org/">Arxiv</a> Main archive for scholarly articles.</li>
<li><a href="http://arxiv-sanity.com/">Arxiv Sanity</a> To keep your mind healthy after trying to deal with all the arxiv content.</li>
</ul>
<h1><a class="header" href="#books-1" id="books-1">Books</a></h1>
<ul>
<li><a href="https://www.deeplearningbook.org/">Deep Learning (Online version)</a> <em>Ian Goodfellow and Yoshua Bengio and Aaron Courville</em> [<a href="bibliography.html#goodfellow_deep_2016">goodfellow_deep_2016</a>] </li>
<li><a href="http://d2l.ai/">Dive into Deep Learning</a> Interactive book</li>
</ul>
<h2><a class="header" href="#general-overview" id="general-overview">General Overview</a></h2>
<ul>
<li>Genius Makers: The Mavericks Who Brought AI to Google, Facebook, and the World [<a href="bibliography.html#metz_genius_2021">metz_genius_2021</a>]</li>
<li>The Deep Learning Revolution [<a href="bibliography.html#sejnowski_deep_2018">sejnowski_deep_2018</a>]</li>
<li>A Brief History of Artificial Intelligence: What It Is, Where We Are, and Where We Are Going [<a href="bibliography.html#wooldridge_brief_2021">wooldridge_brief_2021</a>]</li>
</ul>
<h1><a class="header" href="#research-centerscommunitiescompanies" id="research-centerscommunitiescompanies">Research Centers/Communities/Companies</a></h1>
<ul>
<li><a href="https://openai.com/">OpenAI</a> Mission: Ensure that artificial general intelligence (AGI) benefits all of humanity.</li>
<li><a href="https://www.eleuther.ai/">EleutherAI</a> Group of researchers devoted to GPT-Neo, a family of models designed to
replicate OpenAI's GPT-3.</li>
<li><a href="https://mila.quebec/en/">Mila</a> A community of researchers specializing in ML and dedicated to scientific excellence 
and innovation.</li>
<li><a href="https://www.salk.edu/">Salk Institute</a> A well-known institute researching the foundations of life, seeking new
understandings in neuroscience, genetics, immunology, plant biology and more.</li>
</ul>
<h1><a class="header" href="#courses-and-qa" id="courses-and-qa">[Courses and Q/A]</a></h1>
<ul>
<li><a href="https://www.deep-ml.com/">ML Code Challenges</a></li>
</ul>
<h1><a class="header" href="#opinion" id="opinion">Opinion</a></h1>
<ul>
<li><a href="https://marksaroufim.substack.com/p/machine-learning-the-great-stagnation">Machine Learning: The Great Stagnation</a> Defines the current (early 2021) situation of DS/ML roles in industry, at least in US.
<ul>
<li><a href="https://learn.xnextcon.com/event/eventdetails/W2021031810">Video</a></li>
</ul>
</li>
<li><a href="https://www.edge.org">Edge Org</a> - A website with (speculative) ideas from scientists and thinkers that pretend to draw
and go beyond the current frontiers of knowledge in evolutionary biology, genetics, computer science, neurophysiology, psychology, and physics. </li>
</ul>
<h1><a class="header" href="#my-summary-of-papers" id="my-summary-of-papers">My Summary of Papers</a></h1>
<ul>
<li><a href="https://github.com/francisco-perez-sorrosal/deep-learning-papers/tree/master/Beyond%20Accuracy">Beyond Accuracy: Behavioral Testing of NLP models with CheckList</a> [<a href="bibliography.html#ribeiro_beyond_2020">ribeiro_beyond_2020</a>] </li>
<li><a href="https://github.com/francisco-perez-sorrosal/deep-learning-papers/tree/master/Generative%20Replay">Brain-inspired Replay for Continual Learning with Artiﬁcial Neural Networks</a> [<a href="bibliography.html#van_de_ven_brain-inspired_2020">van_de_ven_brain-inspired_2020</a>]</li>
<li><a href="https://github.com/francisco-perez-sorrosal/deep-learning-papers/tree/master/Generative%20Replay">Generative Replay with Feedback Connections as a General Strategy for Continual Learning</a> [<a href="bibliography.html#van_de_ven_generative_2019">van_de_ven_generative_2019</a>]</li>
<li><a href="(https://github.com/francisco-perez-sorrosal/deep-learning-papers/tree/master/Generative%20Replay)">Three scenarios for continual learning</a> [<a href="bibliography.html#van_de_ven_three_2019">van_de_ven_three_2019</a>]</li>
<li><a href="https://github.com/francisco-perez-sorrosal/deep-learning-papers/tree/master/What%20Does%20BERT%20Look%20At">What Does BERT Look At? An Analysis of BERT’s Attention</a> {{ cite clark_what_2019 }}</li>
</ul>
<h1><a class="header" href="#main-genereal-aimldldata-science-conferences" id="main-genereal-aimldldata-science-conferences">Main Genereal AI/ML/DL/Data Science Conferences</a></h1>
<ul>
<li><a href="https://nips.cc/">NIPS/Neurips</a></li>
<li><a href="https://icml.cc/">ICML</a></li>
<li><a href="https://iclr.cc/">ICLR (International Conference on Learning Representations)</a> Dedicated to advances of the representation learning a.k.a. deep learning.</li>
<li><a href="https://www.kdd.org/">KDD (SIGKDD) ACM</a></li>
<li><a href="https://cikm2020.org/">International Conference on Information and Knowledge Management</a></li>
</ul>
<h2><a class="header" href="#nlplinguistics" id="nlplinguistics">NLP/Linguistics</a></h2>
<h3><a class="header" href="#1st-tier" id="1st-tier">1st Tier</a></h3>
<ul>
<li><a href="https://www.aclweb.org/">ACL (Association of Computational Linguistics)</a></li>
<li><a href="https://naacl.org/">NAACL</a> North American Chapter of ACL</li>
<li><a href="https://2020.emnlp.org/">EMNLP</a> Conference on Empirical Methods in Natural Language Processing</li>
</ul>
<h3><a class="header" href="#2nd-tier" id="2nd-tier">2nd Tier</a></h3>
<ul>
<li><a href="https://coling2020.org/">Coling</a> International Conference on Computational Linguistics</li>
<li><a href="https://2021.eacl.org/">EACL</a> European Chapter of ACL</li>
<li><a href="http://aacl2020.org/">AACL</a> Asia-Pacific Chapter of ACL</li>
</ul>
<h3><a class="header" href="#journals" id="journals">Journals</a></h3>
<ul>
<li><a href="https://transacl.org/index.php/tacl/index">TACL</a> Transactions of ACL (Journal)</li>
<li><a href="https://direct.mit.edu/coli">Computational Linguistics</a></li>
</ul>
<h1><a class="header" href="#a" id="a">A</a></h1>
<h2><a class="header" href="#auto-encoder" id="auto-encoder">Auto-Encoder</a></h2>
<p>Autoencoders are unsupervised ANN that can learn data encodings, making the encoder generate those encodings 
specifically for reconstructing its own input (See figure below.) They convert their inputs to encoded vectors that lie
in a latent space that may not be continuous or allow easy interpolation. In the end, this means that regular autoencoders 
are mostly limited to be used to generate compressed representations of their inputs, allowing to regenerate the original
input with minimal loss.</p>
<p><img src="images/autoencoder.png" alt="Autoencoder (Source: https://towardsdatascience.com/intuitively-understanding-variational-autoencoders-1bfe67eb5daf)" /></p>
<h1><a class="header" href="#b" id="b">B</a></h1>
<h2><a class="header" href="#backpropagation" id="backpropagation">Backpropagation</a></h2>
<p>A procedure to adjust the weights of a neural network by propagating the error obtained in the forward pass, backwards. 
After calculating the error in the output layer, e.g. by contrasting the output of the forward pass with the known 
so-called gold labels by means of a cost function, the gradient on the input weights of the last layer to the output units 
is calculated; then the weights of that layer are adjusted; this process is repeated backwards layer after layer until 
reaching the input layer. </p>
<h1><a class="header" href="#causality" id="causality">Causality</a></h1>
<p>Correlations is not causation. In ML causality tries to understand the relationships between data in order to create models
that generalize well.</p>
<h1><a class="header" href="#confusion-matrix" id="confusion-matrix">Confusion Matrix</a></h1>
<p>A confusion matrix is a tool used to evaluate the performance of a classification model by comparing the predicted labels to the actual labels. It provides a more detailed analysis of the model's performance than simple accuracy metrics. The confusion matrix is typically presented as a table with four main outcomes:</p>
<ul>
<li>True Positive (TP): Correctly predicted positive instances.</li>
<li>True Negative (TN): Correctly predicted negative instances.</li>
<li>False Positive (FP): Incorrectly predicted positive instances (Type I error).</li>
<li>False Negative (FN): Incorrectly predicted negative instances (Type II error).</li>
</ul>
<p>By examining the values in the confusion matrix, we can calculate various evaluation metrics such as precision, recall, and F1 score, which provide insights into the model's performance for different classes. The confusion matrix is an essential tool for understanding the strengths and weaknesses of a classification model.</p>
<p>Example of a confusion matrix:
<img src="images/conf_matrix_example.png" alt="Confusion Matrix Example" /></p>
<p>Main metrics derived from a confusion matrix:
<img src="images/metrics_from_conf_matrix.png" alt="Confusion Matrix Example" /></p>
<h1><a class="header" href="#e" id="e">E</a></h1>
<h2><a class="header" href="#expert-system" id="expert-system">Expert System</a></h2>
<h2><a class="header" href="#a-hrefvocabularyhtmlinterpretabilityexplainabilitya" id="a-hrefvocabularyhtmlinterpretabilityexplainabilitya"><a href="vocabulary.html#Interpretability">Explainability</a></a></h2>
<p><a href="vocabulary.html#Interpretability">See Interpretability</a>.</p>
<h2><a class="header" href="#explanation" id="explanation">Explanation</a></h2>
<p>The explicit ability expected in an intelligent agent to give &quot;good&quot; explanations of its decisions to humans. As usual,
the problem here is to define what is a &quot;good&quot; explanation. If we try to mimic in the intelligent agent world, how 
humans proceed giving explanations to other humans, we have to acknowledge we'll have to deal with biases and/or social
expectations. Some researchers argue {{ cite graaf_how_2017 }} that the framework of explanation of those agents will need 
to be consistent with the conceptual framework and psychological mechanisms of human behavior explanation, as humans
will expect explanations falling under those two premises.</p>
<h1><a class="header" href="#f" id="f">F</a></h1>
<h2><a class="header" href="#feature" id="feature">Feature</a></h2>
<p>It's a property extracted from each data instance of a dataset being observed. An example would be the &quot;color&quot; attribute
extracted from row coding an outfit item example from a file called seasonal_outfits.csv). Features are
crucial for many ML procesess. Selecting those features it's an art, which even has a name: <a href="vocabulary.html#feature_enginering">feature engineering</a>.
Some of the properties that a good feature should have for being selected are:</p>
<ul>
<li>Informative about the concept that they represent</li>
<li>Discriminating, to be able to separate one example instance from another </li>
<li>Independent, if possible from the other features extracted from the data instance</li>
</ul>
<h2><a class="header" href="#feature-engineering-1" id="feature-engineering-1">Feature Engineering</a></h2>
<p>The classical/traditional way of &quot;massage&quot; the input to pass to a ML model (e.g. a classifier.) It refers to the process 
of using domain knowledge to extract features from raw data. This was an &quot;art&quot; in itself usually done by domain experts.
In the age of DL, this has been substituted by the DL models themselves, which represents also the features on top of
which the learning of a task is done.</p>
<h2><a class="header" href="#few-shot-learning" id="few-shot-learning">Few-Shot Learning</a></h2>
<p>Humans, and more specifically children, are able to learn how to transfer their experience in similar tasks to a new one
by using only a small set of examples. For example a kid can learn how to multiply if she already knows how addition
works and with just a bunch of examples of  multiplications. It's even clearer in the world of images, in
which once they have learn to recognize a particular human face, children are able to identify the same face in a
bunch of photographs containing different faces.</p>
<p>In general, up to know, ML algorithms had to be trained in a supervised manner using a large number of examples to
learn. This is not the best scenario, as this poses many limitations, from the availability of datasets for the
task at hand to the energy consumption used for training those models. </p>
<p>Few-Shot Learning (FSL) [<a href="bibliography.html#fei-fei_one-shot_2006">fei-fei_one-shot_2006</a>] [<a href="bibliography.html#fink_object_2004">fink_object_2004</a>] are a type of ML problems in
which a model is trained -in what is called a meta -training phase- on
different related tasks. This step is supposed to give the model the ability to generalize adequately to unseen related 
supervised tasks using only a few bunch of new input data/examples in the testing/few-shot phase.</p>
<p>How many examples are considered few-shot training? [Unknown bib ref: rios_few_2018] mentions from 1 to 5.</p>
<p>A recent survey of few shot learning can be found in [<a href="bibliography.html#wang_generalizing_2020">wang_generalizing_2020</a>].
Different subdomains of FSL can be extrapolated from the regular ML domains such as:</p>
<ul>
<li>Few-shot classification</li>
<li>Few-shot regression</li>
<li>Few-shot reinforcement learning</li>
<li>...</li>
</ul>
<h1><a class="header" href="#g" id="g">G</a></h1>
<h2><a class="header" href="#generalization" id="generalization">Generalization</a></h2>
<p>The capability of an already trained ML model of adapting to previously unseen data taken from the same distribution as
the data used to train it.</p>
<h2><a class="header" href="#generative-adversarial-network-gan" id="generative-adversarial-network-gan">Generative Adversarial Network (GAN)</a></h2>
<p>A special architecture of ANN aimed to <em>generate new data</em> with similar statistics as of the ones found in a particular 
training set. The classical example of what GANs are used for, is the generation of new faces, by interpolating new
features from the data obtained from a pool of preexisting images of faces. The goal is to build the new images as real 
as possible, making them undistinguisable from real images for the human eye.</p>
<p>The idea is to train two models at the same time; the first one is the &quot;generative&quot; one, which serves as the &quot;trend 
gatherer&quot;, that is capturing the data distribution; the second one model, called &quot;discriminative&quot;, is trained to discern
if a particular sample comes from the training data or from the &quot;generative&quot; moidel [<a href="bibliography.html#goodfellow_generative_2014">goodfellow_generative_2014</a>]</p>
<p><img src="images/gan.png" alt="GAN (Source: https://towardsdatascience.com/understanding-generative-adversarial-networks-gans-cd6e4651a29)" /></p>
<h1><a class="header" href="#h" id="h">H</a></h1>
<h2><a class="header" href="#hallucination" id="hallucination">Hallucination</a></h2>
<p>In text generation tasks, it refers to misleading statements generated by the models when outputing their results
. Usually hallucinations have to do with the quality of the data the model was trained on; for example the</p>
<h1><a class="header" href="#i" id="i">I</a></h1>
<h2><a class="header" href="#interpretability" id="interpretability">Interpretability</a></h2>
<p>How well a human can understand the decisions (e.g. the output of a ML classifier) taken by an intelligent system in a given context.
This is related to the extent up to which humans can predict the results of a model. </p>
<h3><a class="header" href="#related" id="related">Related</a></h3>
<ul>
<li><a href="https://www.technologyreview.com/2018/02/21/145289/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/">Ian Goodfellow Interview</a></li>
</ul>
<h1><a class="header" href="#l" id="l">L</a></h1>
<h1><a class="header" href="#language-model" id="language-model">Language Model</a></h1>
<p>In any language, the words (or characters) in a sentence show certain correlations. Those correlations
capture and contextualize the underlying semantics and characteristics of the particular language. </p>
<p>Sequences of tokens can be found almost anywhere, being the words in a text, pixels in an image, the musical notes in
a score, etc. A language model could be defined as a statistical model that has learnt to predict the probability of a
sequence of tokens, capturing the correlation with other nearby tokens, either consecutive or not. In NLP, the tokens 
use to represent words or n-grams.</p>
<p>The calculation of the next token in the sequence \( x_n \) can be modeled as:</p>
<p>\( p(x_n | x_{n-1}, x_{n-2}...x_{1}) \)</p>
<p>where \( x_i \) represents the ith token in the sequence.</p>
<p>For more information see [<a href="bibliography.html#bengio_neural_2003">bengio_neural_2003</a>].</p>
<p>The best language model would be that which could best predict unseen data. To measure the quality of a language model
metrics such as <a href="vocabulary.html#perplexity">Perplexity</a> can be used.</p>
<h2><a class="header" href="#loss-function" id="loss-function">Loss Function</a></h2>
<p>A loss function is a way to measure how well or poorly a model is performing. It calculates the difference (error) between the model’s predictions (the guess your model is doing based on the input data) and the actual values (the labeled data we have, representing the correct answers).</p>
<p>The smaller the difference, the better the model is doing. The larger the difference, the worse it’s performing.</p>
<p>The goal of training a model is to minimize this loss by adjusting the model’s parameters, so its predictions get closer to the actual answers over time.</p>
<h1><a class="header" href="#neural-network" id="neural-network">Neural Network</a></h1>
<h1><a class="header" href="#neuromorphic-computing" id="neuromorphic-computing">Neuromorphic Computing</a></h1>
<p>A computing approach which model neurons as asynchronous and independent computation units which are stimulated by the
spikes triggered by other interconnected neurons, in a similar way as brain neurons behave.</p>
<p>Relying on asynchronous communication between the neurons, these neuromorphic systems do not need to rely on a system 
clock. So, this async communication of pulses to simulate neuron spikes is more enegy efficient, as it consumes less 
power.</p>
<h1><a class="header" href="#normalization" id="normalization">Normalization</a></h1>
<p>NN work best when input vectors/tensors are normalized, i.e. have lower mean and std in each dimension.
You can do input scaling and according weight initialization, but as the training goes, the mean and standard deviation
are blown up by the new inputs.</p>
<p>Layer normalization can be seen like a 'reset' of the weights between layers. </p>
<p>These are some references for weight norm [Unknown bib ref: saliman_weight_2016], batch norm [<a href="bibliography.html#ioffe_batch_2015">ioffe_batch_2015</a>], layer norm [<a href="bibliography.html#ba_layer_2016">ba_layer_2016</a>] and group norm [<a href="bibliography.html#wu_group_2018">wu_group_2018</a>].</p>
<h1><a class="header" href="#o" id="o">O</a></h1>
<h2><a class="header" href="#overfitting" id="overfitting">Overfitting</a></h2>
<p>The effect seen in a ML model when it seems to fit the training data so closely to the target goal that its unable to 
<a href="vocabulary.html#Generalization">generalize</a> well to unseen data. When a model is said to be overfitted, usually we observe a low
error in the metrics from the train dataset and a high error in the metrics from the test dataset. </p>
<h1><a class="header" href="#p" id="p">P</a></h1>
<h2><a class="header" href="#perplexity" id="perplexity">Perplexity</a></h2>
<p>A measure for evaluating NLP models. It measures how good or bad a probability distribution/model predicts a sample.</p>
<p><img src="images/perplexity.png" alt="Perplexity (Source: https://towardsdatascience.com/perplexity-intuition-and-derivation-105dd481c8f3)" /></p>
<h1><a class="header" href="#r" id="r">R</a></h1>
<h2><a class="header" href="#roc-receiver-operating-characteristic-curve" id="roc-receiver-operating-characteristic-curve">RoC (Receiver Operating Characteristic) Curve</a></h2>
<p>The Receiver Operating Characteristic (ROC) curve is a graphical representation of the trade-off between the true positive rate (sensitivity) and the false positive rate (1 - specificity) for a binary classification model.</p>
<p>The true positive rate (TPR) is the proportion of actual positive samples that are correctly classified as positive, while the false positive rate (FPR) is the proportion of actual negative samples that are incorrectly classified as positive.</p>
<p>The ROC curve is created by plotting the TPR against the FPR. Each point on the curve represents a different threshold, so the curve provides a visual representation of the model's performance across all possible thresholds.</p>
<p>The shape of the ROC curve can also provide insights into the model's performance. A curve that is closer to the top-left corner indicates a better model; a curve closer to the diagonal line represents a weaker model.</p>
<p>The area under the ROC curve (AUC) is commonly used to evaluate the performance of a binary classification model. An AUC of 0.5 indicates that the model performs no better than random guessing, while an AUC of 1.0 indicates a perfect classifier.</p>
<p>A model with a higher AUC has better discrimination ability, which means it can better distinguish between positive and negative samples.</p>
<p><img src="images/roc_curve.png" alt="ROC Curve" /></p>
<h1><a class="header" href="#s" id="s">S</a></h1>
<h2><a class="header" href="#simulated-annealing" id="simulated-annealing">Simulated Annealing</a></h2>
<p>Inspired by the process of annealing in metal works, it describes a probabilistic approach to solve problems by 
&quot;heating&quot; them up and, subsequently, &quot;cooling&quot; them down. Let's see what this means.</p>
<p>The algorithmic solution of is applicable in large search domain problems with may contain several local optima points.
At the core of a simulated annealing algorithm, there's a temperature variable. This variable is set up with a high
value to simulate the heating process. As the algorithm proceeds with its iterations, the variable is allowed to be 
&quot;cooled down&quot;. While the temperature is high, the algorithm accepts solutions that are worse than the current solution;
that means in some way that is less risk averse. This allows the algorithm to jump out from locations with local optima
that may be appear early when executing. Gradually, as the temperature decreases, the probability of accepting worse 
solutions decreases, hopefully &quot;crystallizing&quot; on the area of the search space where the global optimum solution is located. </p>
<p>More info see [<a href="bibliography.html#kirkpatrick_optimization_1983">kirkpatrick_optimization_1983</a>].</p>
<h2><a class="header" href="#svm-support-vector-machine" id="svm-support-vector-machine">SVM (Support Vector Machine)</a></h2>
<p>Perceptron-based classifier. SVM learns how to separate points in the space by establishing the so-called decision boundaries.
When data is separable linearly, as it shown in many examples in the ML literature, it may seem a trivial task. However, 
data in the real world is not always linearly separable, being randomly distributed, making it hard the process of segregating
the different classes linearly. The kernel trick introduced by the SVM paper performs a mathematical trick to efficiently 
(in O(n)) map -for example- data from a 2-dimensional space to 3-dimensional space, where maybe it's possible to find a 
hyperplane that separates the different classes.</p>
<h1><a class="header" href="#v" id="v">V</a></h1>
<h2><a class="header" href="#variational-auto-encoder" id="variational-auto-encoder">Variational Auto-Encoder</a></h2>
<p>In contrast to a vanilla <a href="vocabulary.html#auto-encoder">autoencoder</a>, a Variational AutoEncoder (VAE) is a <em>generative model</em> 
that shares most of the architecture with a regular autoencoder, like Generative Adversarial Networks. Because of this, 
VAEs have relatively little to do with classical autoencoders (sparse or denoising autoencoders) from a mathematical
point of view.
VAEs have a special property (which we could call the &quot;creativity&quot; property) that makes them more interesting over 
regular autoencoders for generating outputs; their latent spaces are 
continuous by design, which allows random sampling and interpolation. In a generative model this is what you want in the
end; randomly sample from the continuous latent space in order to &quot;distort a bit&quot; the input image generating an image 
variation, similar to the original one, but definitely not the same.</p>
<p>A VAE tries to maximize the probability of each X in the training set under the entire generative process
according to \( P(X) = \int P(X|z; \theta)P(z)dz \)</p>
<p>\( P(X|z; \theta) \), allows making the dependence of X on z explicit by using the law of total probability. This<br />
framework, called &quot;maximum likelihood&quot;, allows to assume that if the model is likely to produce training set samples, 
then it is also likely to produce similar samples, and also unlikely to produce dissimilar ones.</p>
<p>According to [<a href="bibliography.html#doersch_tutorial_2016">doersch_tutorial_2016</a>] VAEs are called &quot;autoencoders&quot; because the final training objective does
share the encoder/decoder architecture, so it resembles a traditional autoencoder.</p>
<h1><a class="header" href="#andrew-barto" id="andrew-barto">Andrew Barto</a></h1>
<p>Joint with [Richard Sutton](#Richard Sutton), <a href="https://www.cics.umass.edu/news/barto-sutton-co-author-second-edition-ground-breaking-textbook-reinforcement-learning">one of the most influential academics</a> 
behind the recent successes and dissemination of reinforcement learning. <a href="https://www.cics.umass.edu/faculty/directory/barto_andrew">He was at University of Ahmerst</a> 
in Massachusets. Author of the already classic book on RL [<a href="bibliography.html#sutton_reinforcement_2018">sutton_reinforcement_2018</a>]</p>
<h1><a class="header" href="#a-hrefyoshuabengioorgyoshua-bengioa" id="a-hrefyoshuabengioorgyoshua-bengioa"><a href="yoshuabengio.org">Yoshua Bengio</a></a></h1>
<p>Joint with <a href="people.html#geoffrey-hinton">Geoffrey Hinton</a> and <a href="people.html#yann-lecunn">Yann LeCunn</a>, he received the Turing Award in 2018. In
the last decades, he's been one of the leading experts pushing the limits of field of AI contributing forward.</p>
<p>A computer scientist by career, he is a professor at Université de Montréal. <a href="people.html#ian-goofellow">Ian Goodfellow</a> was one
of his students. He's also the Scientific Director of <a href="books_and_resources.html#research-centerscommunities">Mila</a> in Quebec.</p>
<p>He's been also an entrepreneur, although not very successful up to now. <a href="https://en.wikipedia.org/wiki/Element_AI">Element AI</a>
has been up to know his most well-known company.</p>
<h1><a class="header" href="#rodney-brooks" id="rodney-brooks">Rodney Brooks</a></h1>
<p>Father of modern robotics. Strong believer in the <a href="approaches.html#Actionist">actionist approach</a> of ML/AI.
Founder of <a href="https://www.irobot.com/">iRobot</a> and <a href="https://www.rethinkrobotics.com/">Rethink Robotics</a>.</p>
<p><a href="https://dblp.org/pid/b/RodneyABrooks.html">DBLP Papers</a></p>
<h1><a class="header" href="#ian-goofellow" id="ian-goofellow">Ian Goofellow</a></h1>
<p>Generative Adversarial Networks</p>
<h1><a class="header" href="#demis-hassabis" id="demis-hassabis">Demis Hassabis</a></h1>
<p><a href="https://en.wikipedia.org/wiki/Demis_Hassabis">CEO and co-founder</a> of DeepMind.</p>
<h1><a class="header" href="#geoffrey-hinton" id="geoffrey-hinton">Geoffrey Hinton</a></h1>
<p>One of the main people behind the rebirth of NN. Winner of <a href="https://amturing.acm.org/award_winners/hinton_4791679.cfm">Turing Award in 2018</a>
&quot;[f]or conceptual and engineering breakthroughs that have made deep neural networks a critical component of computing.&quot;
Founder of <a href="https://techcrunch.com/2013/06/12/how-googles-acquisition-of-dnnresearch-allowed-it-to-build-its-impressive-google-photo-search-in-6-months/?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAEXqPKy-F911hPhusOztjZn7ny0W7-dggrCD7aET0bqXJLH1xkVbsJWPBdtBM-Gpa5TfLM9k6PqR_NvbvLheqpoo4wkVaNKKd8NyGorbUm9S_oVQ-m8OsTFueR0lVO-n5-LrLWs6PAqGW1oyTEjmwAUExSmE_hDey3fyMaLKZeCA">DNN Research</a>,
which was acquired by Google in 2013.</p>
<ul>
<li><a href="https://www.cs.toronto.edu/%7Ehinton/">Toronto University Web Page</a></li>
<li><a href="https://research.google/people/GeoffreyHinton/">Google Research Web Page</a></li>
<li><a href="https://twitter.com/geoffreyhinton?lang=en">Twitter Handle</a></li>
</ul>
<h1><a class="header" href="#step-hochreiter" id="step-hochreiter">Step Hochreiter</a></h1>
<p>LSTM</p>
<h1><a class="header" href="#jeremy-howard" id="jeremy-howard">Jeremy Howard</a></h1>
<h1><a class="header" href="#andrej-karpathy" id="andrej-karpathy">Andrej Karpathy</a></h1>
<p>AI Researcher mainly in the field of vision. He focused also on model <a href="topics.html#Interpretability">Interpretability</a>. 
Former student of <a href="people.html#Geoff_Hinton">Geoff Hinton</a> at U. of Toronto, his PhD. advisor was <a href="people.html#Fei-Fei_Li">Fei-Fei Li</a> at 
Stanford. After passing by Google's Brain, Research and DeepMind teams, by 2021, current director of AI and Autopilot 
Vision at Tesla. </p>
<p><a href="https://karpathy.ai/">Personal Website</a>
<a href="http://karpathy.github.io/">Blog</a> </p>
<p>Main papers:</p>
<ul>
<li>Large-scale Video Classiﬁcation with Convolutional Neural Networks [<a href="bibliography.html#karpathy_large-scale_nodate">karpathy_large-scale_nodate</a>]</li>
<li>Visualizing and Understanding Recurrent Networks [<a href="bibliography.html#karpathy_visualizing_2015">karpathy_visualizing_2015</a>]</li>
</ul>
<h1><a class="header" href="#a-hrefhttpsenwikipediaorgwikiscott_kirkpatrickscott-kirkpatricka" id="a-hrefhttpsenwikipediaorgwikiscott_kirkpatrickscott-kirkpatricka"><a href="https://en.wikipedia.org/wiki/Scott_Kirkpatrick">Scott Kirkpatrick</a></a></h1>
<p>Inventor of <a href="vocabulary.html#Simulated_Annealing">simulated annealing</a></p>
<h1><a class="header" href="#alex-krizhevsky" id="alex-krizhevsky">Alex Krizhevsky</a></h1>
<p>Co-Developer of AlexNet, which in 2012 obtained an impressive error rate of 18% in the ImageNet dataset.</p>
<h1><a class="header" href="#yann-lecunn" id="yann-lecunn">Yann LeCunn</a></h1>
<p>Creator of &quot;Le Net&quot; and it's subsequent evolutions, mimicking the visual cortex (&quot;ConvNet&quot;).
Creator of a backpropagation-like method in his PhD thesis in 1987 (Modeles connexionnistes de l'apprentissage).</p>
<h1><a class="header" href="#fei-fei-li" id="fei-fei-li">Fei-Fei Li</a></h1>
<h1><a class="header" href="#marvin-minsky" id="marvin-minsky">Marvin Minsky</a></h1>
<p>Winner of the <a href="https://amturing.acm.org/award_winners/minsky_7440781.cfm">Turing Award</a> in 1969. Joint with (#Seymour_Papert)
both being authors of &quot;Perceptrons&quot; {{ cite minsky_perceptrons_1987 }}, demonstrated initially that NN had severe learning limitations as a ML technique.
This is often cited as a cause for the advent of the first machine learning winter int the 70s.</p>
<p>Apart from this, he was famous from his &quot;Theory of Frames&quot;, summarized in the paper, “A Framework for Representing Knowledge” [<a href="bibliography.html#minsky_framework_1974">minsky_framework_1974</a>].
The theory of frames is one of the things I still remember being introduced to during the poorly AI class I took at the
university (although I have to say that at that time, AI wasn't very popular due to all the buzz about the Internet and
the WWW flying around). This evolved years later in his broader theory for memory published in 1979 in the book 
“K-lines: A Theory of Memory” [<a href="bibliography.html#minsky_k-lines_1979">minsky_k-lines_1979</a>].</p>
<p>In the 2006 AI@50 conference, he critized the AI community in not being focused on trying to solve the &quot;general intelligence&quot;
problem and be just focused on applications. According to T. Sejnosky, Dr. Minsky recognized in that conference to have
been the &quot;devil&quot; that caused the 1st winter period in AI in the 70s [<a href="bibliography.html#sejnowski_deep_2018">sejnowski_deep_2018</a>].</p>
<ul>
<li><a href="https://dblp.org/pid/m/MarvinMinsky.html">DBLP Papers</a></li>
</ul>
<h1><a class="header" href="#gary-marcus" id="gary-marcus">Gary Marcus</a></h1>
<p>Cognitive scientist (in his PhD had Steven Pinker as advisor,) founder of Geometric Intelligence, a ML company
acquired by Uber in 2016. He's trying to &quot;shape&quot; the next steps in ML through his essays and articles (e.g. {{ cite marcus_next_2020 }}).
Well known for challenging the traditional <a href="approaches.html#connectionist">connectionist theories</a>, he believes that
<a href="https://en.wikipedia.org/wiki/Gary_Marcus">neurons can be put together to build circuits in order to do things such as process rules or process structured 
representations</a>, which is more aligned with the Neuro-Symbolic Learning 
and Reasoning line of work.</p>
<h1><a class="header" href="#carver-mead" id="carver-mead">Carver Mead</a></h1>
<p>Neuromorphic computation</p>
<h1><a class="header" href="#javier-movellan" id="javier-movellan">Javier Movellan</a></h1>
<p>Piooner in introducing social robots in classrooms.</p>
<p><a href="https://scholar.google.com/citations?user=07NrZFIAAAAJ&amp;hl=en">Google Scholar Papers</a>
<a href="https://dblp.org/pid/41/4458.html">DBLP Papers</a></p>
<h1><a class="header" href="#andrew-ng" id="andrew-ng">Andrew Ng</a></h1>
<p>He's driven a lot of efforts for disseminating and democratizing modern AI and DL. Founder of <a href="https://www.coursera.org/">Coursera</a> and <a href="https://www.deeplearning.ai/">DeepLearning.AI</a>
Author of a guide for Machine Learning engineers that summarizes the basic principles and best practices to take into account in
that new &quot;work position&quot; called <a href="https://d2wvfoqc9gyqzf.cloudfront.net/content/uploads/2018/09/Ng-MLY01-13.pdf">Machine Learning Yearning</a></p>
<h1><a class="header" href="#allen-newell" id="allen-newell">Allen Newell</a></h1>
<p>Joint with [Herbert A. Simon](#Herbert A. Simon) one of the fathers of the <a href="approaches.html#Symbolist">symbolic approach in AI/ML</a>. </p>
<h1><a class="header" href="#arthur-samuel" id="arthur-samuel">Arthur Samuel</a></h1>
<p>One of the pioners of a game-oriented AI, and reinforcement learning precursor. Creator of a chess game while at IBM that
learned playing against itself.</p>
<h1><a class="header" href="#santiago-ramon-y-cajal" id="santiago-ramon-y-cajal">Santiago Ramon y Cajal</a></h1>
<p>Spanish neuroanatomist considered one of the fathers of modern neuroscience.</p>
<h1><a class="header" href="#sebastian-ruder" id="sebastian-ruder">Sebastian Ruder</a></h1>
<p>Author of {{ howard_umlfit_2018 }} and <a href="http://nlpprogress.com/">NLP Progress</a></p>
<h1><a class="header" href="#david-rumelhart" id="david-rumelhart">David Rumelhart</a></h1>
<p>(1943-2011)</p>
<p>Known for being one of the persons developing <a href="vocabulary.html#backpropagation">Backpropagation</a>.
He was diagnosed with FTD (frontotemporal dementia). In FTD, some areas of the frontal lobes of the brain suffer an 
atrophy (they shrink), which in the end may cause problems with behavior and language depending on the area affected.</p>
<h1><a class="header" href="#terrence-sejnowsky" id="terrence-sejnowsky">Terrence Sejnowsky</a></h1>
<p>(1947-)</p>
<p>One of the initial developers and advocates of connectionism.</p>
<h1><a class="header" href="#herbert-a-simon" id="herbert-a-simon">Herbert A. Simon</a></h1>
<p>A strong believer of the <a href="approaches.html#Symbolist">symbolic approach in AI/ML</a>. </p>
<h1><a class="header" href="#marian-stewart-bartlett" id="marian-stewart-bartlett">Marian Stewart-Bartlett</a></h1>
<p>Pioneer on recognizing facial expressions identified by Paul Ekman with neural networks.
Founder, joint with <a href="people.html#Javier_Movellan">Javier Movellan</a> of Emotient, which was eventually acquired by Apple.</p>
<p><a href="https://dblp.org/pid/54/4284.html">DBLP Papers</a></p>
<h1><a class="header" href="#ilya-sutskever" id="ilya-sutskever">Ilya Sutskever</a></h1>
<p>Co-Developer of AlexNet
Co-Founder of Open AI</p>
<h1><a class="header" href="#richard-sutton" id="richard-sutton">Richard Sutton</a></h1>
<p>One of the current popes of Reinforcement Learning.
His short blog post <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">The Bitter Lesson</a> is a nice summary
of this view on the evolution of certain parts of AI.</p>
<h1><a class="header" href="#seymour-papert" id="seymour-papert">Seymour Papert</a></h1>
<h1><a class="header" href="#judea-perl" id="judea-perl">Judea Perl</a></h1>
<p>Creator of Belief Networks based on Bayesian analysis.
Author or {{ cite perl_2018 }}</p>
<h1><a class="header" href="#jurgen-schimidhuber" id="jurgen-schimidhuber">Jurgen Schimidhuber</a></h1>
<p>LSTM</p>
<h1><a class="header" href="#hava-siegelmann" id="hava-siegelmann">Hava Siegelmann</a></h1>
<p><a href="https://www.cics.umass.edu/faculty/directory/siegelmann_hava">She's the creator</a> of a new field of computer science, 
Super-Turing computation. This is related to the <a href="approaches.html#Adaptable">Adaptable approach</a> to AI/ML learning.</p>
<h1><a class="header" href="#vladimir-vapnik" id="vladimir-vapnik">Vladimir Vapnik</a></h1>
<p>Author of the SVM</p>
<h1><a class="header" href="#stephen-wolfram" id="stephen-wolfram">Stephen Wolfram</a></h1>
<p>Pioneer in Complexity theory and creator of Mathematica and Wolfgram Alpha mathematical search engine. He studied complexity
through cellular automatas (e.g. Conway's Game of Life.) John von Neuman also studied cellullar automata, in this case
for self-replication. <a href="https://science.sciencemag.org/content/157/3785/180.1">He found an automata</a> with 29 states 
and a large memory that was able to self-replicate.</p>
<h1><a class="header" href="#bibliography" id="bibliography">Bibliography</a></h1>
<script type="text/javascript">
function defaultCopyTextToClipboard(text) {
    var textArea = document.createElement("textarea");
    textArea.value = text;

    // Avoid scrolling to bottom
    textArea.style.top = "0";
    textArea.style.left = "0";
    textArea.style.position = "fixed";

    document.body.appendChild(textArea);
    textArea.focus();
    textArea.select();

    try {
        var ok = document.execCommand('copy');
        var msg = ok ? 'was ok' : 'failed';
        console.log('Backing copy: Text copy was ' + msg);
    } catch (err) {
        console.error('Backing copy: Unable to copy text', err);
    }

    document.body.removeChild(textArea);
}

function copyToClipboard(text) {
    if (!navigator.clipboard) {
        defaultCopyTextToClipboard(text);
        return;
    }
    navigator.clipboard.writeText(text).then(function() {
        console.log('Text copied to clipboard');
    }, function(err) {
        console.error('Error copying text: ', err);
    });
}

</script>
<style></style>
<div class="bib_div">
<details data-key="agarwal_neural_2020" class=ref>
<summary class=citation>
<a id="agarwal_neural_2020">[agarwal_neural_2020]</a> - Agarwal, Rishabh and Frosst, Nicholas and Zhang, Xuezhou and Caruana, Rich and Hinton, Geoffrey E. - <a href="http://arxiv.org/abs/2004.13912" target="_blank"><cite>Neural Additive Models: Interpretable Machine Learning with Neural Nets</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite agarwal_neural_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract" id="summaryabstract">Summary/Abstract</a></h1>
<div>Deep neural networks ({DNNs}) are powerful black-box predictors that have achieved impressive performance on a wide variety of tasks. However, their accuracy comes at the cost of intelligibility: it is usually unclear how they make their decisions. This hinders their applicability to high stakes decision-making domains such as healthcare. We propose Neural Additive Models ({NAMs}) which combine some of the expressivity of {DNNs} with the inherent intelligibility of generalized additive models. {NAMs} learn a linear combination of neural networks that each attend to a single input feature. These networks are trained jointly and can learn arbitrarily complex relationships between their input feature and the output. Our experiments on regression and classification datasets show that {NAMs} are more accurate than widely used intelligible models such as logistic regression and shallow decision trees. They perform similarly to existing state-of-the-art generalized additive models in accuracy, but can be more easily applied to real-world problems.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="akama_elements_2015" class=ref>
<summary class=citation>
<a id="akama_elements_2015">[akama_elements_2015]</a> - Akama, Seiki - <a href="http://link.springer.com/10.1007/978-3-319-08284-4" target="_blank"><cite>Elements of Quantum Computing</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite akama_elements_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-1" id="summaryabstract-1">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="al-rfou_character-level_2018" class=ref>
<summary class=citation>
<a id="al-rfou_character-level_2018">[al-rfou_character-level_2018]</a> - Al-Rfou, Rami and Choe, Dokook and Constant, Noah and Guo, Mandy and Jones, Llion - <a href="http://arxiv.org/abs/1808.04444" target="_blank"><cite>Character-Level Language Modeling with Deeper Self-Attention</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite al-rfou_character-level_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-2" id="summaryabstract-2">Summary/Abstract</a></h1>
<div>{LSTMs} and other {RNN} variants have shown strong performance on character-level language modeling. These models are typically trained using truncated backpropagation through time, and it is common to assume that their success stems from their ability to remember long-term contexts. In this paper, we show that a deep (64-layer) transformer model with fixed context outperforms {RNN} variants by a large margin, achieving state of the art on two popular benchmarks: 1.13 bits per character on text8 and 1.06 on enwik8. To get good results at this depth, we show that it is important to add auxiliary losses, both at intermediate network layers and intermediate sequence positions.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="alyafeai_survey_2020" class=ref>
<summary class=citation>
<a id="alyafeai_survey_2020">[alyafeai_survey_2020]</a> - Alyafeai, Zaid and {AlShaibani}, Maged Saeed and Ahmad, Irfan - <a href="http://arxiv.org/abs/2007.04239" target="_blank"><cite>A Survey on Transfer Learning in Natural Language Processing</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite alyafeai_survey_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-3" id="summaryabstract-3">Summary/Abstract</a></h1>
<div>Deep learning models usually require a huge amount of data. However, these large datasets are not always attainable. This is common in many challenging {NLP} tasks. Consider Neural Machine Translation, for instance, where curating such large datasets may not be possible specially for low resource languages. Another limitation of deep learning models is the demand for huge computing resources. These obstacles motivate research to question the possibility of knowledge transfer using large trained models. The demand for transfer learning is increasing as many large models are emerging. In this survey, we feature the recent transfer learning advances in the field of {NLP}. We also provide a taxonomy for categorizing different transfer learning approaches from the literature.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="arute_quantum_2019" class=ref>
<summary class=citation>
<a id="arute_quantum_2019">[arute_quantum_2019]</a> - Arute, Frank and Arya, Kunal and Babbush, Ryan and Bacon, Dave and Bardin, Joseph C. and Barends, Rami and Biswas, Rupak and Boixo, Sergio and Brandao, Fernando G. S. L. and Buell, David A. and Burkett, Brian and Chen, Yu and Chen, Zijun and Chiaro, Ben and Collins, Roberto and Courtney, William and Dunsworth, Andrew and Farhi, Edward and Foxen, Brooks and Fowler, Austin and Gidney, Craig and Giustina, Marissa and Graff, Rob and Guerin, Keith and Habegger, Steve and Harrigan, Matthew P. and Hartmann, Michael J. and Ho, Alan and Hoffmann, Markus and Huang, Trent and Humble, Travis S. and Isakov, Sergei V. and Jeffrey, Evan and Jiang, Zhang and Kafri, Dvir and Kechedzhi, Kostyantyn and Kelly, Julian and Klimov, Paul V. and Knysh, Sergey and Korotkov, Alexander and Kostritsa, Fedor and Landhuis, David and Lindmark, Mike and Lucero, Erik and Lyakh, Dmitry and Mandrà, Salvatore and {McClean}, Jarrod R. and {McEwen}, Matthew and Megrant, Anthony and Mi, Xiao and Michielsen, Kristel and Mohseni, Masoud and Mutus, Josh and Naaman, Ofer and Neeley, Matthew and Neill, Charles and Niu, Murphy Yuezhen and Ostby, Eric and Petukhov, Andre and Platt, John C. and Quintana, Chris and Rieffel, Eleanor G. and Roushan, Pedram and Rubin, Nicholas C. and Sank, Daniel and Satzinger, Kevin J. and Smelyanskiy, Vadim and Sung, Kevin J. and Trevithick, Matthew D. and Vainsencher, Amit and Villalonga, Benjamin and White, Theodore and Yao, Z. Jamie and Yeh, Ping and Zalcman, Adam and Neven, Hartmut and Martinis, John M. - <a href="http://www.nature.com/articles/s41586-019-1666-5" target="_blank"><cite>Quantum supremacy using a programmable superconducting processor</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite arute_quantum_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-4" id="summaryabstract-4">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="austin_structured_2023" class=ref>
<summary class=citation>
<a id="austin_structured_2023">[austin_structured_2023]</a> - Austin, Jacob and Johnson, Daniel D. and Ho, Jonathan and Tarlow, Daniel and Berg, Rianne van den - <a href="http://arxiv.org/abs/2107.03006" target="_blank"><cite>Structured Denoising Diffusion Models in Discrete State-Spaces</cite></a>. - 2023. -
<button onclick="copyToClipboard('\{\{ #cite austin_structured_2023 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-5" id="summaryabstract-5">Summary/Abstract</a></h1>
<div>Denoising diffusion probabilistic models ({DDPMs}) [19] have shown impressive results on image and waveform generation in continuous state spaces. Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs), diffusionlike generative models for discrete data that generalize the multinomial diffusion model of Hoogeboom et al. [20], by going beyond corruption processes with uniform transition probabilities. This includes corruption with transition matrices that mimic Gaussian kernels in continuous space, matrices based on nearest neighbors in embedding space, and matrices that introduce absorbing states. The third allows us to draw a connection between diffusion models and autoregressive and mask-based generative models. We show that the choice of transition matrix is an important design decision that leads to improved results in image and text domains. We also introduce a new loss function that combines the variational lower bound with an auxiliary cross entropy loss. For text, this model class achieves strong results on character-level text generation while scaling to large vocabularies on {LM}1B. On the image dataset {CIFAR}-10, our models approach the sample quality and exceed the log-likelihood of the continuous-space {DDPM} model.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="austin_structured_2023-1" class=ref>
<summary class=citation>
<a id="austin_structured_2023-1">[austin_structured_2023-1]</a> - Austin, Jacob and Johnson, Daniel D. and Ho, Jonathan and Tarlow, Daniel and Berg, Rianne van den - <a href="http://arxiv.org/abs/2107.03006" target="_blank"><cite>Structured Denoising Diffusion Models in Discrete State-Spaces</cite></a>. - 2023. -
<button onclick="copyToClipboard('\{\{ #cite austin_structured_2023-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-6" id="summaryabstract-6">Summary/Abstract</a></h1>
<div>Denoising diffusion probabilistic models ({DDPMs}) [19] have shown impressive results on image and waveform generation in continuous state spaces. Here, we introduce Discrete Denoising Diffusion Probabilistic Models (D3PMs), diffusionlike generative models for discrete data that generalize the multinomial diffusion model of Hoogeboom et al. [20], by going beyond corruption processes with uniform transition probabilities. This includes corruption with transition matrices that mimic Gaussian kernels in continuous space, matrices based on nearest neighbors in embedding space, and matrices that introduce absorbing states. The third allows us to draw a connection between diffusion models and autoregressive and mask-based generative models. We show that the choice of transition matrix is an important design decision that leads to improved results in image and text domains. We also introduce a new loss function that combines the variational lower bound with an auxiliary cross entropy loss. For text, this model class achieves strong results on character-level text generation while scaling to large vocabularies on {LM}1B. On the image dataset {CIFAR}-10, our models approach the sample quality and exceed the log-likelihood of the continuous-space {DDPM} model.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="ba_layer_2016" class=ref>
<summary class=citation>
<a id="ba_layer_2016">[ba_layer_2016]</a> - Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E. - <a href="http://arxiv.org/abs/1607.06450" target="_blank"><cite>Layer Normalization</cite></a>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite ba_layer_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-7" id="summaryabstract-7">Summary/Abstract</a></h1>
<div>Training state-of-the-art, deep neural networks is computationally expensive. One way to reduce the training time is to normalize the activities of the neurons. A recently introduced technique called batch normalization uses the distribution of the summed input to a neuron over a mini-batch of training cases to compute a mean and variance which are then used to normalize the summed input to that neuron on each training case. This significantly reduces the training time in feed-forward neural networks. However, the effect of batch normalization is dependent on the mini-batch size and it is not obvious how to apply it to recurrent neural networks. In this paper, we transpose batch normalization into layer normalization by computing the mean and variance used for normalization from all of the summed inputs to the neurons in a layer on a single training case. Like batch normalization, we also give each neuron its own adaptive bias and gain which are applied after the normalization but before the non-linearity. Unlike batch normalization, layer normalization performs exactly the same computation at training and test times. It is also straightforward to apply to recurrent neural networks by computing the normalization statistics separately at each time step. Layer normalization is very effective at stabilizing the hidden state dynamics in recurrent networks. Empirically, we show that layer normalization can substantially reduce the training time compared with previously published techniques.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="baevski_data2vec_nodate" class=ref>
<summary class=citation>
<a id="baevski_data2vec_nodate">[baevski_data2vec_nodate]</a> - Baevski, Alexei and Hsu, Wei-Ning and Xu, Qiantong and Babu, Arun and Gu, Jiatao and Auli, Michael - <cite>data2vec: A General Framework for Self-supervised Learning in Speech, Vision and Language</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite baevski_data2vec_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-8" id="summaryabstract-8">Summary/Abstract</a></h1>
<div>While the general idea of self-supervised learning is identical across modalities, the actual algorithms and objectives differ widely because they were developed with a single modality in mind. To get us closer to general self-supervised learning, we present data2vec, a framework that uses the same learning method for either speech, {NLP} or computer vision. The core idea is to predict latent representations of the full input data based on a masked view of the input in a selfdistillation setup using a standard Transformer architecture. Instead of predicting modality-specific targets such as words, visual tokens or units of human speech which are local in nature, data2vec predicts contextualized latent representations that contain information from the entire input. Experiments on the major benchmarks of speech recognition, image classification, and natural language understanding demonstrate a new state of the art or competitive performance to predominant approaches. Models and code are available at www.github.com/pytorch/fairseq/ tree/master/examples/data2vec.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="barrett_seven_2021" class=ref>
<summary class=citation>
<a id="barrett_seven_2021">[barrett_seven_2021]</a> - Barrett, Lisa - <cite>Seven and a Half Lessons About the Brain</cite>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite barrett_seven_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-9" id="summaryabstract-9">Summary/Abstract</a></h1>
<div>From the author of How Emotions Are Made, a myth-busting primer on the brain in the tradition of Seven Brief Lessons on Physics and Astrophysics for People in a Hurry Have you ever wondered why you have a brain? Let renowned neuroscientist Lisa Feldman Barrett demystify that big gray blob between your ears. In seven short essays (plus a bite-size story about how brains evolved), this slim, entertaining, and accessible collection reveals mind-expanding lessons from the front lines of neuroscience research. You’ll learn where brains came from, how they’re structured (and why it matters), and how yours works in tandem with other brains to create everything you experience. Along the way, you’ll also learn to dismiss popular myths such as the idea of a “lizard brain” and the alleged battle between thoughts and emotions—or between nature and nurture—to determine your behavior.   Sure to intrigue casual readers and scientific veterans alike, Seven and a Half Lessons About the Brain is full of surprises, humor, and important implications for human nature—a gift of a book that you will want to savor again and again.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="bengio_neural_2003" class=ref>
<summary class=citation>
<a id="bengio_neural_2003">[bengio_neural_2003]</a> - Bengio, Yoshua and Ducharme, Réjean and Vincent, Pascal and Janvin, Christian - <cite>A neural probabilistic language model</cite>. - 2003. -
<button onclick="copyToClipboard('\{\{ #cite bengio_neural_2003 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-10" id="summaryabstract-10">Summary/Abstract</a></h1>
<div>A goal of statistical language modeling is to learn the joint probability function of sequences of words in a language. This is intrinsically difficult because of the curse of dimensionality: a word sequence on which the model will be tested is likely to be different from all the word sequences seen during training. Traditional but very successful approaches based on n-grams obtain generalization by concatenating very short overlapping sequences seen in the training set. We propose to fight the curse of dimensionality by learning a distributed representation for words which allows each training sentence to inform the model about an exponential number of semantically neighboring sentences. The model learns simultaneously (1) a distributed representation for each word along with (2) the probability function for word sequences, expressed in terms of these representations. Generalization is obtained because a sequence of words that has never been seen before gets high probability if it is made of words that are similar (in the sense of having a nearby representation) to words forming an already seen sentence. Training such large models (with millions of parameters) within a reasonable time is itself a significant challenge. We report on experiments using neural networks for the probability function, showing on two text corpora that the proposed approach significantly improves on state-of-the-art n-gram models, and that the proposed approach allows to take advantage of longer contexts.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="besold_neural-symbolic_2017" class=ref>
<summary class=citation>
<a id="besold_neural-symbolic_2017">[besold_neural-symbolic_2017]</a> - Besold, Tarek R. and Garcez, Artur d&#x27;Avila and Bader, Sebastian and Bowman, Howard and Domingos, Pedro and Hitzler, Pascal and Kuehnberger, Kai-Uwe and Lamb, Luis C. and Lowd, Daniel and Lima, Priscila Machado Vieira and de Penning, Leo and Pinkas, Gadi and Poon, Hoifung and Zaverucha, Gerson - <a href="http://arxiv.org/abs/1711.03902" target="_blank"><cite>Neural-Symbolic Learning and Reasoning: A Survey and Interpretation</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite besold_neural-symbolic_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-11" id="summaryabstract-11">Summary/Abstract</a></h1>
<div>The study and understanding of human behaviour is relevant to computer science, artificial intelligence, neural computation, cognitive science, philosophy, psychology, and several other areas. Presupposing cognition as basis of behaviour, among the most prominent tools in the modelling of behaviour are computational-logic systems, connectionist models of cognition, and models of uncertainty. Recent studies in cognitive science, artificial intelligence, and psychology have produced a number of cognitive models of reasoning, learning, and language that are underpinned by computation. In addition, efforts in computer science research have led to the development of cognitive computational systems integrating machine learning and automated reasoning. Such systems have shown promise in a range of applications, including computational biology, fault diagnosis, training and assessment in simulators, and software verification. This joint survey reviews the personal ideas and views of several researchers on neural-symbolic learning and reasoning. The article is organised in three parts: Firstly, we frame the scope and goals of neural-symbolic computation and have a look at the theoretical foundations. We then proceed to describe the realisations of neural-symbolic computation, systems, and applications. Finally we present the challenges facing the area and avenues for further research.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="biesialska_continual_2020" class=ref>
<summary class=citation>
<a id="biesialska_continual_2020">[biesialska_continual_2020]</a> - Biesialska, Magdalena and Biesialska, Katarzyna and Costa-jussà, Marta R. - <a href="http://arxiv.org/abs/2012.09823" target="_blank"><cite>Continual Lifelong Learning in Natural Language Processing: A Survey</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite biesialska_continual_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-12" id="summaryabstract-12">Summary/Abstract</a></h1>
<div>Continual learning ({CL}) aims to enable information systems to learn from a continuous data stream across time. However, it is difficult for existing deep learning architectures to learn a new task without largely forgetting previously acquired knowledge. Furthermore, {CL} is particularly challenging for language learning, as natural language is ambiguous: it is discrete, compositional, and its meaning is context-dependent. In this work, we look at the problem of {CL} through the lens of various {NLP} tasks. Our survey discusses major challenges in {CL} and current methods applied in neural network models. We also provide a critical review of the existing {CL} evaluation methods and datasets in {NLP}. Finally, we present our outlook on future research directions.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="blank_quantum_2020" class=ref>
<summary class=citation>
<a id="blank_quantum_2020">[blank_quantum_2020]</a> - Blank, Carsten and Park, Daniel K. and Rhee, June-Koo Kevin and Petruccione, Francesco - <a href="https://www.nature.com/articles/s41534-020-0272-6" target="_blank"><cite>Quantum classifier with tailored quantum kernel</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite blank_quantum_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-13" id="summaryabstract-13">Summary/Abstract</a></h1>
<div>Kernel methods have a wide spectrum of applications in machine learning. Recently, a link between quantum computing and kernel theory has been formally established, opening up opportunities for quantum techniques to enhance various existing machine-learning methods. We present a distance-based quantum classifier whose kernel is based on the quantum state fidelity between training and test data. The quantum kernel can be tailored systematically with a quantum circuit to raise the kernel to an arbitrary power and to assign arbitrary weights to each training data. Given a specific input state, our protocol calculates the weighted power sum of fidelities of quantum data in quantum parallel via a swap-test circuit followed by two single-qubit measurements, requiring only a constant number of repetitions regardless of the number of data. We also show that our classifier is equivalent to measuring the expectation value of a Helstrom operator, from which the well-known optimal quantum state discrimination can be derived. We demonstrate the performance of our classifier via classical simulations with a realistic noise model and proof-of-principle experiments using the {IBM} quantum cloud platform.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="bommasani_opportunities_2021" class=ref>
<summary class=citation>
<a id="bommasani_opportunities_2021">[bommasani_opportunities_2021]</a> - Bommasani, Rishi and Hudson, Drew A. and Adeli, Ehsan and Altman, Russ and Arora, Simran and von Arx, Sydney and Bernstein, Michael S. and Bohg, Jeannette and Bosselut, Antoine and Brunskill, Emma and Brynjolfsson, Erik and Buch, Shyamal and Card, Dallas and Castellon, Rodrigo and Chatterji, Niladri and Chen, Annie and Creel, Kathleen and Davis, Jared Quincy and Demszky, Dora and Donahue, Chris and Doumbouya, Moussa and Durmus, Esin and Ermon, Stefano and Etchemendy, John and Ethayarajh, Kawin and Fei-Fei, Li and Finn, Chelsea and Gale, Trevor and Gillespie, Lauren and Goel, Karan and Goodman, Noah and Grossman, Shelby and Guha, Neel and Hashimoto, Tatsunori and Henderson, Peter and Hewitt, John and Ho, Daniel E. and Hong, Jenny and Hsu, Kyle and Huang, Jing and Icard, Thomas and Jain, Saahil and Jurafsky, Dan and Kalluri, Pratyusha and Karamcheti, Siddharth and Keeling, Geoff and Khani, Fereshte and Khattab, Omar and Kohd, Pang Wei and Krass, Mark and Krishna, Ranjay and Kuditipudi, Rohith and Kumar, Ananya and Ladhak, Faisal and Lee, Mina and Lee, Tony and Leskovec, Jure and Levent, Isabelle and Li, Xiang Lisa and Li, Xuechen and Ma, Tengyu and Malik, Ali and Manning, Christopher D. and Mirchandani, Suvir and Mitchell, Eric and Munyikwa, Zanele and Nair, Suraj and Narayan, Avanika and Narayanan, Deepak and Newman, Ben and Nie, Allen and Niebles, Juan Carlos and Nilforoshan, Hamed and Nyarko, Julian and Ogut, Giray and Orr, Laurel and Papadimitriou, Isabel and Park, Joon Sung and Piech, Chris and Portelance, Eva and Potts, Christopher and Raghunathan, Aditi and Reich, Rob and Ren, Hongyu and Rong, Frieda and Roohani, Yusuf and Ruiz, Camilo and Ryan, Jack and Ré, Christopher and Sadigh, Dorsa and Sagawa, Shiori and Santhanam, Keshav and Shih, Andy and Srinivasan, Krishnan and Tamkin, Alex and Taori, Rohan and Thomas, Armin W. and Tramèr, Florian and Wang, Rose E. and Wang, William and Wu, Bohan and Wu, Jiajun and Wu, Yuhuai and Xie, Sang Michael and Yasunaga, Michihiro and You, Jiaxuan and Zaharia, Matei and Zhang, Michael and Zhang, Tianyi and Zhang, Xikun and Zhang, Yuhui and Zheng, Lucia and Zhou, Kaitlyn and Liang, Percy - <a href="http://arxiv.org/abs/2108.07258" target="_blank"><cite>On the Opportunities and Risks of Foundation Models</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite bommasani_opportunities_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-14" id="summaryabstract-14">Summary/Abstract</a></h1>
<div>{AI} is undergoing a paradigm shift with the rise of models (e.g., {BERT}, {DALL}-E, {GPT}-3) that are trained on broad data at scale and are adaptable to a wide range of downstream tasks. We call these models foundation models to underscore their critically central yet incomplete character. This report provides a thorough account of the opportunities and risks of foundation models, ranging from their capabilities (e.g., language, vision, robotics, reasoning, human interaction) and technical principles(e.g., model architectures, training procedures, data, systems, security, evaluation, theory) to their applications (e.g., law, healthcare, education) and societal impact (e.g., inequity, misuse, economic and environmental impact, legal and ethical considerations). Though foundation models are based on standard deep learning and transfer learning, their scale results in new emergent capabilities,and their effectiveness across so many tasks incentivizes homogenization. Homogenization provides powerful leverage but demands caution, as the defects of the foundation model are inherited by all the adapted models downstream. Despite the impending widespread deployment of foundation models, we currently lack a clear understanding of how they work, when they fail, and what they are even capable of due to their emergent properties. To tackle these questions, we believe much of the critical research on foundation models will require deep interdisciplinary collaboration commensurate with their fundamentally sociotechnical nature.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="bowman_eight_2023" class=ref>
<summary class=citation>
<a id="bowman_eight_2023">[bowman_eight_2023]</a> - Bowman, Samuel R. - <a href="http://arxiv.org/abs/2304.00612" target="_blank"><cite>Eight Things to Know about Large Language Models</cite></a>. - 2023. -
<button onclick="copyToClipboard('\{\{ #cite bowman_eight_2023 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-15" id="summaryabstract-15">Summary/Abstract</a></h1>
<div>The widespread public deployment of large language models ({LLMs}) in recent months has prompted a wave of new attention and engagement from advocates, policymakers, and scholars from many fields. This attention is a timely response to the many urgent questions that this technology raises, but it can sometimes miss important considerations. This paper surveys the evidence for eight potentially surprising such points: 1. {LLMs} predictably get more capable with increasing investment, even without targeted innovation. 2. Many important {LLM} behaviors emerge unpredictably as a byproduct of increasing investment. 3. {LLMs} often appear to learn and use representations of the outside world. 4. There are no reliable techniques for steering the behavior of {LLMs}. 5. Experts are not yet able to interpret the inner workings of {LLMs}. 6. Human performance on a task isn&#x27;t an upper bound on {LLM} performance. 7. {LLMs} need not express the values of their creators nor the values encoded in web text. 8. Brief interactions with {LLMs} are often misleading.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="bowman_large_2015" class=ref>
<summary class=citation>
<a id="bowman_large_2015">[bowman_large_2015]</a> - Bowman, Samuel R. and Angeli, Gabor and Potts, Christopher and Manning, Christopher D. - <a href="http://aclweb.org/anthology/D15-1075" target="_blank"><cite>A large annotated corpus for learning natural language inference</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite bowman_large_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-16" id="summaryabstract-16">Summary/Abstract</a></h1>
<div>Understanding entailment and contradiction is fundamental to understanding natural language, and inference about entailment and contradiction is a valuable testing ground for the development of semantic representations. However, machine learning research in this area has been dramatically limited by the lack of large-scale resources. To address this, we introduce the Stanford Natural Language Inference corpus, a new, freely available collection of labeled sentence pairs, written by humans doing a novel grounded task based on image captioning. At 570K pairs, it is two orders of magnitude larger than all other resources of its type. This increase in scale allows lexicalized classiﬁers to outperform some sophisticated existing entailment models, and it allows a neural network-based model to perform competitively on natural language inference benchmarks for the ﬁrst time.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="brittain_prioritized_nodate" class=ref>
<summary class=citation>
<a id="brittain_prioritized_nodate">[brittain_prioritized_nodate]</a> - Brittain, Marc and Bertram, Josh and Yang, Xuxi and Wei, Peng - <cite>Prioritized Sequence Experience Replay</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite brittain_prioritized_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-17" id="summaryabstract-17">Summary/Abstract</a></h1>
<div>Experience replay is widely used in deep reinforcement learning algorithms and allows agents to remember and learn from experiences from the past. In an effort to learn more efﬁciently, researchers proposed prioritized experience replay ({PER}) which samples important transitions more frequently. In this paper, we propose Prioritized Sequence Experience Replay ({PSER}) a framework for prioritizing sequences of experience in an attempt to both learn more efﬁciently and to obtain better performance. We compare the performance of {PER} and {PSER} sampling techniques in a tabular Q-learning environment and in {DQN} on the Atari 2600 benchmark. We prove theoretically that {PSER} is guaranteed to converge faster than {PER} and empirically show {PSER} substantially improves upon {PER}.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="broughton_tensorflow_2020" class=ref>
<summary class=citation>
<a id="broughton_tensorflow_2020">[broughton_tensorflow_2020]</a> - Broughton, Michael and Verdon, Guillaume and {McCourt}, Trevor and Martinez, Antonio J. and Yoo, Jae Hyeon and Isakov, Sergei V. and Massey, Philip and Niu, Murphy Yuezhen and Halavati, Ramin and Peters, Evan and Leib, Martin and Skolik, Andrea and Streif, Michael and Von Dollen, David and {McClean}, Jarrod R. and Boixo, Sergio and Bacon, Dave and Ho, Alan K. and Neven, Hartmut and Mohseni, Masoud - <a href="http://arxiv.org/abs/2003.02989" target="_blank"><cite>{TensorFlow} Quantum: A Software Framework for Quantum Machine Learning</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite broughton_tensorflow_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-18" id="summaryabstract-18">Summary/Abstract</a></h1>
<div>We introduce {TensorFlow} Quantum ({TFQ}), an open source library for the rapid prototyping of hybrid quantum-classical models for classical or quantum data. This framework offers high-level abstractions for the design and training of both discriminative and generative quantum models under {TensorFlow} and supports high-performance quantum circuit simulators. We provide an overview of the software architecture and building blocks through several examples and review the theory of hybrid quantum-classical neural networks. We illustrate {TFQ} functionalities via several basic applications including supervised learning for quantum classification, quantum control, and quantum approximate optimization. Moreover, we demonstrate how one can apply {TFQ} to tackle advanced quantum learning tasks including meta-learning, Hamiltonian learning, and sampling thermal states. We hope this framework provides the necessary tools for the quantum computing and machine learning research communities to explore models of both natural and artificial quantum systems, and ultimately discover new quantum algorithms which could potentially yield a quantum advantage.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="brown_language_2020" class=ref>
<summary class=citation>
<a id="brown_language_2020">[brown_language_2020]</a> - Brown, Tom B. and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and Agarwal, Sandhini and Herbert-Voss, Ariel and Krueger, Gretchen and Henighan, Tom and Child, Rewon and Ramesh, Aditya and Ziegler, Daniel M. and Wu, Jeffrey and Winter, Clemens and Hesse, Christopher and Chen, Mark and Sigler, Eric and Litwin, Mateusz and Gray, Scott and Chess, Benjamin and Clark, Jack and Berner, Christopher and {McCandlish}, Sam and Radford, Alec and Sutskever, Ilya and Amodei, Dario - <a href="http://arxiv.org/abs/2005.14165" target="_blank"><cite>Language Models are Few-Shot Learners</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite brown_language_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-19" id="summaryabstract-19">Summary/Abstract</a></h1>
<div>Recent work has demonstrated substantial gains on many {NLP} tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something which current {NLP} systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches. Specifically, we train {GPT}-3, an autoregressive language model with 175 billion parameters, 10x more than any previous non-sparse language model, and test its performance in the few-shot setting. For all tasks, {GPT}-3 is applied without any gradient updates or fine-tuning, with tasks and few-shot demonstrations specified purely via text interaction with the model. {GPT}-3 achieves strong performance on many {NLP} datasets, including translation, question-answering, and cloze tasks, as well as several tasks that require on-the-fly reasoning or domain adaptation, such as unscrambling words, using a novel word in a sentence, or performing 3-digit arithmetic. At the same time, we also identify some datasets where {GPT}-3&#x27;s few-shot learning still struggles, as well as some datasets where {GPT}-3 faces methodological issues related to training on large web corpora. Finally, we find that {GPT}-3 can generate samples of news articles which human evaluators have difficulty distinguishing from articles written by humans. We discuss broader societal impacts of this finding and of {GPT}-3 in general.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="brunner_entity_2020" class=ref>
<summary class=citation>
<a id="brunner_entity_2020">[brunner_entity_2020]</a> - Brunner, Ursin and Stockinger, Kurt - <a href="https://openproceedings.org/2020/conf/edbt/paper_205.pdf" target="_blank"><cite>Entity Matching with Transformer Architectures - A Step Forward in Data Integration</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite brunner_entity_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-20" id="summaryabstract-20">Summary/Abstract</a></h1>
<div>Transformer architectures have proven to be very effective and provide state-of-the-art results in many natural language tasks. The attention-based architecture in combination with pre-training on large amounts of text lead to the recent breakthrough and a variety of slightly different implementations. In this paper we analyze how well four of the most recent attention-based transformer architectures ({BERT}[6], {XLNet}[33], {RoBERTa}[17] and {DistilBERT} [23]) perform on the task of entity matching - a crucial part of data integration. Entity matching ({EM}) is the task of finding data instances that refer to the same real-world entity. It is a challenging task if the data instances consist of long textual data or if the data instances are dirty due to misplaced values.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="brunner_identifiability_2020" class=ref>
<summary class=citation>
<a id="brunner_identifiability_2020">[brunner_identifiability_2020]</a> - Brunner, Gino and Liu, Yang and Pascual, Damián and Richter, Oliver and Ciaramita, Massimiliano and Wattenhofer, Roger - <a href="http://arxiv.org/abs/1908.04211" target="_blank"><cite>On Identifiability in Transformers</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite brunner_identifiability_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-21" id="summaryabstract-21">Summary/Abstract</a></h1>
<div>In this paper we delve deep in the Transformer architecture by investigating two of its core components: self-attention and contextual embeddings. In particular, we study the identifiability of attention weights and token embeddings, and the aggregation of context into hidden tokens. We show that, for sequences longer than the attention head dimension, attention weights are not identifiable. We propose effective attention as a complementary tool for improving explanatory interpretations based on attention. Furthermore, we show that input tokens retain to a large degree their identity across the model. We also find evidence suggesting that identity information is mainly encoded in the angle of the embeddings and gradually decreases with depth. Finally, we demonstrate strong mixing of input information in the generation of contextual embeddings by means of a novel quantification method based on gradient attribution. Overall, we show that self-attention distributions are not directly interpretable and present tools to better understand and further investigate Transformer models.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="bucilua_model_2006" class=ref>
<summary class=citation>
<a id="bucilua_model_2006">[bucilua_model_2006]</a> - Buciluǎ, Cristian and Caruana, Rich and Niculescu-Mizil, Alexandru - <a href="https://doi.org/10.1145/1150402.1150464" target="_blank"><cite>Model compression</cite></a>. - 2006. -
<button onclick="copyToClipboard('\{\{ #cite bucilua_model_2006 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-22" id="summaryabstract-22">Summary/Abstract</a></h1>
<div>Often the best performing supervised learning models are ensembles of hundreds or thousands of base-level classifiers. Unfortunately, the space required to store this many classifiers, and the time required to execute them at run-time, prohibits their use in applications where test sets are large (e.g. Google), where storage space is at a premium (e.g. {PDAs}), and where computational power is limited (e.g. hea-ring aids). We present a method for compressing large, complex ensembles into smaller, faster models, usually without significant loss in performance.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="cappelletti_polyadic_2020" class=ref>
<summary class=citation>
<a id="cappelletti_polyadic_2020">[cappelletti_polyadic_2020]</a> - Cappelletti, William and Erbanni, Rebecca and Keller, Joaquín - <a href="http://arxiv.org/abs/2007.14044" target="_blank"><cite>Polyadic Quantum Classifier</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite cappelletti_polyadic_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-23" id="summaryabstract-23">Summary/Abstract</a></h1>
<div>We introduce here a supervised quantum machine learning algorithm for multi-class classification on {NISQ} architectures. A parametric quantum circuit is trained to output a specific bit string corresponding to the class of the input datapoint. We train and test it on an {IBMq} 5-qubit quantum computer and the algorithm shows good accuracy –compared to a classical machine learning model– for ternary classification of the Iris dataset and an extension of the {XOR} problem. Furthermore, we evaluate with simulations how the algorithm fares for a binary and a quaternary classification on resp. a known binary dataset and a synthetic dataset.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="caruana_multitask_1997" class=ref>
<summary class=citation>
<a id="caruana_multitask_1997">[caruana_multitask_1997]</a> - Caruana, Rich - <a href="http://reports-archive.adm.cs.cmu.edu/anon/1997/CMU-CS-97-203.pdf" target="_blank"><cite>Multitask Learning</cite></a>. - 1997. -
<button onclick="copyToClipboard('\{\{ #cite caruana_multitask_1997 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-24" id="summaryabstract-24">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="chen_universal_2023" class=ref>
<summary class=citation>
<a id="chen_universal_2023">[chen_universal_2023]</a> - Chen, Xinyun and Aksitov, Renat and Alon, Uri and Ren, Jie and Xiao, Kefan and Yin, Pengcheng and Prakash, Sushant and Sutton, Charles and Wang, Xuezhi and Zhou, Denny - <a href="http://arxiv.org/abs/2311.17311" target="_blank"><cite>Universal Self-Consistency for Large Language Model Generation</cite></a>. - 2023. -
<button onclick="copyToClipboard('\{\{ #cite chen_universal_2023 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-25" id="summaryabstract-25">Summary/Abstract</a></h1>
<div>Self-consistency with chain-of-thought prompting ({CoT}) has demonstrated remarkable performance gains on various challenging tasks, by utilizing multiple reasoning paths sampled from large language models ({LLMs}). However, selfconsistency relies on the answer extraction process to aggregate multiple solutions, which is not applicable to free-form answers. In this work, we propose Universal Self-Consistency ({USC}), which leverages {LLMs} themselves to select the most consistent answer among multiple candidates. We evaluate {USC} on a variety of benchmarks, including mathematical reasoning, code generation, long-context summarization, and open-ended question answering. On open-ended generation tasks where the original self-consistency method is not applicable, {USC} effectively utilizes multiple samples and improves the performance. For mathematical reasoning, {USC} matches the standard self-consistency performance without requiring the answer formats to be similar. Finally, without access to execution results, {USC} also matches the execution-based voting performance on code generation.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="chen_teaching_2023" class=ref>
<summary class=citation>
<a id="chen_teaching_2023">[chen_teaching_2023]</a> - Chen, Xinyun and Lin, Maxwell and Schärli, Nathanael and Zhou, Denny - <a href="http://arxiv.org/abs/2304.05128" target="_blank"><cite>Teaching Large Language Models to Self-Debug</cite></a>. - 2023. -
<button onclick="copyToClipboard('\{\{ #cite chen_teaching_2023 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-26" id="summaryabstract-26">Summary/Abstract</a></h1>
<div>Large language models ({LLMs}) have achieved impressive performance on code generation. However, for complex programming tasks, generating the correct solution in one go becomes challenging, thus some prior works have designed program repair approaches to improve code generation performance. In this work, we propose {SELF}-{DEBUGGING}, which teaches a large language model to debug its predicted program via few-shot demonstrations. In particular, we demonstrate that {SELF}-{DEBUGGING} can teach the large language model to perform rubber duck debugging; i.e., without any human feedback on the code correctness or error messages, the model is able to identify its mistakes by investigating the execution results and explaining the generated code in natural language. {SELF}-{DEBUGGING} achieves the state-of-the-art performance on several code generation benchmarks, including the Spider dataset for text-to-{SQL} generation, {TransCoder} for C++to-Python translation, and {MBPP} for text-to-Python generation. On the Spider benchmark where there are no unit tests to verify the correctness of predictions, {SELF}-{DEBUGGING} with code explanation consistently improves the baseline by 2 − 3\%, and improves the prediction accuracy on problems of the hardest level by 9\%. On {TransCoder} and {MBPP} where unit tests are available, {SELF}-{DEBUGGING} improves the baseline accuracy by up to 12\%. Meanwhile, by leveraging feedback messages and reusing failed predictions, {SELF}-{DEBUGGING} notably improves sample efficiency, and can match or outperform baseline models that generate more than 10× candidate programs.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="cheng_long_2016" class=ref>
<summary class=citation>
<a id="cheng_long_2016">[cheng_long_2016]</a> - Cheng, Jianpeng and Dong, Li and Lapata, Mirella - <a href="http://arxiv.org/abs/1601.06733" target="_blank"><cite>Long Short-Term Memory-Networks for Machine Reading</cite></a>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite cheng_long_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-27" id="summaryabstract-27">Summary/Abstract</a></h1>
<div>In this paper we address the question of how to render sequence-level networks better at handling structured input. We propose a machine reading simulator which processes text incrementally from left to right and performs shallow reasoning with memory and attention. The reader extends the Long Short-Term Memory architecture with a memory network in place of a single memory cell. This enables adaptive memory usage during recurrence with neural attention, offering a way to weakly induce relations among tokens. The system is initially designed to process a single sequence but we also demonstrate how to integrate it with an encoder-decoder architecture. Experiments on language modeling, sentiment analysis, and natural language inference show that our model matches or outperforms the state of the art.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="child_generating_2019" class=ref>
<summary class=citation>
<a id="child_generating_2019">[child_generating_2019]</a> - Child, Rewon and Gray, Scott and Radford, Alec and Sutskever, Ilya - <a href="http://arxiv.org/abs/1904.10509" target="_blank"><cite>Generating Long Sequences with Sparse Transformers</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite child_generating_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-28" id="summaryabstract-28">Summary/Abstract</a></h1>
<div>Transformers are powerful sequence models, but require time and memory that grows quadratically with the sequence length. In this paper we introduce sparse factorizations of the attention matrix which reduce this to \$O(n {\textbackslash}sqrt\{n\})\$. We also introduce a) a variation on architecture and initialization to train deeper networks, b) the recomputation of attention matrices to save memory, and c) fast attention kernels for training. We call networks with these changes Sparse Transformers, and show they can model sequences tens of thousands of timesteps long using hundreds of layers. We use the same architecture to model images, audio, and text from raw bytes, setting a new state of the art for density modeling of Enwik8, {CIFAR}-10, and {ImageNet}-64. We generate unconditional samples that demonstrate global coherence and great diversity, and show it is possible in principle to use self-attention to model sequences of length one million or more.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="clark_whatever_2013" class=ref>
<summary class=citation>
<a id="clark_whatever_2013">[clark_whatever_2013]</a> - Clark, Andy - <a href="https://www.cambridge.org/core/product/identifier/S0140525X12000477/type/journal_article" target="_blank"><cite>Whatever next? Predictive brains, situated agents, and the future of cognitive science</cite></a>. - 2013. -
<button onclick="copyToClipboard('\{\{ #cite clark_whatever_2013 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-29" id="summaryabstract-29">Summary/Abstract</a></h1>
<div>Brains, it has recently been argued, are essentially prediction machines. They are bundles of cells that support perception and action by constantly attempting to match incoming sensory inputs with top-down expectations or predictions. This is achieved using a hierarchical generative model that aims to minimize prediction error within a bidirectional cascade of cortical processing. Such accounts offer a unifying model of perception and action, illuminate the functional role of attention, and may neatly capture the special contribution of cortical processing to adaptive success. This target article critically examines this “hierarchical prediction machine” approach, concluding that it offers the best clue yet to the shape of a uniﬁed science of mind and action. Sections 1 and 2 lay out the key elements and implications of the approach. Section 3 explores a variety of pitfalls and challenges, spanning the evidential, the methodological, and the more properly conceptual. The paper ends (sections 4 and 5) by asking how such approaches might impact our more general vision of mind, experience, and agency.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="clark_electra_2019" class=ref>
<summary class=citation>
<a id="clark_electra_2019">[clark_electra_2019]</a> - Clark, Kevin and Luong, Minh-Thang and Le, Quoc V. and Manning, Christopher D. - <a href="https://openreview.net/forum?id&#x3D;r1xMH1BtvB" target="_blank"><cite>{ELECTRA}: Pre-training Text Encoders as Discriminators Rather Than Generators</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite clark_electra_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-30" id="summaryabstract-30">Summary/Abstract</a></h1>
<div>Masked language modeling ({MLM}) pre-training methods such as {BERT} corrupt the input by replacing some tokens with [{MASK}] and then train a model to reconstruct the original tokens. While they produce...</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="clark_what_2019" class=ref>
<summary class=citation>
<a id="clark_what_2019">[clark_what_2019]</a> - Clark, Kevin and Khandelwal, Urvashi and Levy, Omer and Manning, Christopher D. - <a href="http://arxiv.org/abs/1906.04341" target="_blank"><cite>What Does {BERT} Look At? An Analysis of {BERT}&#x27;s Attention</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite clark_what_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-31" id="summaryabstract-31">Summary/Abstract</a></h1>
<div>Large pre-trained neural networks such as {BERT} have had great recent success in {NLP}, motivating a growing body of research investigating what aspects of language they are able to learn from unlabeled data. Most recent analysis has focused on model outputs (e.g., language model surprisal) or internal vector representations (e.g., probing classifiers). Complementary to these works, we propose methods for analyzing the attention mechanisms of pre-trained models and apply them to {BERT}. {BERT}&#x27;s attention heads exhibit patterns such as attending to delimiter tokens, specific positional offsets, or broadly attending over the whole sentence, with heads in the same layer often exhibiting similar behaviors. We further show that certain attention heads correspond well to linguistic notions of syntax and coreference. For example, we find heads that attend to the direct objects of verbs, determiners of nouns, objects of prepositions, and coreferent mentions with remarkably high accuracy. Lastly, we propose an attention-based probing classifier and use it to further demonstrate that substantial syntactic information is captured in {BERT}&#x27;s attention.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="dai_transformer-xl:_2019" class=ref>
<summary class=citation>
<a id="dai_transformer-xl:_2019">[dai_transformer-xl:_2019]</a> - Dai, Zihang and Yang, Zhilin and Yang, Yiming and Carbonell, Jaime and Le, Quoc V. and Salakhutdinov, Ruslan - <a href="http://arxiv.org/abs/1901.02860" target="_blank"><cite>Transformer-{XL}: Attentive Language Models Beyond a Fixed-Length Context</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite dai_transformer-xl:_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-32" id="summaryabstract-32">Summary/Abstract</a></h1>
<div>Transformers have a potential of learning longer-term dependency, but are limited by a fixed-length context in the setting of language modeling. We propose a novel neural architecture Transformer-{XL} that enables learning dependency beyond a fixed length without disrupting temporal coherence. It consists of a segment-level recurrence mechanism and a novel positional encoding scheme. Our method not only enables capturing longer-term dependency, but also resolves the context fragmentation problem. As a result, Transformer-{XL} learns dependency that is 80\% longer than {RNNs} and 450\% longer than vanilla Transformers, achieves better performance on both short and long sequences, and is up to 1,800+ times faster than vanilla Transformers during evaluation. Notably, we improve the state-of-the-art results of bpc/perplexity to 0.99 on enwiki8, 1.08 on text8, 18.3 on {WikiText}-103, 21.8 on One Billion Word, and 54.5 on Penn Treebank (without finetuning). When trained only on {WikiText}-103, Transformer-{XL} manages to generate reasonably coherent, novel text articles with thousands of tokens. Our code, pretrained models, and hyperparameters are available in both Tensorflow and {PyTorch}.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="dathathri_plug_2020" class=ref>
<summary class=citation>
<a id="dathathri_plug_2020">[dathathri_plug_2020]</a> - Dathathri, Sumanth and Madotto, Andrea and Lan, Janice and Hung, Jane and Frank, Eric and Molino, Piero and Yosinski, Jason and Liu, Rosanne - <a href="http://arxiv.org/abs/1912.02164" target="_blank"><cite>Plug and Play Language Models: A Simple Approach to Controlled Text Generation</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite dathathri_plug_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-33" id="summaryabstract-33">Summary/Abstract</a></h1>
<div>Large transformer-based language models ({LMs}) trained on huge text corpora have shown unparalleled generation capabilities. However, controlling attributes of the generated language (e.g. switching topic or sentiment) is difficult without modifying the model architecture or fine-tuning on attribute-specific data and entailing the significant cost of retraining. We propose a simple alternative: the Plug and Play Language Model ({PPLM}) for controllable language generation, which combines a pretrained {LM} with one or more simple attribute classifiers that guide text generation without any further training of the {LM}. In the canonical scenario we present, the attribute models are simple classifiers consisting of a user-specified bag of words or a single learned layer with 100,000 times fewer parameters than the {LM}. Sampling entails a forward and backward pass in which gradients from the attribute model push the {LM}&#x27;s hidden activations and thus guide the generation. Model samples demonstrate control over a range of topics and sentiment styles, and extensive automated and human annotated evaluations show attribute alignment and fluency. {PPLMs} are flexible in that any combination of differentiable attribute models may be used to steer text generation, which will allow for diverse and creative applications beyond the examples given in this paper.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="de_lange_continual_2020" class=ref>
<summary class=citation>
<a id="de_lange_continual_2020">[de_lange_continual_2020]</a> - De Lange, Matthias and Aljundi, Rahaf and Masana, Marc and Parisot, Sarah and Jia, Xu and Leonardis, Ales and Slabaugh, Gregory and Tuytelaars, Tinne - <a href="http://arxiv.org/abs/1909.08383" target="_blank"><cite>A continual learning survey: Defying forgetting in classification tasks</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite de_lange_continual_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-34" id="summaryabstract-34">Summary/Abstract</a></h1>
<div>Artificial neural networks thrive in solving the classification problem for a particular rigid task, acquiring knowledge through generalized learning behaviour from a distinct training phase. The resulting network resembles a static entity of knowledge, with endeavours to extend this knowledge without targeting the original task resulting in a catastrophic forgetting. Continual learning shifts this paradigm towards networks that can continually accumulate knowledge over different tasks without the need to retrain from scratch. We focus on task incremental classification, where tasks arrive sequentially and are delineated by clear boundaries. Our main contributions concern 1) a taxonomy and extensive overview of the state-of-the-art, 2) a novel framework to continually determine the stability-plasticity trade-off of the continual learner, 3) a comprehensive experimental comparison of 11 state-of-the-art continual learning methods and 4 baselines. We empirically scrutinize method strengths and weaknesses on three benchmarks, considering Tiny Imagenet and large-scale unbalanced {iNaturalist} and a sequence of recognition datasets. We study the influence of model capacity, weight decay and dropout regularization, and the order in which the tasks are presented, and qualitatively compare methods in terms of required memory, computation time, and storage.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="devlin_bert_2019" class=ref>
<summary class=citation>
<a id="devlin_bert_2019">[devlin_bert_2019]</a> - Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina - <a href="http://arxiv.org/abs/1810.04805" target="_blank"><cite>{BERT}: Pre-training of Deep Bidirectional Transformers for Language Understanding</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite devlin_bert_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-35" id="summaryabstract-35">Summary/Abstract</a></h1>
<div>We introduce a new language representation model called {BERT}, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, {BERT} is designed to pre-train deep bidirectional representations from unlabeled text by jointly conditioning on both left and right context in all layers. As a result, the pre-trained {BERT} model can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. {BERT} is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the {GLUE} score to 80.5\% (7.7\% point absolute improvement), {MultiNLI} accuracy to 86.7\% (4.6\% absolute improvement), {SQuAD} v1.1 question answering Test F1 to 93.2 (1.5 point absolute improvement) and {SQuAD} v2.0 Test F1 to 83.1 (5.1 point absolute improvement).</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="doersch_tutorial_2016" class=ref>
<summary class=citation>
<a id="doersch_tutorial_2016">[doersch_tutorial_2016]</a> - Doersch, Carl - <a href="http://arxiv.org/abs/1606.05908" target="_blank"><cite>Tutorial on Variational Autoencoders</cite></a>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite doersch_tutorial_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-36" id="summaryabstract-36">Summary/Abstract</a></h1>
<div>In just three years, Variational Autoencoders ({VAEs}) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. {VAEs} are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. {VAEs} have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, {CIFAR} images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind {VAEs}, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="domingos_master_2015" class=ref>
<summary class=citation>
<a id="domingos_master_2015">[domingos_master_2015]</a> - Domingos, Pedro - <cite>The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World</cite>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite domingos_master_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-37" id="summaryabstract-37">Summary/Abstract</a></h1>
<div>A thought-provoking and wide-ranging exploration of machine learning and the race to build computer intelligences as flexible as our {ownIn} the world&#x27;s top research labs and universities, the race is on to invent the ultimate learning algorithm: one capable of discovering any knowledge from data, and doing anything we want, before we even ask. In The Master Algorithm, Pedro Domingos lifts the veil to give us a peek inside the learning machines that power Google, Amazon, and your smartphone. He assembles a blueprint for the future universal learner--the Master Algorithm--and discusses what it will mean for business, science, and society. If data-ism is today&#x27;s philosophy, this book is its bible.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="dubey_llama_2024" class=ref>
<summary class=citation>
<a id="dubey_llama_2024">[dubey_llama_2024]</a> - Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Yang, Amy and Fan, Angela and Goyal, Anirudh and Hartshorn, Anthony and Yang, Aobo and Mitra, Archi and Sravankumar, Archie and Korenev, Artem and Hinsvark, Arthur and Rao, Arun and Zhang, Aston and Rodriguez, Aurelien and Gregerson, Austen and Spataru, Ava and Roziere, Baptiste and Biron, Bethany and Tang, Binh and Chern, Bobbie and Caucheteux, Charlotte and Nayak, Chaya and Bi, Chloe and Marra, Chris and {McConnell}, Chris and Keller, Christian and Touret, Christophe and Wu, Chunyang and Wong, Corinne and Ferrer, Cristian Canton and Nikolaidis, Cyrus and Allonsius, Damien and Song, Daniel and Pintz, Danielle and Livshits, Danny and Esiobu, David and Choudhary, Dhruv and Mahajan, Dhruv and Garcia-Olano, Diego and Perino, Diego and Hupkes, Dieuwke and Lakomkin, Egor and {AlBadawy}, Ehab and Lobanova, Elina and Dinan, Emily and Smith, Eric Michael and Radenovic, Filip and Zhang, Frank and Synnaeve, Gabriel and Lee, Gabrielle and Anderson, Georgia Lewis and Nail, Graeme and Mialon, Gregoire and Pang, Guan and Cucurell, Guillem and Nguyen, Hailey and Korevaar, Hannah and Xu, Hu and Touvron, Hugo and Zarov, Iliyan and Ibarra, Imanol Arrieta and Kloumann, Isabel and Misra, Ishan and Evtimov, Ivan and Copet, Jade and Lee, Jaewon and Geffert, Jan and Vranes, Jana and Park, Jason and Mahadeokar, Jay and Shah, Jeet and van der Linde, Jelmer and Billock, Jennifer and Hong, Jenny and Lee, Jenya and Fu, Jeremy and Chi, Jianfeng and Huang, Jianyu and Liu, Jiawen and Wang, Jie and Yu, Jiecao and Bitton, Joanna and Spisak, Joe and Park, Jongsoo and Rocca, Joseph and Johnstun, Joshua and Saxe, Joshua and Jia, Junteng and Alwala, Kalyan Vasuden and Upasani, Kartikeya and Plawiak, Kate and Li, Ke and Heafield, Kenneth and Stone, Kevin and El-Arini, Khalid and Iyer, Krithika and Malik, Kshitiz and Chiu, Kuenley and Bhalla, Kunal and Rantala-Yeary, Lauren and van der Maaten, Laurens and Chen, Lawrence and Tan, Liang and Jenkins, Liz and Martin, Louis and Madaan, Lovish and Malo, Lubo and Blecher, Lukas and Landzaat, Lukas and de Oliveira, Luke and Muzzi, Madeline and Pasupuleti, Mahesh and Singh, Mannat and Paluri, Manohar and Kardas, Marcin and Oldham, Mathew and Rita, Mathieu and Pavlova, Maya and Kambadur, Melanie and Lewis, Mike and Si, Min and Singh, Mitesh Kumar and Hassan, Mona and Goyal, Naman and Torabi, Narjes and Bashlykov, Nikolay and Bogoychev, Nikolay and Chatterji, Niladri and Duchenne, Olivier and Çelebi, Onur and Alrassy, Patrick and Zhang, Pengchuan and Li, Pengwei and Vasic, Petar and Weng, Peter and Bhargava, Prajjwal and Dubal, Pratik and Krishnan, Praveen and Koura, Punit Singh and Xu, Puxin and He, Qing and Dong, Qingxiao and Srinivasan, Ragavan and Ganapathy, Raj and Calderer, Ramon and Cabral, Ricardo Silveira and Stojnic, Robert and Raileanu, Roberta and Girdhar, Rohit and Patel, Rohit and Sauvestre, Romain and Polidoro, Ronnie and Sumbaly, Roshan and Taylor, Ross and Silva, Ruan and Hou, Rui and Wang, Rui and Hosseini, Saghar and Chennabasappa, Sahana and Singh, Sanjay and Bell, Sean and Kim, Seohyun Sonia and Edunov, Sergey and Nie, Shaoliang and Narang, Sharan and Raparthy, Sharath and Shen, Sheng and Wan, Shengye and Bhosale, Shruti and Zhang, Shun and Vandenhende, Simon and Batra, Soumya and Whitman, Spencer and Sootla, Sten and Collot, Stephane and Gururangan, Suchin and Borodinsky, Sydney and Herman, Tamar and Fowler, Tara and Sheasha, Tarek and Georgiou, Thomas and Scialom, Thomas and Speckbacher, Tobias and Mihaylov, Todor and Xiao, Tong and Karn, Ujjwal and Goswami, Vedanuj and Gupta, Vibhor and Ramanathan, Vignesh and Kerkez, Viktor and Gonguet, Vincent and Do, Virginie and Vogeti, Vish and Petrovic, Vladan and Chu, Weiwei and Xiong, Wenhan and Fu, Wenyin and Meers, Whitney and Martinet, Xavier and Wang, Xiaodong and Tan, Xiaoqing Ellen and Xie, Xinfeng and Jia, Xuchao and Wang, Xuewei and Goldschlag, Yaelle and Gaur, Yashesh and Babaei, Yasmine and Wen, Yi and Song, Yiwen and Zhang, Yuchen and Li, Yue and Mao, Yuning and Coudert, Zacharie Delpierre and Yan, Zheng and Chen, Zhengxing and Papakipos, Zoe and Singh, Aaditya and Grattafiori, Aaron and Jain, Abha and Kelsey, Adam and Shajnfeld, Adam and Gangidi, Adithya and Victoria, Adolfo and Goldstand, Ahuva and Menon, Ajay and Sharma, Ajay and Boesenberg, Alex and Vaughan, Alex and Baevski, Alexei and Feinstein, Allie and Kallet, Amanda and Sangani, Amit and Yunus, Anam and Lupu, Andrei and Alvarado, Andres and Caples, Andrew and Gu, Andrew and Ho, Andrew and Poulton, Andrew and Ryan, Andrew and Ramchandani, Ankit and Franco, Annie and Saraf, Aparajita and Chowdhury, Arkabandhu and Gabriel, Ashley and Bharambe, Ashwin and Eisenman, Assaf and Yazdan, Azadeh and James, Beau and Maurer, Ben and Leonhardi, Benjamin and Huang, Bernie and Loyd, Beth and De Paola, Beto and Paranjape, Bhargavi and Liu, Bing and Wu, Bo and Ni, Boyu and Hancock, Braden and Wasti, Bram and Spence, Brandon and Stojkovic, Brani and Gamido, Brian and Montalvo, Britt and Parker, Carl and Burton, Carly and Mejia, Catalina and Wang, Changhan and Kim, Changkyu and Zhou, Chao and Hu, Chester and Chu, Ching-Hsiang and Cai, Chris and Tindal, Chris and Feichtenhofer, Christoph and Civin, Damon and Beaty, Dana and Kreymer, Daniel and Li, Daniel and Wyatt, Danny and Adkins, David and Xu, David and Testuggine, Davide and David, Delia and Parikh, Devi and Liskovich, Diana and Foss, Didem and Wang, Dingkang and Le, Duc and Holland, Dustin and Dowling, Edward and Jamil, Eissa and Montgomery, Elaine and Presani, Eleonora and Hahn, Emily and Wood, Emily and Brinkman, Erik and Arcaute, Esteban and Dunbar, Evan and Smothers, Evan and Sun, Fei and Kreuk, Felix and Tian, Feng and Ozgenel, Firat and Caggioni, Francesco and Guzmán, Francisco and Kanayet, Frank and Seide, Frank and Florez, Gabriela Medina and Schwarz, Gabriella and Badeer, Gada and Swee, Georgia and Halpern, Gil and Thattai, Govind and Herman, Grant and Sizov, Grigory and Guangyi and Zhang and Lakshminarayanan, Guna and Shojanazeri, Hamid and Zou, Han and Wang, Hannah and Zha, Hanwen and Habeeb, Haroun and Rudolph, Harrison and Suk, Helen and Aspegren, Henry and Goldman, Hunter and Damlaj, Ibrahim and Molybog, Igor and Tufanov, Igor and Veliche, Irina-Elena and Gat, Itai and Weissman, Jake and Geboski, James and Kohli, James and Asher, Japhet and Gaya, Jean-Baptiste and Marcus, Jeff and Tang, Jeff and Chan, Jennifer and Zhen, Jenny and Reizenstein, Jeremy and Teboul, Jeremy and Zhong, Jessica and Jin, Jian and Yang, Jingyi and Cummings, Joe and Carvill, Jon and Shepard, Jon and {McPhie}, Jonathan and Torres, Jonathan and Ginsburg, Josh and Wang, Junjie and Wu, Kai and U, Kam Hou and Saxena, Karan and Prasad, Karthik and Khandelwal, Kartikay and Zand, Katayoun and Matosich, Kathy and Veeraraghavan, Kaushik and Michelena, Kelly and Li, Keqian and Huang, Kun and Chawla, Kunal and Lakhotia, Kushal and Huang, Kyle and Chen, Lailin and Garg, Lakshya and A, Lavender and Silva, Leandro and Bell, Lee and Zhang, Lei and Guo, Liangpeng and Yu, Licheng and Moshkovich, Liron and Wehrstedt, Luca and Khabsa, Madian and Avalani, Manav and Bhatt, Manish and Tsimpoukelli, Maria and Mankus, Martynas and Hasson, Matan and Lennie, Matthew and Reso, Matthias and Groshev, Maxim and Naumov, Maxim and Lathi, Maya and Keneally, Meghan and Seltzer, Michael L. and Valko, Michal and Restrepo, Michelle and Patel, Mihir and Vyatskov, Mik and Samvelyan, Mikayel and Clark, Mike and Macey, Mike and Wang, Mike and Hermoso, Miquel Jubert and Metanat, Mo and Rastegari, Mohammad and Bansal, Munish and Santhanam, Nandhini and Parks, Natascha and White, Natasha and Bawa, Navyata and Singhal, Nayan and Egebo, Nick and Usunier, Nicolas and Laptev, Nikolay Pavlovich and Dong, Ning and Zhang, Ning and Cheng, Norman and Chernoguz, Oleg and Hart, Olivia and Salpekar, Omkar and Kalinli, Ozlem and Kent, Parkin and Parekh, Parth and Saab, Paul and Balaji, Pavan and Rittner, Pedro and Bontrager, Philip and Roux, Pierre and Dollar, Piotr and Zvyagina, Polina and Ratanchandani, Prashant and Yuvraj, Pritish and Liang, Qian and Alao, Rachad and Rodriguez, Rachel and Ayub, Rafi and Murthy, Raghotham and Nayani, Raghu and Mitra, Rahul and Li, Raymond and Hogan, Rebekkah and Battey, Robin and Wang, Rocky and Maheswari, Rohan and Howes, Russ and Rinott, Ruty and Bondu, Sai Jayesh and Datta, Samyak and Chugh, Sara and Hunt, Sara and Dhillon, Sargun and Sidorov, Sasha and Pan, Satadru and Verma, Saurabh and Yamamoto, Seiji and Ramaswamy, Sharadh and Lindsay, Shaun and Lindsay, Shaun and Feng, Sheng and Lin, Shenghao and Zha, Shengxin Cindy and Shankar, Shiva and Zhang, Shuqiang and Zhang, Shuqiang and Wang, Sinong and Agarwal, Sneha and Sajuyigbe, Soji and Chintala, Soumith and Max, Stephanie and Chen, Stephen and Kehoe, Steve and Satterfield, Steve and Govindaprasad, Sudarshan and Gupta, Sumit and Cho, Sungmin and Virk, Sunny and Subramanian, Suraj and Choudhury, Sy and Goldman, Sydney and Remez, Tal and Glaser, Tamar and Best, Tamara and Kohler, Thilo and Robinson, Thomas and Li, Tianhe and Zhang, Tianjun and Matthews, Tim and Chou, Timothy and Shaked, Tzook and Vontimitta, Varun and Ajayi, Victoria and Montanez, Victoria and Mohan, Vijai and Kumar, Vinay Satish and Mangla, Vishal and Albiero, Vítor and Ionescu, Vlad and Poenaru, Vlad and Mihailescu, Vlad Tiberiu and Ivanov, Vladimir and Li, Wei and Wang, Wenchen and Jiang, Wenwen and Bouaziz, Wes and Constable, Will and Tang, Xiaocheng and Wang, Xiaofang and Wu, Xiaojian and Wang, Xiaolan and Xia, Xide and Wu, Xilun and Gao, Xinbo and Chen, Yanjun and Hu, Ye and Jia, Ye and Qi, Ye and Li, Yenda and Zhang, Yilin and Zhang, Ying and Adi, Yossi and Nam, Youngjin and Yu and Wang and Hao, Yuchen and Qian, Yundi and He, Yuzi and Rait, Zach and {DeVito}, Zachary and Rosnbrick, Zef and Wen, Zhaoduo and Yang, Zhenyu and Zhao, Zhiwei - <a href="http://arxiv.org/abs/2407.21783" target="_blank"><cite>The Llama 3 Herd of Models</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite dubey_llama_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-38" id="summaryabstract-38">Summary/Abstract</a></h1>
<div>Modern artificial intelligence ({AI}) systems are powered by foundation models. This paper presents a new set of foundation models, called Llama 3. It is a herd of language models that natively support multilinguality, coding, reasoning, and tool usage. Our largest model is a dense Transformer with 405B parameters and a context window of up to 128K tokens. This paper presents an extensive empirical evaluation of Llama 3. We find that Llama 3 delivers comparable quality to leading language models such as {GPT}-4 on a plethora of tasks. We publicly release Llama 3, including pre-trained and post-trained versions of the 405B parameter language model and our Llama Guard 3 model for input and output safety. The paper also presents the results of experiments in which we integrate image, video, and speech capabilities into Llama 3 via a compositional approach. We observe this approach performs competitively with the state-of-the-art on image, video, and speech recognition tasks. The resulting models are not yet being broadly released as they are still under development.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="edge_local_2024" class=ref>
<summary class=citation>
<a id="edge_local_2024">[edge_local_2024]</a> - Edge, Darren and Trinh, Ha and Cheng, Newman and Bradley, Joshua and Chao, Alex and Mody, Apurva and Truitt, Steven and Larson, Jonathan - <a href="http://arxiv.org/abs/2404.16130" target="_blank"><cite>From Local to Global: A Graph {RAG} Approach to Query-Focused Summarization</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite edge_local_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-39" id="summaryabstract-39">Summary/Abstract</a></h1>
<div>The use of retrieval-augmented generation ({RAG}) to retrieve relevant information from an external knowledge source enables large language models ({LLMs}) to answer questions over private and/or previously unseen document collections. However, {RAG} fails on global questions directed at an entire text corpus, such as What are the main themes in the dataset?, since this is inherently a query-focused summarization ({QFS}) task, rather than an explicit retrieval task. Prior {QFS} methods, meanwhile, fail to scale to the quantities of text indexed by typical {RAG} systems. To combine the strengths of these contrasting methods, we propose a Graph {RAG} approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed. Our approach uses an {LLM} to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pregenerate community summaries for all groups of closely-related entities. Given a question, each community summary is used to generate a partial response, before all partial responses are again summarized in a final response to the user. For a class of global sensemaking questions over datasets in the 1 million token range, we show that Graph {RAG} leads to substantial improvements over a na{\textbackslash}ive {RAG} baseline for both the comprehensiveness and diversity of generated answers. An open-source, Python-based implementation of both global and local Graph {RAG} approaches is forthcoming at https://aka.ms/graphrag.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="elias_what_2024" class=ref>
<summary class=citation>
<a id="elias_what_2024">[elias_what_2024]</a> - Elias, Greggory - <a href="https://skimai.com/what-is-autogen-our-full-guide-to-the-autogen-multi-agent-platform/" target="_blank"><cite>What is {AutoGen}? Our Full Guide to the Autogen Multi-Agent Platform</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite elias_what_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-40" id="summaryabstract-40">Summary/Abstract</a></h1>
<div>Discover the transformative potential of {AI} agents and multi-agent systems in business operations. Learn about Microsoft {AutoGen}, a framework that leverages {AI} agents and large language models to enhance flexibility, scalability, and problem-solving capabilities. Explore key features, real-world applications, and the unique advantages of {AutoGen} in {AI} development.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="fedorenko_language_2024" class=ref>
<summary class=citation>
<a id="fedorenko_language_2024">[fedorenko_language_2024]</a> - Fedorenko, Evelina and Piantadosi, Steven T. and Gibson, Edward A. F. - <a href="https://www.nature.com/articles/s41586-024-07522-w" target="_blank"><cite>Language is primarily a tool for communication rather than thought</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite fedorenko_language_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-41" id="summaryabstract-41">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="fei-fei_one-shot_2006" class=ref>
<summary class=citation>
<a id="fei-fei_one-shot_2006">[fei-fei_one-shot_2006]</a> - Fei-Fei, Li and Fergus, R. and Perona, P. - <cite>One-shot learning of object categories</cite>. - 2006. -
<button onclick="copyToClipboard('\{\{ #cite fei-fei_one-shot_2006 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-42" id="summaryabstract-42">Summary/Abstract</a></h1>
<div>Learning visual models of object categories notoriously requires hundreds or thousands of training examples. We show that it is possible to learn much information about a category from just one, or a handful, of images. The key insight is that, rather than learning from scratch, one can take advantage of knowledge coming from previously learned categories, no matter how different these categories might be. We explore a Bayesian implementation of this idea. Object categories are represented by probabilistic models. Prior knowledge is represented as a probability density function on the parameters of these models. The posterior model for an object category is obtained by updating the prior in the light of one or more observations. We test a simple implementation of our algorithm on a database of 101 diverse object categories. We compare category models learned by an implementation of our Bayesian approach to models learned from by maximum likelihood ({ML}) and maximum a posteriori ({MAP}) methods. We find that on a database of more than 100 categories, the Bayesian approach produces informative models when the number of training examples is too small for other methods to operate successfully.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="fink_object_2004" class=ref>
<summary class=citation>
<a id="fink_object_2004">[fink_object_2004]</a> - Fink, Michael - <a href="https://proceedings.neurips.cc/paper/2004/hash/ef1e491a766ce3127556063d49bc2f98-Abstract.html" target="_blank"><cite>Object Classification from a Single Example Utilizing Class Relevance Metrics</cite></a>. - 2004. -
<button onclick="copyToClipboard('\{\{ #cite fink_object_2004 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-43" id="summaryabstract-43">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="friston_free-energy_2010" class=ref>
<summary class=citation>
<a id="friston_free-energy_2010">[friston_free-energy_2010]</a> - Friston, Karl - <a href="https://www.nature.com/articles/nrn2787" target="_blank"><cite>The free-energy principle: a unified brain theory?</cite></a>. - 2010. -
<button onclick="copyToClipboard('\{\{ #cite friston_free-energy_2010 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-44" id="summaryabstract-44">Summary/Abstract</a></h1>
<div>A free-energy principle has been proposed recently that accounts for action, perception and learning. This Review looks at some key brain theories in the biological (for example, neural Darwinism) and physical (for example, information theory and optimal control theory) sciences from the free-energy perspective. Crucially, one key theme runs through each of these theories — optimization. Furthermore, if we look closely at what is optimized, the same quantity keeps emerging, namely value (expected reward, expected utility) or its complement, surprise (prediction error, expected cost). This is the quantity that is optimized under the free-energy principle, which suggests that several global brain theories might be unified within a free-energy framework.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="friston_free_2006" class=ref>
<summary class=citation>
<a id="friston_free_2006">[friston_free_2006]</a> - Friston, Karl and Kilner, James and Harrison, Lee - <a href="https://linkinghub.elsevier.com/retrieve/pii/S092842570600060X" target="_blank"><cite>A free energy principle for the brain</cite></a>. - 2006. -
<button onclick="copyToClipboard('\{\{ #cite friston_free_2006 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-45" id="summaryabstract-45">Summary/Abstract</a></h1>
<div>By formulating Helmholtz’s ideas about perception, in terms of modern-day theories, one arrives at a model of perceptual inference and learning that can explain a remarkable range of neurobiological facts: using constructs from statistical physics, the problems of inferring the causes of sensory input and learning the causal structure of their generation can be resolved using exactly the same principles. Furthermore, inference and learning can proceed in a biologically plausible fashion. The ensuing scheme rests on Empirical Bayes and hierarchical models of how sensory input is caused. The use of hierarchical models enables the brain to construct prior expectations in a dynamic and context-sensitive fashion. This scheme provides a principled way to understand many aspects of cortical organisation and responses.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="garcez_neural-symbolic_2019" class=ref>
<summary class=citation>
<a id="garcez_neural-symbolic_2019">[garcez_neural-symbolic_2019]</a> - Garcez, Artur d&#x27;Avila and Gori, Marco and Lamb, Luis C. and Serafini, Luciano and Spranger, Michael and Tran, Son N. - <a href="http://arxiv.org/abs/1905.06088" target="_blank"><cite>Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite garcez_neural-symbolic_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-46" id="summaryabstract-46">Summary/Abstract</a></h1>
<div>Current advances in Artificial Intelligence and machine learning in general, and deep learning in particular have reached unprecedented impact not only across research communities, but also over popular media channels. However, concerns about interpretability and accountability of {AI} have been raised by influential thinkers. In spite of the recent impact of {AI}, several works have identified the need for principled knowledge representation and reasoning mechanisms integrated with deep learning-based systems to provide sound and explainable models for such systems. Neural-symbolic computing aims at integrating, as foreseen by Valiant, two most fundamental cognitive abilities: the ability to learn from the environment, and the ability to reason from what has been learned. Neural-symbolic computing has been an active topic of research for many years, reconciling the advantages of robust learning in neural networks and reasoning and interpretability of symbolic representation. In this paper, we survey recent accomplishments of neural-symbolic computing as a principled methodology for integrated machine learning and reasoning. We illustrate the effectiveness of the approach by outlining the main characteristics of the methodology: principled integration of neural learning with symbolic knowledge representation and reasoning allowing for the construction of explainable {AI} systems. The insights provided by neural-symbolic computing shed new light on the increasingly prominent need for interpretable and accountable {AI} systems.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="gasparetto_survey_2022" class=ref>
<summary class=citation>
<a id="gasparetto_survey_2022">[gasparetto_survey_2022]</a> - Gasparetto, Andrea and Marcuzzo, Matteo and Zangari, Alessandro and Albarelli, Andrea - <a href="https://www.mdpi.com/2078-2489/13/2/83" target="_blank"><cite>A Survey on Text Classification Algorithms: From Text to Predictions</cite></a>. - 2022. -
<button onclick="copyToClipboard('\{\{ #cite gasparetto_survey_2022 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-47" id="summaryabstract-47">Summary/Abstract</a></h1>
<div>In recent years, the exponential growth of digital documents has been met by rapid progress in text classification techniques. Newly proposed machine learning algorithms leverage the latest advancements in deep learning methods, allowing for the automatic extraction of expressive features. The swift development of these methods has led to a plethora of strategies to encode natural language into machine-interpretable data. The latest language modelling algorithms are used in conjunction with ad hoc preprocessing procedures, of which the description is often omitted in favour of a more detailed explanation of the classification step. This paper offers a concise review of recent text classification models, with emphasis on the flow of data, from raw text to output labels. We highlight the differences between earlier methods and more recent, deep learning-based methods in both their functioning and in how they transform input data. To give a better perspective on the text classification landscape, we provide an overview of datasets for the English language, as well as supplying instructions for the synthesis of two new multilabel datasets, which we found to be particularly scarce in this setting. Finally, we provide an outline of new experimental results and discuss the open research challenges posed by deep learning-based language models.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="geiger_scaling_2020" class=ref>
<summary class=citation>
<a id="geiger_scaling_2020">[geiger_scaling_2020]</a> - Geiger, Mario and Jacot, Arthur and Spigler, Stefano and Gabriel, Franck and Sagun, Levent and d&#x27;Ascoli, Stéphane and Biroli, Giulio and Hongler, Clément and Wyart, Matthieu - <a href="http://arxiv.org/abs/1901.01608" target="_blank"><cite>Scaling description of generalization with number of parameters in deep learning</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite geiger_scaling_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-48" id="summaryabstract-48">Summary/Abstract</a></h1>
<div>Supervised deep learning involves the training of neural networks with a large number \$N\$ of parameters. For large enough \$N\$, in the so-called over-parametrized regime, one can essentially fit the training data points. Sparsity-based arguments would suggest that the generalization error increases as \$N\$ grows past a certain threshold \$N{\textasciicircum}\{*\}\$. Instead, empirical studies have shown that in the over-parametrized regime, generalization error keeps decreasing with \$N\$. We resolve this paradox through a new framework. We rely on the so-called Neural Tangent Kernel, which connects large neural nets to kernel methods, to show that the initialization causes finite-size random fluctuations \${\textbackslash}{\textbar}f\_\{N\}-{\textbackslash}bar\{f\}\_\{N\}{\textbackslash}{\textbar}{\textbackslash}sim N{\textasciicircum}\{-1/4\}\$ of the neural net output function \$f\_\{N\}\$ around its expectation \${\textbackslash}bar\{f\}\_\{N\}\$. These affect the generalization error \${\textbackslash}epsilon\_\{N\}\$ for classification: under natural assumptions, it decays to a plateau value \${\textbackslash}epsilon\_\{{\textbackslash}infty\}\$ in a power-law fashion \${\textbackslash}sim N{\textasciicircum}\{-1/2\}\$. This description breaks down at a so-called jamming transition \$N&#x3D;N{\textasciicircum}\{*\}\$. At this threshold, we argue that \${\textbackslash}{\textbar}f\_\{N\}{\textbackslash}{\textbar}\$ diverges. This result leads to a plausible explanation for the cusp in test error known to occur at \$N{\textasciicircum}\{*\}\$. Our results are confirmed by extensive empirical observations on the {MNIST} and {CIFAR} image datasets. Our analysis finally suggests that, given a computational envelope, the smallest generalization error is obtained using several networks of intermediate sizes, just beyond \$N{\textasciicircum}\{*\}\$, and averaging their outputs.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="goldberg_word2vec_2014" class=ref>
<summary class=citation>
<a id="goldberg_word2vec_2014">[goldberg_word2vec_2014]</a> - Goldberg, Yoav and Levy, Omer - <a href="http://arxiv.org/abs/1402.3722" target="_blank"><cite>word2vec Explained: deriving Mikolov et al.&#x27;s negative-sampling word-embedding method</cite></a>. - 2014. -
<button onclick="copyToClipboard('\{\{ #cite goldberg_word2vec_2014 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-49" id="summaryabstract-49">Summary/Abstract</a></h1>
<div>The word2vec software of Tomas Mikolov and colleagues (https://code.google.com/p/word2vec/ ) has gained a lot of traction lately, and provides state-of-the-art word embeddings. The learning models behind the software are described in two research papers. We found the description of the models in these papers to be somewhat cryptic and hard to follow. While the motivations and presentation may be obvious to the neural-networks language-modeling crowd, we had to struggle quite a bit to figure out the rationale behind the equations. This note is an attempt to explain equation (4) (negative sampling) in Distributed Representations of Words and Phrases and their Compositionality by Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg Corrado and Jeffrey Dean.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="gong_hierarchical_2020" class=ref>
<summary class=citation>
<a id="gong_hierarchical_2020">[gong_hierarchical_2020]</a> - Gong, Jibing and Liu, Mingsheng and Ma, Hongyuan and Teng, Zhiyong and Teng, Qi and Zhang, Hekai and Du, Linfeng and Chen, Shuai and Bhuiyan, Md and Li, Jianhua - <cite>Hierarchical Graph Transformer Based Deep Learning Model for Large-Scale Multi-Label Text Classification</cite>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite gong_hierarchical_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-50" id="summaryabstract-50">Summary/Abstract</a></h1>
<div>Traditional methods of multi-label text classification, particularly deep learning, have achieved remarkable results. However, most of these methods use word2vec technology to represent sequential text information, while ignoring the logic and internal hierarchy of the text itself. Although these approaches can learn the hypothetical hierarchy and logic of the text, it is unexplained. In addition, the traditional approach treats labels as independent individuals and ignores the relationships between them, which not only does not reflect reality but also causes significant loss of semantic information. In this paper, we propose a novel Hierarchical Graph Transformer based deep learning model for large-scale multi-label text classification. We first model the text into a graph structure that can embody the different semantics of the text and the connections between them. We then use a multi-layer transformer structure with a multi-head attention mechanism at the word, sentence, and graph levels to fully capture the features of the text and observe the importance of the separate parts. Finally, we use the hierarchical relationship of the labels to generate the representation of the labels, and design a weighted loss function based on the semantic distances of the labels. Extensive experiments conducted on three benchmark datasets demonstrated that the proposed model can realistically capture the hierarchy and logic of text and improve performance compared with the state-of-the-art methods.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="goodfellow_generative_2014" class=ref>
<summary class=citation>
<a id="goodfellow_generative_2014">[goodfellow_generative_2014]</a> - Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua - <a href="http://arxiv.org/abs/1406.2661" target="_blank"><cite>Generative Adversarial Networks</cite></a>. - 2014. -
<button onclick="copyToClipboard('\{\{ #cite goodfellow_generative_2014 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-51" id="summaryabstract-51">Summary/Abstract</a></h1>
<div>We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to 1/2 everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="goodfellow_deep_2016" class=ref>
<summary class=citation>
<a id="goodfellow_deep_2016">[goodfellow_deep_2016]</a> - Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron - <cite>Deep Learning</cite>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite goodfellow_deep_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-52" id="summaryabstract-52">Summary/Abstract</a></h1>
<div>An introduction to a broad range of topics in deep learning, covering mathematical and conceptual background, deep learning techniques used in industry, and research perspectives.“Written by three experts in the field, Deep Learning is the only comprehensive book on the subject.”—Elon Musk, cochair of {OpenAI}; cofounder and {CEO} of Tesla and {SpaceXDeep} learning is a form of machine learning that enables computers to learn from experience and understand the world in terms of a hierarchy of concepts. Because the computer gathers knowledge from experience, there is no need for a human computer operator to formally specify all the knowledge that the computer needs. The hierarchy of concepts allows the computer to learn complicated concepts by building them out of simpler ones; a graph of these hierarchies would be many layers deep. This book introduces a broad range of topics in deep learning. The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology; and it surveys such applications as natural language processing, speech recognition, computer vision, online recommendation systems, bioinformatics, and videogames. Finally, the book offers research perspectives, covering such theoretical topics as linear factor models, autoencoders, representation learning, structured probabilistic models, Monte Carlo methods, the partition function, approximate inference, and deep generative models. Deep Learning can be used by undergraduate or graduate students planning careers in either industry or research, and by software engineers who want to begin using deep learning in their products or platforms. A website offers supplementary material for both readers and instructors.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="gupta_effective_2020" class=ref>
<summary class=citation>
<a id="gupta_effective_2020">[gupta_effective_2020]</a> - Gupta, Aakriti and Thadani, Kapil and O&#x27;Hare, Neil - <a href="https://www.aclweb.org/anthology/2020.coling-main.92" target="_blank"><cite>Effective Few-Shot Classification with Transfer Learning</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite gupta_effective_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-53" id="summaryabstract-53">Summary/Abstract</a></h1>
<div>Few-shot learning addresses the the problem of learning based on a small amount of training data. Although more well-studied in the domain of computer vision, recent work has adapted the Amazon Review Sentiment Classification ({ARSC}) text dataset for use in the few-shot setting. In this work, we use the {ARSC} dataset to study a simple application of transfer learning approaches to few-shot classification. We train a single binary classifier to learn all few-shot classes jointly by prefixing class identifiers to the input text. Given the text and class, the model then makes a binary prediction for that text/class pair. Our results show that this simple approach can outperform most published results on this dataset. Surprisingly, we also show that including domain information as part of the task definition only leads to a modest improvement in model accuracy, and zero-shot classification, without further fine-tuning on few-shot domains, performs equivalently to few-shot classification. These results suggest that the classes in the {ARSC} few-shot task, which are defined by the intersection of domain and rating, are actually very similar to each other, and that a more suitable dataset is needed for the study of few-shot text classification.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="guu_realm_2020" class=ref>
<summary class=citation>
<a id="guu_realm_2020">[guu_realm_2020]</a> - Guu, Kelvin and Lee, Kenton and Tung, Zora and Pasupat, Panupong and Chang, Ming-Wei - <a href="https://arxiv.org/abs/2002.08909v1" target="_blank"><cite>{REALM}: Retrieval-Augmented Language Model Pre-Training</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite guu_realm_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-54" id="summaryabstract-54">Summary/Abstract</a></h1>
<div>Language model pre-training has been shown to capture a surprising amount of world knowledge, crucial for {NLP} tasks such as question answering. However, this knowledge is stored implicitly in the parameters of a neural network, requiring ever-larger networks to cover more facts. To capture knowledge in a more modular and interpretable way, we augment language model pre-training with a latent knowledge retriever, which allows the model to retrieve and attend over documents from a large corpus such as Wikipedia, used during pre-training, fine-tuning and inference. For the first time, we show how to pre-train such a knowledge retriever in an unsupervised manner, using masked language modeling as the learning signal and backpropagating through a retrieval step that considers millions of documents. We demonstrate the effectiveness of Retrieval-Augmented Language Model pre-training ({REALM}) by fine-tuning on the challenging task of Open-domain Question Answering (Open-{QA}). We compare against state-of-the-art models for both explicit and implicit knowledge storage on three popular Open-{QA} benchmarks, and find that we outperform all previous methods by a significant margin (4-16\% absolute accuracy), while also providing qualitative benefits such as interpretability and modularity.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="hinton_distilling_2015" class=ref>
<summary class=citation>
<a id="hinton_distilling_2015">[hinton_distilling_2015]</a> - Hinton, Geoffrey and Vinyals, Oriol and Dean, Jeff - <a href="http://arxiv.org/abs/1503.02531" target="_blank"><cite>Distilling the Knowledge in a Neural Network</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite hinton_distilling_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-55" id="summaryabstract-55">Summary/Abstract</a></h1>
<div>A very simple way to improve the performance of almost any machine learning algorithm is to train many different models on the same data and then to average their predictions. Unfortunately, making predictions using a whole ensemble of models is cumbersome and may be too computationally expensive to allow deployment to a large number of users, especially if the individual models are large neural nets. Caruana and his collaborators have shown that it is possible to compress the knowledge in an ensemble into a single model which is much easier to deploy and we develop this approach further using a different compression technique. We achieve some surprising results on {MNIST} and we show that we can significantly improve the acoustic model of a heavily used commercial system by distilling the knowledge in an ensemble of models into a single model. We also introduce a new type of ensemble composed of one or more full models and many specialist models which learn to distinguish fine-grained classes that the full models confuse. Unlike a mixture of experts, these specialist models can be trained rapidly and in parallel.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="huang_large_2024" class=ref>
<summary class=citation>
<a id="huang_large_2024">[huang_large_2024]</a> - Huang, Jie and Chen, Xinyun and Mishra, Swaroop and Zheng, Huaixiu Steven and Yu, Adams Wei and Song, Xinying and Zhou, Denny - <a href="http://arxiv.org/abs/2310.01798" target="_blank"><cite>Large Language Models Cannot Self-Correct Reasoning Yet</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite huang_large_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-56" id="summaryabstract-56">Summary/Abstract</a></h1>
<div>Large Language Models ({LLMs}) have emerged as a groundbreaking technology with their unparalleled text generation capabilities across various applications. Nevertheless, concerns persist regarding the accuracy and appropriateness of their generated content. A contemporary methodology, self-correction, has been proposed as a remedy to these issues. Building upon this premise, this paper critically examines the role and efficacy of self-correction within {LLMs}, shedding light on its true potential and limitations. Central to our investigation is the notion of intrinsic self-correction, whereby an {LLM} attempts to correct its initial responses based solely on its inherent capabilities, without the crutch of external feedback. In the context of reasoning, our research indicates that {LLMs} struggle to selfcorrect their responses without external feedback, and at times, their performance even degrades after self-correction. Drawing from these insights, we offer suggestions for future research and practical applications in this field.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="huszar_quadratic_2017" class=ref>
<summary class=citation>
<a id="huszar_quadratic_2017">[huszar_quadratic_2017]</a> - Huszár, Ferenc - <a href="http://arxiv.org/abs/1712.03847" target="_blank"><cite>On Quadratic Penalties in Elastic Weight Consolidation</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite huszar_quadratic_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-57" id="summaryabstract-57">Summary/Abstract</a></h1>
<div>Elastic weight consolidation ({EWC}, Kirkpatrick et al, 2017) is a novel algorithm designed to safeguard against catastrophic forgetting in neural networks. {EWC} can be seen as an approximation to Laplace propagation (Eskin et al, 2004), and this view is consistent with the motivation given by Kirkpatrick et al (2017). In this note, I present an extended derivation that covers the case when there are more than two tasks. I show that the quadratic penalties in {EWC} are inconsistent with this derivation and might lead to double-counting data from earlier tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="ioffe_batch_2015" class=ref>
<summary class=citation>
<a id="ioffe_batch_2015">[ioffe_batch_2015]</a> - Ioffe, Sergey and Szegedy, Christian - <a href="http://arxiv.org/abs/1502.03167" target="_blank"><cite>Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite ioffe_batch_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-58" id="summaryabstract-58">Summary/Abstract</a></h1>
<div>Training Deep Neural Networks is complicated by the fact that the distribution of each layer&#x27;s inputs changes during training, as the parameters of the previous layers change. This slows down the training by requiring lower learning rates and careful parameter initialization, and makes it notoriously hard to train models with saturating nonlinearities. We refer to this phenomenon as internal covariate shift, and address the problem by normalizing layer inputs. Our method draws its strength from making normalization a part of the model architecture and performing the normalization for each training mini-batch. Batch Normalization allows us to use much higher learning rates and be less careful about initialization. It also acts as a regularizer, in some cases eliminating the need for Dropout. Applied to a state-of-the-art image classification model, Batch Normalization achieves the same accuracy with 14 times fewer training steps, and beats the original model by a significant margin. Using an ensemble of batch-normalized networks, we improve upon the best published result on {ImageNet} classification: reaching 4.9\% top-5 validation error (and 4.8\% test error), exceeding the accuracy of human raters.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="jaderberg_quantum_2021" class=ref>
<summary class=citation>
<a id="jaderberg_quantum_2021">[jaderberg_quantum_2021]</a> - Jaderberg, Ben and Anderson, Lewis W. and Xie, Weidi and Albanie, Samuel and Kiffner, Martin and Jaksch, Dieter - <a href="http://arxiv.org/abs/2103.14653" target="_blank"><cite>Quantum Self-Supervised Learning</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite jaderberg_quantum_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-59" id="summaryabstract-59">Summary/Abstract</a></h1>
<div>The popularisation of neural networks has seen incredible advances in pattern recognition, driven by the supervised learning of human annotations. However, this approach is unsustainable in relation to the dramatically increasing size of real-world datasets. This has led to a resurgence in self-supervised learning, a paradigm whereby the model generates its own supervisory signal from the data. Here we propose a hybrid quantum-classical neural network architecture for contrastive self-supervised learning and test its effectiveness in proof-of-principle experiments. Interestingly, we observe a numerical advantage for the learning of visual representations using small-scale quantum neural networks over equivalently structured classical networks, even when the quantum circuits are sampled with only 100 shots. Furthermore, we apply our best quantum model to classify unseen images on the ibmq\_paris quantum computer and find that current noisy devices can already achieve equal accuracy to the equivalent classical model on downstream tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="jaegle_perceiver_2021" class=ref>
<summary class=citation>
<a id="jaegle_perceiver_2021">[jaegle_perceiver_2021]</a> - Jaegle, Andrew and Gimeno, Felix and Brock, Andrew and Zisserman, Andrew and Vinyals, Oriol and Carreira, Joao - <a href="http://arxiv.org/abs/2103.03206" target="_blank"><cite>Perceiver: General Perception with Iterative Attention</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite jaegle_perceiver_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-60" id="summaryabstract-60">Summary/Abstract</a></h1>
<div>Biological systems perceive the world by simultaneously processing high-dimensional inputs from modalities as diverse as vision, audition, touch, proprioception, etc. The perception models used in deep learning on the other hand are designed for individual modalities, often relying on domain-specific assumptions such as the local grid structures exploited by virtually all existing vision models. These priors introduce helpful inductive biases, but also lock models to individual modalities. In this paper we introduce the Perceiver - a model that builds upon Transformers and hence makes few architectural assumptions about the relationship between its inputs, but that also scales to hundreds of thousands of inputs, like {ConvNets}. The model leverages an asymmetric attention mechanism to iteratively distill inputs into a tight latent bottleneck, allowing it to scale to handle very large inputs. We show that this architecture is competitive with or outperforms strong, specialized models on classification tasks across various modalities: images, point clouds, audio, video, and video+audio. The Perceiver obtains performance comparable to {ResNet}-50 and {ViT} on {ImageNet} without 2D convolutions by directly attending to 50,000 pixels. It is also competitive in all modalities in {AudioSet}.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="kaplan_scaling_2020" class=ref>
<summary class=citation>
<a id="kaplan_scaling_2020">[kaplan_scaling_2020]</a> - Kaplan, Jared and {McCandlish}, Sam and Henighan, Tom and Brown, Tom B. and Chess, Benjamin and Child, Rewon and Gray, Scott and Radford, Alec and Wu, Jeffrey and Amodei, Dario - <a href="http://arxiv.org/abs/2001.08361" target="_blank"><cite>Scaling Laws for Neural Language Models</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite kaplan_scaling_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-61" id="summaryabstract-61">Summary/Abstract</a></h1>
<div>We study empirical scaling laws for language model performance on the cross-entropy loss. The loss scales as a power-law with model size, dataset size, and the amount of compute used for training, with some trends spanning more than seven orders of magnitude. Other architectural details such as network width or depth have minimal effects within a wide range. Simple equations govern the dependence of overfitting on model/dataset size and the dependence of training speed on model size. These relationships allow us to determine the optimal allocation of a fixed compute budget. Larger models are significantly more sample-efficient, such that optimally compute-efficient training involves training very large models on a relatively modest amount of data and stopping significantly before convergence.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="karpathy_large-scale_nodate" class=ref>
<summary class=citation>
<a id="karpathy_large-scale_nodate">[karpathy_large-scale_nodate]</a> - Karpathy, Andrej and Toderici, George and Shetty, Sanketh and Leung, Thomas and Sukthankar, Rahul and Fei-Fei, Li - <cite>Large-scale Video Classiﬁcation with Convolutional Neural Networks</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite karpathy_large-scale_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-62" id="summaryabstract-62">Summary/Abstract</a></h1>
<div>Convolutional Neural Networks ({CNNs}) have been established as a powerful class of models for image recognition problems. Encouraged by these results, we provide an extensive empirical evaluation of {CNNs} on largescale video classiﬁcation using a new dataset of 1 million {YouTube} videos belonging to 487 classes. We study multiple approaches for extending the connectivity of a {CNN} in time domain to take advantage of local spatio-temporal information and suggest a multiresolution, foveated architecture as a promising way of speeding up the training. Our best spatio-temporal networks display signiﬁcant performance improvements compared to strong feature-based baselines (55.3\% to 63.9\%), but only a surprisingly modest improvement compared to single-frame models (59.3\% to 60.9\%). We further study the generalization performance of our best model by retraining the top layers on the {UCF}101 Action Recognition dataset and observe signiﬁcant performance improvements compared to the {UCF}-101 baseline model (63.3\% up from 43.9\%).</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="karpathy_visualizing_2015" class=ref>
<summary class=citation>
<a id="karpathy_visualizing_2015">[karpathy_visualizing_2015]</a> - Karpathy, Andrej and Johnson, Justin and Fei-Fei, Li - <a href="http://arxiv.org/abs/1506.02078" target="_blank"><cite>Visualizing and Understanding Recurrent Networks</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite karpathy_visualizing_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-63" id="summaryabstract-63">Summary/Abstract</a></h1>
<div>Recurrent Neural Networks ({RNNs}), and specifically a variant with Long Short-Term Memory ({LSTM}), are enjoying renewed interest as a result of successful applications in a wide range of machine learning problems that involve sequential data. However, while {LSTMs} provide exceptional results in practice, the source of their performance and their limitations remain rather poorly understood. Using character-level language models as an interpretable testbed, we aim to bridge this gap by providing an analysis of their representations, predictions and error types. In particular, our experiments reveal the existence of interpretable cells that keep track of long-range dependencies such as line lengths, quotes and brackets. Moreover, our comparative analysis with finite horizon n-gram models traces the source of the {LSTM} improvements to long-range structural dependencies. Finally, we provide analysis of the remaining errors and suggests areas for further study.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="keitakurita_building_2019" class=ref>
<summary class=citation>
<a id="keitakurita_building_2019">[keitakurita_building_2019]</a> - keitakurita, Author - <a href="https://mlexplained.com/2019/07/04/building-the-transformer-xl-from-scratch/" target="_blank"><cite>Building the Transformer {XL} from Scratch</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite keitakurita_building_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-64" id="summaryabstract-64">Summary/Abstract</a></h1>
<div>With the release of {XLNet}, the Transformer {XL} is the new cool kid on the block. Although the Transformer {XL} is simple in concept, actually understanding the details is harder than might meet the ey…</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="keitakurita_intuitive_2018" class=ref>
<summary class=citation>
<a id="keitakurita_intuitive_2018">[keitakurita_intuitive_2018]</a> - keitakurita, Author - <a href="http://mlexplained.com/2018/01/10/an-intuitive-explanation-of-why-batch-normalization-really-works-normalization-in-deep-learning-part-1/" target="_blank"><cite>An Intuitive Explanation of Why Batch Normalization Really Works (Normalization in Deep Learning Part 1)</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite keitakurita_intuitive_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-65" id="summaryabstract-65">Summary/Abstract</a></h1>
<div>Batch normalization is one of the reasons why deep learning has made such outstanding progress in recent years. Batch normalization enables the use of higher learning rates, greatly accelerating th…</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="kemker_fearnet_2018" class=ref>
<summary class=citation>
<a id="kemker_fearnet_2018">[kemker_fearnet_2018]</a> - Kemker, Ronald and Kanan, Christopher - <a href="https://openreview.net/forum?id&#x3D;SJ1Xmf-Rb" target="_blank"><cite>{FearNet}: Brain-Inspired Model for Incremental Learning</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite kemker_fearnet_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-66" id="summaryabstract-66">Summary/Abstract</a></h1>
<div>{FearNet} is a memory efficient neural-network, inspired by memory formation in the mammalian brain, that is capable of incremental class learning without catastrophic forgetting.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="keskar_ctrl_nodate" class=ref>
<summary class=citation>
<a id="keskar_ctrl_nodate">[keskar_ctrl_nodate]</a> - Keskar, Nitish Shirish and {McCann}, Bryan and Varshney, Lav R and Xiong, Caiming and Socher, Richard - <cite>{CTRL}: A {CONDITIONAL} {TRANSFORMER} {LANGUAGE} {MODEL} {FOR} {CONTROLLABLE} {GENERATION}</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite keskar_ctrl_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-67" id="summaryabstract-67">Summary/Abstract</a></h1>
<div>Large-scale language models show promising text generation capabilities, but users cannot easily control particular aspects of the generated text. We release {CTRL}, a 1.63 billion-parameter conditional transformer language model, trained to condition on control codes that govern style, content, and task-speciﬁc behavior. Control codes were derived from structure that naturally co-occurs with raw text, preserving the advantages of unsupervised learning while providing more explicit control over text generation. These codes also allow {CTRL} to predict which parts of the training data are most likely given a sequence. This provides a potential method for analyzing large amounts of data via model-based source attribution. We have released multiple full-sized, pretrained versions of {CTRL} at https://github.com/salesforce/ctrl.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="khattab_colbert_2020" class=ref>
<summary class=citation>
<a id="khattab_colbert_2020">[khattab_colbert_2020]</a> - Khattab, Omar and Zaharia, Matei - <a href="http://arxiv.org/abs/2004.12832" target="_blank"><cite>{ColBERT}: Efficient and Effective Passage Search via Contextualized Late Interaction over {BERT}</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite khattab_colbert_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-68" id="summaryabstract-68">Summary/Abstract</a></h1>
<div>Recent progress in Natural Language Understanding ({NLU}) is driving fast-paced advances in Information Retrieval ({IR}), largely owed to fine-tuning deep language models ({LMs}) for document ranking. While remarkably effective, the ranking models based on these {LMs} increase computational cost by orders of magnitude over prior approaches, particularly as they must feed each query-document pair through a massive neural network to compute a single relevance score. To tackle this, we present {ColBERT}, a novel ranking model that adapts deep {LMs} (in particular, {BERT}) for efficient retrieval. {ColBERT} introduces a late interaction architecture that independently encodes the query and the document using {BERT} and then employs a cheap yet powerful interaction step that models their fine-grained similarity. By delaying and yet retaining this fine-granular interaction, {ColBERT} can leverage the expressiveness of deep {LMs} while simultaneously gaining the ability to pre-compute document representations offline, considerably speeding up query processing. Beyond reducing the cost of re-ranking the documents retrieved by a traditional model, {ColBERT}&#x27;s pruning-friendly interaction mechanism enables leveraging vector-similarity indexes for end-to-end retrieval directly from a large document collection. We extensively evaluate {ColBERT} using two recent passage search datasets. Results show that {ColBERT}&#x27;s effectiveness is competitive with existing {BERT}-based models (and outperforms every non-{BERT} baseline), while executing two orders-of-magnitude faster and requiring four orders-of-magnitude fewer {FLOPs} per query.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="kirkpatrick_overcoming_2017" class=ref>
<summary class=citation>
<a id="kirkpatrick_overcoming_2017">[kirkpatrick_overcoming_2017]</a> - Kirkpatrick, James and Pascanu, Razvan and Rabinowitz, Neil and Veness, Joel and Desjardins, Guillaume and Rusu, Andrei A. and Milan, Kieran and Quan, John and Ramalho, Tiago and Grabska-Barwinska, Agnieszka and Hassabis, Demis and Clopath, Claudia and Kumaran, Dharshan and Hadsell, Raia - <a href="http://arxiv.org/abs/1612.00796" target="_blank"><cite>Overcoming catastrophic forgetting in neural networks</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite kirkpatrick_overcoming_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-69" id="summaryabstract-69">Summary/Abstract</a></h1>
<div>The ability to learn tasks in a sequential fashion is crucial to the development of artificial intelligence. Neural networks are not, in general, capable of this and it has been widely thought that catastrophic forgetting is an inevitable feature of connectionist models. We show that it is possible to overcome this limitation and train networks that can maintain expertise on tasks which they have not experienced for a long time. Our approach remembers old tasks by selectively slowing down learning on the weights important for those tasks. We demonstrate our approach is scalable and effective by solving a set of classification tasks based on the {MNIST} hand written digit dataset and by learning several Atari 2600 games sequentially.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="kirkpatrick_optimization_1983" class=ref>
<summary class=citation>
<a id="kirkpatrick_optimization_1983">[kirkpatrick_optimization_1983]</a> - Kirkpatrick, S. and Gelatt, C. D. and Vecchi, M. P. - <a href="https://science.sciencemag.org/content/220/4598/671" target="_blank"><cite>Optimization by Simulated Annealing</cite></a>. - 1983. -
<button onclick="copyToClipboard('\{\{ #cite kirkpatrick_optimization_1983 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-70" id="summaryabstract-70">Summary/Abstract</a></h1>
<div>There is a deep and useful connection between statistical mechanics (the behavior of systems with many degrees of freedom in thermal equilibrium at a finite temperature) and multivariate or combinatorial optimization (finding the minimum of a given function depending on many parameters). A detailed analogy with annealing in solids provides a framework for optimization of the properties of very large and complex systems. This connection to statistical mechanics exposes new information and provides an unfamiliar perspective on traditional optimization problems and methods.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="kitaev_reformer_2020" class=ref>
<summary class=citation>
<a id="kitaev_reformer_2020">[kitaev_reformer_2020]</a> - Kitaev, Nikita and Kaiser, Łukasz and Levskaya, Anselm - <a href="http://arxiv.org/abs/2001.04451" target="_blank"><cite>Reformer: The Efficient Transformer</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite kitaev_reformer_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-71" id="summaryabstract-71">Summary/Abstract</a></h1>
<div>Large Transformer models routinely achieve state-of-the-art results on a number of tasks but training these models can be prohibitively costly, especially on long sequences. We introduce two techniques to improve the efficiency of Transformers. For one, we replace dot-product attention by one that uses locality-sensitive hashing, changing its complexity from O(\$L{\textasciicircum}2\$) to O(\$L{\textbackslash}log L\$), where \$L\$ is the length of the sequence. Furthermore, we use reversible residual layers instead of the standard residuals, which allows storing activations only once in the training process instead of \$N\$ times, where \$N\$ is the number of layers. The resulting model, the Reformer, performs on par with Transformer models while being much more memory-efficient and much faster on long sequences.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="klein_opennmt_2017" class=ref>
<summary class=citation>
<a id="klein_opennmt_2017">[klein_opennmt_2017]</a> - Klein, Guillaume and Kim, Yoon and Deng, Yuntian and Senellart, Jean and Rush, Alexander - <a href="http://aclweb.org/anthology/P17-4012" target="_blank"><cite>{OpenNMT}: Open-Source Toolkit for Neural Machine Translation</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite klein_opennmt_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-72" id="summaryabstract-72">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="kraska_case_2018" class=ref>
<summary class=citation>
<a id="kraska_case_2018">[kraska_case_2018]</a> - Kraska, Tim and Beutel, Alex and Chi, Ed H. and Dean, Jeffrey and Polyzotis, Neoklis - <a href="http://arxiv.org/abs/1712.01208" target="_blank"><cite>The Case for Learned Index Structures</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite kraska_case_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-73" id="summaryabstract-73">Summary/Abstract</a></h1>
<div>Indexes are models: a B-Tree-Index can be seen as a model to map a key to the position of a record within a sorted array, a Hash-Index as a model to map a key to a position of a record within an unsorted array, and a {BitMap}-Index as a model to indicate if a data record exists or not. In this exploratory research paper, we start from this premise and posit that all existing index structures can be replaced with other types of models, including deep-learning models, which we term learned indexes. The key idea is that a model can learn the sort order or structure of lookup keys and use this signal to effectively predict the position or existence of records. We theoretically analyze under which conditions learned indexes outperform traditional index structures and describe the main challenges in designing learned index structures. Our initial results show, that by using neural nets we are able to outperform cache-optimized B-Trees by up to 70\% in speed while saving an order-of-magnitude in memory over several real-world data sets. More importantly though, we believe that the idea of replacing core components of a data management system through learned models has far reaching implications for future systems designs and that this work just provides a glimpse of what might be possible.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="kusupati_matryoshka_2024" class=ref>
<summary class=citation>
<a id="kusupati_matryoshka_2024">[kusupati_matryoshka_2024]</a> - Kusupati, Aditya and Bhatt, Gantavya and Rege, Aniket and Wallingford, Matthew and Sinha, Aditya and Ramanujan, Vivek and Howard-Snyder, William and Chen, Kaifeng and Kakade, Sham and Jain, Prateek and Farhadi, Ali - <a href="http://arxiv.org/abs/2205.13147" target="_blank"><cite>Matryoshka Representation Learning</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite kusupati_matryoshka_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-74" id="summaryabstract-74">Summary/Abstract</a></h1>
<div>Learned representations are a central component in modern {ML} systems, serving a multitude of downstream tasks. When training such representations, it is often the case that computational and statistical constraints for each downstream task are unknown. In this context, rigid fixed-capacity representations can be either over or under-accommodating to the task at hand. This leads us to ask: can we design a flexible representation that can adapt to multiple downstream tasks with varying computational resources? Our main contribution is Matryoshka Representation Learning ({MRL}) which encodes information at different granularities and allows a single embedding to adapt to the computational constraints of downstream tasks. {MRL} minimally modifies existing representation learning pipelines and imposes no additional cost during inference and deployment. {MRL} learns coarse-to-fine representations that are at least as accurate and rich as independently trained low-dimensional representations. The flexibility within the learned Matryoshka Representations offer: (a) up to 14× smaller embedding size for {ImageNet}-1K classification at the same level of accuracy; (b) up to 14× real-world speed-ups for large-scale retrieval on {ImageNet}-1K and 4K; and (c) up to 2\% accuracy improvements for long-tail few-shot classification, all while being as robust as the original representations. Finally, we show that {MRL} extends seamlessly to web-scale datasets ({ImageNet}, {JFT}) across various modalities – vision ({ViT}, {ResNet}), vision + language ({ALIGN}) and language ({BERT}). {MRL} code and pretrained models are open-sourced at https://github.com/{RAIVNLab}/{MRL}.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lake_building_2016" class=ref>
<summary class=citation>
<a id="lake_building_2016">[lake_building_2016]</a> - Lake, Brenden M. and Ullman, Tomer D. and Tenenbaum, Joshua B. and Gershman, Samuel J. - <a href="http://arxiv.org/abs/1604.00289" target="_blank"><cite>Building Machines That Learn and Think Like People</cite></a>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite lake_building_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-75" id="summaryabstract-75">Summary/Abstract</a></h1>
<div>Recent progress in artificial intelligence ({AI}) has renewed interest in building systems that learn and think like people. Many advances have come from using deep neural networks trained end-to-end in tasks such as object recognition, video games, and board games, achieving performance that equals or even beats humans in some respects. Despite their biological inspiration and performance achievements, these systems differ from human intelligence in crucial ways. We review progress in cognitive science suggesting that truly human-like learning and thinking machines will have to reach beyond current engineering trends in both what they learn, and how they learn it. Specifically, we argue that these machines should (a) build causal models of the world that support explanation and understanding, rather than merely solving pattern recognition problems; (b) ground learning in intuitive theories of physics and psychology, to support and enrich the knowledge that is learned; and (c) harness compositionality and learning-to-learn to rapidly acquire and generalize knowledge to new tasks and situations. We suggest concrete challenges and promising routes towards these goals that can combine the strengths of recent neural network advances with more structured cognitive models.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lample_cross-lingual_2019" class=ref>
<summary class=citation>
<a id="lample_cross-lingual_2019">[lample_cross-lingual_2019]</a> - Lample, Guillaume and Conneau, Alexis - <a href="http://arxiv.org/abs/1901.07291" target="_blank"><cite>Cross-lingual Language Model Pretraining</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite lample_cross-lingual_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-76" id="summaryabstract-76">Summary/Abstract</a></h1>
<div>Recent studies have demonstrated the efficiency of generative pretraining for English natural language understanding. In this work, we extend this approach to multiple languages and show the effectiveness of cross-lingual pretraining. We propose two methods to learn cross-lingual language models ({XLMs}): one unsupervised that only relies on monolingual data, and one supervised that leverages parallel data with a new cross-lingual language model objective. We obtain state-of-the-art results on cross-lingual classification, unsupervised and supervised machine translation. On {XNLI}, our approach pushes the state of the art by an absolute gain of 4.9\% accuracy. On unsupervised machine translation, we obtain 34.3 {BLEU} on {WMT}&#x27;16 German-English, improving the previous state of the art by more than 9 {BLEU}. On supervised machine translation, we obtain a new state of the art of 38.5 {BLEU} on {WMT}&#x27;16 Romanian-English, outperforming the previous best approach by more than 4 {BLEU}. Our code and pretrained models will be made publicly available.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lecun_path_nodate" class=ref>
<summary class=citation>
<a id="lecun_path_nodate">[lecun_path_nodate]</a> - {LeCun}, Yann - <cite>A Path Towards Autonomous Machine Intelligence Version 0.9.2, 2022-06-27</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite lecun_path_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-77" id="summaryabstract-77">Summary/Abstract</a></h1>
<div>How could machines learn as eﬃciently as humans and animals? How could machines learn to reason and plan? How could machines learn representations of percepts and action plans at multiple levels of abstraction, enabling them to reason, predict, and plan at multiple time horizons? This position paper proposes an architecture and training paradigms with which to construct autonomous intelligent agents. It combines concepts such as conﬁgurable predictive world model, behavior driven through intrinsic motivation, and hierarchical joint embedding architectures trained with self-supervised learning.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lee-thorp_fnet_2021" class=ref>
<summary class=citation>
<a id="lee-thorp_fnet_2021">[lee-thorp_fnet_2021]</a> - Lee-Thorp, James and Ainslie, Joshua and Eckstein, Ilya and Ontanon, Santiago - <a href="http://arxiv.org/abs/2105.03824" target="_blank"><cite>{FNet}: Mixing Tokens with Fourier Transforms</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite lee-thorp_fnet_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-78" id="summaryabstract-78">Summary/Abstract</a></h1>
<div>We show that Transformer encoder architectures can be massively sped up, with limited accuracy costs, by replacing the self-attention sublayers with simple linear transformations that mix input tokens. These linear transformations, along with simple nonlinearities in feed-forward layers, are sufficient to model semantic relationships in several text classification tasks. Perhaps most surprisingly, we find that replacing the self-attention sublayer in a Transformer encoder with a standard, unparameterized Fourier Transform achieves 92\% of the accuracy of {BERT} on the {GLUE} benchmark, but pre-trains and runs up to seven times faster on {GPUs} and twice as fast on {TPUs}. The resulting model, which we name {FNet}, scales very efficiently to long inputs, matching the accuracy of the most accurate efficient Transformers on the Long Range Arena benchmark, but training and running faster across all sequence lengths on {GPUs} and relatively shorter sequence lengths on {TPUs}. Finally, {FNet} has a light memory footprint and is particularly efficient at smaller model sizes: for a fixed speed and accuracy budget, small {FNet} models outperform Transformer counterparts.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lehnert_beyond_2024" class=ref>
<summary class=citation>
<a id="lehnert_beyond_2024">[lehnert_beyond_2024]</a> - Lehnert, Lucas and Sukhbaatar, Sainbayar and Mcvay, Paul and Rabbat, Michael and Tian, Yuandong - <a href="http://arxiv.org/abs/2402.14083" target="_blank"><cite>Beyond A*: Better Planning with Transformers via Search Dynamics Bootstrapping</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite lehnert_beyond_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-79" id="summaryabstract-79">Summary/Abstract</a></h1>
<div>While Transformers have enabled tremendous progress in various application settings, such architectures still lag behind traditional symbolic planners for solving complex decision making tasks. In this work, we demonstrate how to train Transformers to solve complex planning tasks and present Searchformer, a Transformer model that optimally solves previously unseen Sokoban puzzles 93.7\% of the time, while using up to 26.8\% fewer search steps than standard \$A{\textasciicircum}*\$ search. Searchformer is an encoder-decoder Transformer model trained to predict the search dynamics of \$A{\textasciicircum}*\$. This model is then fine-tuned via expert iterations to perform fewer search steps than \$A{\textasciicircum}*\$ search while still generating an optimal plan. In our training method, \$A{\textasciicircum}*\$&#x27;s search dynamics are expressed as a token sequence outlining when task states are added and removed into the search tree during symbolic planning. In our ablation studies on maze navigation, we find that Searchformer significantly outperforms baselines that predict the optimal plan directly with a 5-10\${\textbackslash}times\$ smaller model size and a 10\${\textbackslash}times\$ smaller training dataset. We also demonstrate how Searchformer scales to larger and more complex decision making tasks like Sokoban with improved percentage of solved tasks and shortened search dynamics.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lewis_retrieval-augmented_2020" class=ref>
<summary class=citation>
<a id="lewis_retrieval-augmented_2020">[lewis_retrieval-augmented_2020]</a> - Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Küttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rocktäschel, Tim and Riedel, Sebastian and Kiela, Douwe - <a href="https://arxiv.org/abs/2005.11401v4" target="_blank"><cite>Retrieval-Augmented Generation for Knowledge-Intensive {NLP} Tasks</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite lewis_retrieval-augmented_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-80" id="summaryabstract-80">Summary/Abstract</a></h1>
<div>Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream {NLP} tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation ({RAG}) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce {RAG} models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two {RAG} formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive {NLP} tasks and set the state-of-the-art on three open domain {QA} tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that {RAG} models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="li_learning_2017" class=ref>
<summary class=citation>
<a id="li_learning_2017">[li_learning_2017]</a> - Li, Zhizhong and Hoiem, Derek - <a href="http://arxiv.org/abs/1606.09282" target="_blank"><cite>Learning without Forgetting</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite li_learning_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-81" id="summaryabstract-81">Summary/Abstract</a></h1>
<div>When building a unified vision system or gradually adding new capabilities to a system, the usual assumption is that training data for all tasks is always available. However, as the number of tasks grows, storing and retraining on such data becomes infeasible. A new problem arises where we add new capabilities to a Convolutional Neural Network ({CNN}), but the training data for its existing capabilities are unavailable. We propose our Learning without Forgetting method, which uses only new task data to train the network while preserving the original capabilities. Our method performs favorably compared to commonly used feature extraction and fine-tuning adaption techniques and performs similarly to multitask learning that uses original task data we assume unavailable. A more surprising observation is that Learning without Forgetting may be able to replace fine-tuning with similar old and new task datasets for improved new task performance.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="li_deep_2020" class=ref>
<summary class=citation>
<a id="li_deep_2020">[li_deep_2020]</a> - Li, Yuliang and Li, Jinfeng and Suhara, Yoshihiko and Doan, {AnHai} and Tan, Wang-Chiew - <a href="http://arxiv.org/abs/2004.00584" target="_blank"><cite>Deep Entity Matching with Pre-Trained Language Models</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite li_deep_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-82" id="summaryabstract-82">Summary/Abstract</a></h1>
<div>We present Ditto, a novel entity matching system based on pre-trained Transformer-based language models. We fine-tune and cast {EM} as a sequence-pair classification problem to leverage such models with a simple architecture. Our experiments show that a straightforward application of language models such as {BERT}, {DistilBERT}, or {RoBERTa} pre-trained on large text corpora already significantly improves the matching quality and outperforms previous state-of-the-art ({SOTA}), by up to 29\% of F1 score on benchmark datasets. We also developed three optimization techniques to further improve Ditto&#x27;s matching capability. Ditto allows domain knowledge to be injected by highlighting important pieces of input information that may be of interest when making matching decisions. Ditto also summarizes strings that are too long so that only the essential information is retained and used for {EM}. Finally, Ditto adapts a {SOTA} technique on data augmentation for text to {EM} to augment the training data with (difficult) examples. This way, Ditto is forced to learn harder to improve the model&#x27;s matching capability. The optimizations we developed further boost the performance of Ditto by up to 9.8\%. Perhaps more surprisingly, we establish that Ditto can achieve the previous {SOTA} results with at most half the number of labeled data. Finally, we demonstrate Ditto&#x27;s effectiveness on a real-world large-scale {EM} task. On matching two company datasets consisting of 789K and 412K records, Ditto achieves a high F1 score of 96.5\%.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="li_deep_2020-1" class=ref>
<summary class=citation>
<a id="li_deep_2020-1">[li_deep_2020-1]</a> - Li, Yuliang and Li, Jinfeng and Suhara, Yoshihiko and Doan, {AnHai} and Tan, Wang-Chiew - <a href="http://arxiv.org/abs/2004.00584" target="_blank"><cite>Deep Entity Matching with Pre-Trained Language Models</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite li_deep_2020-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-83" id="summaryabstract-83">Summary/Abstract</a></h1>
<div>We present Ditto, a novel entity matching system based on pre-trained Transformer-based language models. We fine-tune and cast {EM} as a sequence-pair classification problem to leverage such models with a simple architecture. Our experiments show that a straightforward application of language models such as {BERT}, {DistilBERT}, or {RoBERTa} pre-trained on large text corpora already significantly improves the matching quality and outperforms previous state-of-the-art ({SOTA}), by up to 29\% of F1 score on benchmark datasets. We also developed three optimization techniques to further improve Ditto&#x27;s matching capability. Ditto allows domain knowledge to be injected by highlighting important pieces of input information that may be of interest when making matching decisions. Ditto also summarizes strings that are too long so that only the essential information is retained and used for {EM}. Finally, Ditto adapts a {SOTA} technique on data augmentation for text to {EM} to augment the training data with (difficult) examples. This way, Ditto is forced to learn harder to improve the model&#x27;s matching capability. The optimizations we developed further boost the performance of Ditto by up to 9.8\%. Perhaps more surprisingly, we establish that Ditto can achieve the previous {SOTA} results with at most half the number of labeled data. Finally, we demonstrate Ditto&#x27;s effectiveness on a real-world large-scale {EM} task. On matching two company datasets consisting of 789K and 412K records, Ditto achieves a high F1 score of 96.5\%.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="li_survey_2022" class=ref>
<summary class=citation>
<a id="li_survey_2022">[li_survey_2022]</a> - Li, Qian and Peng, Hao and Li, Jianxin and Xia, Congying and Yang, Renyu and Sun, Lichao and Yu, Philip S. and He, Lifang - <a href="https://doi.org/10.1145/3495162" target="_blank"><cite>A Survey on Text Classification: From Traditional to Deep Learning</cite></a>. - 2022. -
<button onclick="copyToClipboard('\{\{ #cite li_survey_2022 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-84" id="summaryabstract-84">Summary/Abstract</a></h1>
<div>Text classification is the most fundamental and essential task in natural language processing. The last decade has seen a surge of research in this area due to the unprecedented success of deep learning. Numerous methods, datasets, and evaluation metrics have been proposed in the literature, raising the need for a comprehensive and updated survey. This paper fills the gap by reviewing the state-of-the-art approaches from 1961 to 2021, focusing on models from traditional models to deep learning. We create a taxonomy for text classification according to the text involved and the models used for feature extraction and classification. We then discuss each of these categories in detail, dealing with both the technical developments and benchmark datasets that support tests of predictions. A comprehensive comparison between different techniques, as well as identifying the pros and cons of various evaluation metrics are also provided in this survey. Finally, we conclude by summarizing key implications, future research directions, and the challenges facing the research area.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="li_chain_2024" class=ref>
<summary class=citation>
<a id="li_chain_2024">[li_chain_2024]</a> - Li, Zhiyuan and Liu, Hong and Zhou, Denny and Ma, Tengyu - <a href="http://arxiv.org/abs/2402.12875" target="_blank"><cite>Chain of Thought Empowers Transformers to Solve Inherently Serial Problems</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite li_chain_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-85" id="summaryabstract-85">Summary/Abstract</a></h1>
<div>Instructing the model to generate a sequence of intermediate steps, a.k.a., a chain of thought ({CoT}), is a highly effective method to improve the accuracy of large language models ({LLMs}) on arithmetics and symbolic reasoning tasks. However, the mechanism behind {CoT} remains unclear. This work provides a theoretical understanding of the power of {CoT} for decoder-only transformers through the lens of expressiveness. Conceptually, {CoT} empowers the model with the ability to perform inherently serial computation, which is otherwise lacking in transformers, especially when depth is low. Given input length n, previous works have shown that constantdepth transformers with finite precision poly(n) embedding size can only solve problems in {TC}0 without {CoT}. We first show an even tighter expressiveness upper bound for constant-depth transformers with constant-bit precision, which can only solve problems in {AC}0, a proper subset of {TC}0. However, with T steps of {CoT}, constant-depth transformers using constant-bit precision and O(log n) embedding size can solve any problem solvable by boolean circuits of size T . Empirically, enabling {CoT} dramatically improves the accuracy for tasks that are hard for parallel computation, including the composition of permutation groups, iterated squaring, and circuit value problems, especially for low-depth transformers.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="liu_roberta:_2019" class=ref>
<summary class=citation>
<a id="liu_roberta:_2019">[liu_roberta:_2019]</a> - Liu, Yinhan and Ott, Myle and Goyal, Naman and Du, Jingfei and Joshi, Mandar and Chen, Danqi and Levy, Omer and Lewis, Mike and Zettlemoyer, Luke and Stoyanov, Veselin - <a href="http://arxiv.org/abs/1907.11692" target="_blank"><cite>{RoBERTa}: A Robustly Optimized {BERT} Pretraining Approach</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite liu_roberta:_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-86" id="summaryabstract-86">Summary/Abstract</a></h1>
<div>Language model pretraining has led to significant performance gains but careful comparison between different approaches is challenging. Training is computationally expensive, often done on private datasets of different sizes, and, as we will show, hyperparameter choices have significant impact on the final results. We present a replication study of {BERT} pretraining (Devlin et al., 2019) that carefully measures the impact of many key hyperparameters and training data size. We find that {BERT} was significantly undertrained, and can match or exceed the performance of every model published after it. Our best model achieves state-of-the-art results on {GLUE}, {RACE} and {SQuAD}. These results highlight the importance of previously overlooked design choices, and raise questions about the source of recently reported improvements. We release our models and code.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="liu_multi-task_2019" class=ref>
<summary class=citation>
<a id="liu_multi-task_2019">[liu_multi-task_2019]</a> - Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng - <a href="https://www.aclweb.org/anthology/P19-1441" target="_blank"><cite>Multi-Task Deep Neural Networks for Natural Language Understanding</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite liu_multi-task_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-87" id="summaryabstract-87">Summary/Abstract</a></h1>
<div>In this paper, we present a Multi-Task Deep Neural Network ({MT}-{DNN}) for learning representations across multiple natural language understanding ({NLU}) tasks. {MT}-{DNN} not only leverages large amounts of cross-task data, but also benefits from a regularization effect that leads to more general representations to help adapt to new tasks and domains. {MT}-{DNN} extends the model proposed in Liu et al. (2015) by incorporating a pre-trained bidirectional transformer language model, known as {BERT} (Devlin et al., 2018). {MT}-{DNN} obtains new state-of-the-art results on ten {NLU} tasks, including {SNLI}, {SciTail}, and eight out of nine {GLUE} tasks, pushing the {GLUE} benchmark to 82.7\% (2.2\% absolute improvement) as of February 25, 2019 on the latest {GLUE} test set. We also demonstrate using the {SNLI} and {SciTail} datasets that the representations learned by {MT}-{DNN} allow domain adaptation with substantially fewer in-domain labels than the pre-trained {BERT} representations. Our code and pre-trained models will be made publicly available.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="liu_seeing_nodate" class=ref>
<summary class=citation>
<a id="liu_seeing_nodate">[liu_seeing_nodate]</a> - Liu, Ziming and Gan, Eric and Tegmark, Max - <cite>{SEEING} {IS} {BELIEVING}: {BRAIN}-{INSPIRED} {MODULAR} {TRAINING} {FOR} {MECHANISTIC} {INTERPRETABILITY}</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite liu_seeing_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-88" id="summaryabstract-88">Summary/Abstract</a></h1>
<div>We introduce Brain-Inspired Modular Training ({BIMT}), a method for making neural networks more modular and interpretable. Inspired by brains, {BIMT} embeds neurons in a geometric space and augments the loss function with a cost proportional to the length of each neuron connection. We demonstrate that {BIMT} discovers useful modular neural networks for many simple tasks, revealing compositional structures in symbolic formulas, interpretable decision boundaries and features for classification, and mathematical structure in algorithmic datasets. The ability to directly see modules with the naked eye can complement current mechanistic interpretability strategies such as probes, interventions or staring at all weights.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="liu_ring_2023" class=ref>
<summary class=citation>
<a id="liu_ring_2023">[liu_ring_2023]</a> - Liu, Hao and Zaharia, Matei and Abbeel, Pieter - <a href="http://arxiv.org/abs/2310.01889" target="_blank"><cite>Ring Attention with Blockwise Transformers for Near-Infinite Context</cite></a>. - 2023. -
<button onclick="copyToClipboard('\{\{ #cite liu_ring_2023 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-89" id="summaryabstract-89">Summary/Abstract</a></h1>
<div>Transformers have emerged as the architecture of choice for many state-of-the-art {AI} models, showcasing exceptional performance across a wide range of {AI} applications. However, the memory demands imposed by Transformers limit their ability to handle long sequences, thereby posing challenges in utilizing videos, actions, and other long-form sequences and modalities in complex environments. We present a novel approach, Ring Attention with Blockwise Transformers (Ring Attention), which leverages blockwise computation of self-attention and feedforward to distribute long sequences across multiple devices while fully overlapping the communication of key-value blocks with the computation of blockwise attention. Our approach enables training and inference of sequences that are up to device count times longer than those achievable by prior memory-efficient Transformers, without resorting to approximations or incurring additional communication and computation overheads. Extensive experiments on language modeling and reinforcement learning tasks demonstrate the effectiveness of our approach in allowing millions of tokens context size and improving performance.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lloyd_quantum_2020" class=ref>
<summary class=citation>
<a id="lloyd_quantum_2020">[lloyd_quantum_2020]</a> - Lloyd, Seth and Schuld, Maria and Ijaz, Aroosa and Izaac, Josh and Killoran, Nathan - <a href="http://arxiv.org/abs/2001.03622" target="_blank"><cite>Quantum embeddings for machine learning</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite lloyd_quantum_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-90" id="summaryabstract-90">Summary/Abstract</a></h1>
<div>Quantum classifiers are trainable quantum circuits used as machine learning models. The first part of the circuit implements a quantum feature map that encodes classical inputs into quantum states, embedding the data in a high-dimensional Hilbert space; the second part of the circuit executes a quantum measurement interpreted as the output of the model. Usually, the measurement is trained to distinguish quantum-embedded data. We propose to instead train the first part of the circuit---the embedding---with the objective of maximally separating data classes in Hilbert space, a strategy we call quantum metric learning. As a result, the measurement minimizing a linear classification loss is already known and depends on the metric used: for embeddings separating data using the l1 or trace distance, this is the Helstrom measurement, while for the l2 or Hilbert-Schmidt distance, it is a simple overlap measurement. This approach provides a powerful analytic framework for quantum machine learning and eliminates a major component in current models, freeing up more precious resources to best leverage the capabilities of near-term quantum information processors.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lopez-paz_gradient_2017" class=ref>
<summary class=citation>
<a id="lopez-paz_gradient_2017">[lopez-paz_gradient_2017]</a> - Lopez-Paz, David and Ranzato, Marc&#x27;Aurelio - <a href="http://arxiv.org/abs/1706.08840" target="_blank"><cite>Gradient Episodic Memory for Continual Learning</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite lopez-paz_gradient_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-91" id="summaryabstract-91">Summary/Abstract</a></h1>
<div>One major obstacle towards {AI} is the poor ability of models to solve new problems quicker, and without forgetting previously acquired knowledge. To better understand this issue, we study the problem of continual learning, where the model observes, once and one by one, examples concerning a sequence of tasks. First, we propose a set of metrics to evaluate models learning over a continuum of data. These metrics characterize models not only by their test accuracy, but also in terms of their ability to transfer knowledge across tasks. Second, we propose a model for continual learning, called Gradient Episodic Memory ({GEM}) that alleviates forgetting, while allowing beneficial transfer of knowledge to previous tasks. Our experiments on variants of the {MNIST} and {CIFAR}-100 datasets demonstrate the strong performance of {GEM} when compared to the state-of-the-art.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lou_discrete_2024" class=ref>
<summary class=citation>
<a id="lou_discrete_2024">[lou_discrete_2024]</a> - Lou, Aaron and Meng, Chenlin and Ermon, Stefano - <a href="http://arxiv.org/abs/2310.16834" target="_blank"><cite>Discrete Diffusion Modeling by Estimating the Ratios of the Data Distribution</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite lou_discrete_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-92" id="summaryabstract-92">Summary/Abstract</a></h1>
<div>Despite their groundbreaking performance for many generative modeling tasks, diffusion models have fallen short on discrete data domains such as natural language. Crucially, standard diffusion models rely on the well-established theory of score matching, but efforts to generalize this to discrete structures have not yielded the same empirical gains. In this work, we bridge this gap by proposing score entropy, a novel loss that naturally extends score matching to discrete spaces, integrates seamlessly to build discrete diffusion models, and significantly boosts performance. Experimentally, we test our Score Entropy Discrete Diffusion models ({SEDD}) on standard language modeling tasks. For comparable model sizes, {SEDD} beats existing language diffusion paradigms (reducing perplexity by 25-75\%) and is competitive with autoregressive models, in particular outperforming {GPT}-2. Furthermore, compared to autoregressive mdoels, {SEDD} generates faithful text without requiring distribution annealing techniques like temperature scaling (around 68× better generative perplexity than un-annealed {GPT}-2), can trade compute and quality (similar quality with 32× fewer network evaluations), and enables controllable infilling (matching nucleus sampling quality while enabling other strategies besides left to right prompting).</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="lundberg_unified_2017" class=ref>
<summary class=citation>
<a id="lundberg_unified_2017">[lundberg_unified_2017]</a> - Lundberg, Scott and Lee, Su-In - <a href="http://arxiv.org/abs/1705.07874" target="_blank"><cite>A Unified Approach to Interpreting Model Predictions</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite lundberg_unified_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-93" id="summaryabstract-93">Summary/Abstract</a></h1>
<div>Understanding why a model makes a certain prediction can be as crucial as the prediction&#x27;s accuracy in many applications. However, the highest accuracy for large modern datasets is often achieved by complex models that even experts struggle to interpret, such as ensemble or deep learning models, creating a tension between accuracy and interpretability. In response, various methods have recently been proposed to help users interpret the predictions of complex models, but it is often unclear how these methods are related and when one method is preferable over another. To address this problem, we present a unified framework for interpreting predictions, {SHAP} ({SHapley} Additive {exPlanations}). {SHAP} assigns each feature an importance value for a particular prediction. Its novel components include: (1) the identification of a new class of additive feature importance measures, and (2) theoretical results showing there is a unique solution in this class with a set of desirable properties. The new class unifies six existing methods, notable because several recent methods in the class lack the proposed desirable properties. Based on insights from this unification, we present new methods that show improved computational performance and/or better consistency with human intuition than previous approaches.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="luo_have_2021" class=ref>
<summary class=citation>
<a id="luo_have_2021">[luo_have_2021]</a> - Luo, Ziyang - <a href="http://arxiv.org/abs/2102.07926" target="_blank"><cite>Have Attention Heads in {BERT} Learned Constituency Grammar?</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite luo_have_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-94" id="summaryabstract-94">Summary/Abstract</a></h1>
<div>With the success of pre-trained language models in recent years, more and more researchers focus on opening the black box of these models. Following this interest, we carry out a qualitative and quantitative analysis of constituency grammar in attention heads of {BERT} and {RoBERTa}. We employ the syntactic distance method to extract implicit constituency grammar from the attention weights of each head. Our results show that there exist heads that can induce some grammar types much better than baselines, suggesting that some heads act as a proxy for constituency grammar. We also analyze how attention heads&#x27; constituency grammar inducing ({CGI}) ability changes after fine-tuning with two kinds of tasks, including sentence meaning similarity ({SMS}) tasks and natural language inference ({NLI}) tasks. Our results suggest that {SMS} tasks decrease the average {CGI} ability of upper layers, while {NLI} tasks increase it. Lastly, we investigate the connections between {CGI} ability and natural language understanding ability on {QQP} and {MNLI} tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="marcus_next_2020" class=ref>
<summary class=citation>
<a id="marcus_next_2020">[marcus_next_2020]</a> - Marcus, Gary - <a href="http://arxiv.org/abs/2002.06177" target="_blank"><cite>The Next Decade in {AI}: Four Steps Towards Robust Artificial Intelligence</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite marcus_next_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-95" id="summaryabstract-95">Summary/Abstract</a></h1>
<div>Recent research in artificial intelligence and machine learning has largely emphasized general-purpose learning and ever-larger training sets and more and more compute. In contrast, I propose a hybrid, knowledge-driven, reasoning-based approach, centered around cognitive models, that could provide the substrate for a richer, more robust {AI} than is currently possible.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="masse_alleviating_2018" class=ref>
<summary class=citation>
<a id="masse_alleviating_2018">[masse_alleviating_2018]</a> - Masse, Nicolas Y. and Grant, Gregory D. and Freedman, David J. - <a href="https://www.pnas.org/content/115/44/E10467" target="_blank"><cite>Alleviating catastrophic forgetting using context-dependent gating and synaptic stabilization</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite masse_alleviating_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-96" id="summaryabstract-96">Summary/Abstract</a></h1>
<div>Humans and most animals can learn new tasks without forgetting old ones. However, training artificial neural networks ({ANNs}) on new tasks typically causes them to forget previously learned tasks. This phenomenon is the result of “catastrophic forgetting,” in which training an {ANN} disrupts connection weights that were important for solving previous tasks, degrading task performance. Several recent studies have proposed methods to stabilize connection weights of {ANNs} that are deemed most important for solving a task, which helps alleviate catastrophic forgetting. Here, drawing inspiration from algorithms that are believed to be implemented in vivo, we propose a complementary method: adding a context-dependent gating signal, such that only sparse, mostly nonoverlapping patterns of units are active for any one task. This method is easy to implement, requires little computational overhead, and allows {ANNs} to maintain high performance across large numbers of sequentially presented tasks, particularly when combined with weight stabilization. We show that this method works for both feedforward and recurrent network architectures, trained using either supervised or reinforcement-based learning. This suggests that using multiple, complementary methods, akin to what is believed to occur in the brain, can be a highly effective strategy to support continual learning.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="mccloskey_catastrophic_1989" class=ref>
<summary class=citation>
<a id="mccloskey_catastrophic_1989">[mccloskey_catastrophic_1989]</a> - {McCloskey}, Michael and Cohen, Neal J. - <a href="https://www.sciencedirect.com/science/article/pii/S0079742108605368" target="_blank"><cite>Catastrophic Interference in Connectionist Networks: The Sequential Learning Problem</cite></a>. - 1989. -
<button onclick="copyToClipboard('\{\{ #cite mccloskey_catastrophic_1989 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-97" id="summaryabstract-97">Summary/Abstract</a></h1>
<div>Connectionist networks in which information is stored in weights on connections among simple processing units have attracted considerable interest in cognitive science. Much of the interest centers around two characteristics of these networks. First, the weights on connections between units need not be prewired by the model builder but rather may be established through training in which items to be learned are presented repeatedly to the network and the connection weights are adjusted in small increments according to a learning algorithm. Second, the networks may represent information in a distributed fashion. This chapter discusses the catastrophic interference in connectionist networks. Distributed representations established through the application of learning algorithms have several properties that are claimed to be desirable from the standpoint of modeling human cognition. These properties include content-addressable memory and so-called automatic generalization in which a network trained on a set of items responds correctly to other untrained items within the same domain. New learning may interfere catastrophically with old learning when networks are trained sequentially. The analysis of the causes of interference implies that at least some interference will occur whenever new learning may alter weights involved in representing old learning, and the simulation results demonstrate only that interference is catastrophic in some specific networks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="metz_genius_2021" class=ref>
<summary class=citation>
<a id="metz_genius_2021">[metz_genius_2021]</a> - Metz, Cade - <cite>Genius Makers: The Mavericks Who Brought {AI} to Google, Facebook, and the World</cite>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite metz_genius_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-98" id="summaryabstract-98">Summary/Abstract</a></h1>
<div>This colorful page-turner puts artificial intelligence into a human perspective. Through the lives of Geoff Hinton and other major players, Metz explains this transformative technology and makes the quest thrilling.—Walter Isaacson, author of The Code {BreakerRecipient} of starred reviews in both Kirkus and Library {JournalTHE} {UNTOLD} {TECH} {STORY} {OF} {OUR} {TIME}   What does it mean to be smart? To be human? What do we really want from life and the intelligence we have, or might create?   With deep and exclusive reporting, across hundreds of interviews, New York Times Silicon Valley journalist Cade Metz brings you into the rooms where these questions are being answered. Where an extraordinarily powerful new artificial intelligence has been built into our biggest companies, our social discourse, and our daily lives, with few of us even noticing.     Long dismissed as a technology of the distant future, artificial intelligence was a project consigned to the fringes of the scientific community. Then two researchers changed everything. One was a sixty-four-year-old computer science professor who didn’t drive and didn’t fly because he could no longer sit down—but still made his way across North America for the moment that would define a new age of technology. The other was a thirty-six-year-old neuroscientist and chess prodigy who laid claim to being the greatest game player of all time before vowing to build a machine that could do anything the human brain could do.   They took two very different paths to that lofty goal, and they disagreed on how quickly it would arrive. But both were soon drawn into the heart of the tech industry. Their ideas drove a new kind of arms race, spanning Google, Microsoft, Facebook, and {OpenAI}, a new lab founded by Silicon Valley kingpin Elon Musk. But some believed that China would beat them all to the finish line.   Genius Makers dramatically presents the fierce conflict between national interests, shareholder value, the pursuit of scientific knowledge, and the very human concerns about privacy, security, bias, and prejudice. Like a great Victorian novel, this world of eccentric, brilliant, often unimaginably yet suddenly wealthy characters draws you into the most profound moral questions we can ask. And like a great mystery, it presents the story and facts that lead to a core, vital question:   How far will we let it go?</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="mikolov_efficient_2013" class=ref>
<summary class=citation>
<a id="mikolov_efficient_2013">[mikolov_efficient_2013]</a> - Mikolov, Tomas and Chen, Kai and Corrado, Greg and Dean, Jeffrey - <a href="http://arxiv.org/abs/1301.3781" target="_blank"><cite>Efficient Estimation of Word Representations in Vector Space</cite></a>. - 2013. -
<button onclick="copyToClipboard('\{\{ #cite mikolov_efficient_2013 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-99" id="summaryabstract-99">Summary/Abstract</a></h1>
<div>We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="mikolov_distributed_nodate" class=ref>
<summary class=citation>
<a id="mikolov_distributed_nodate">[mikolov_distributed_nodate]</a> - Mikolov, Tomas and Sutskever, Ilya and Chen, Kai and Corrado, Greg S and Dean, Jeff - <cite>Distributed Representations of Words and Phrases and their Compositionality</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite mikolov_distributed_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-100" id="summaryabstract-100">Summary/Abstract</a></h1>
<div>The recently introduced continuous Skip-gram model is an efﬁcient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain signiﬁcant speedup and also learn more regular word representations. We also describe a simple alternative to the hierarchical softmax called negative sampling.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="miller_explanation_2018" class=ref>
<summary class=citation>
<a id="miller_explanation_2018">[miller_explanation_2018]</a> - Miller, Tim - <a href="http://arxiv.org/abs/1706.07269" target="_blank"><cite>Explanation in Artificial Intelligence: Insights from the Social Sciences</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite miller_explanation_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-101" id="summaryabstract-101">Summary/Abstract</a></h1>
<div>There has been a recent resurgence in the area of explainable artificial intelligence as researchers and practitioners seek to make their algorithms more understandable. Much of this research is focused on explicitly explaining decisions or actions to a human observer, and it should not be controversial to say that looking at how humans explain to each other can serve as a useful starting point for explanation in artificial intelligence. However, it is fair to say that most work in explainable artificial intelligence uses only the researchers&#x27; intuition of what constitutes a &#x60;good&#x27; explanation. There exists vast and valuable bodies of research in philosophy, psychology, and cognitive science of how people define, generate, select, evaluate, and present explanations, which argues that people employ certain cognitive biases and social expectations towards the explanation process. This paper argues that the field of explainable artificial intelligence should build on this existing research, and reviews relevant papers from philosophy, cognitive psychology/science, and social psychology, which study these topics. It draws out some important findings, and discusses ways that these can be infused with work on explainable artificial intelligence.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="minaee_deep_2021" class=ref>
<summary class=citation>
<a id="minaee_deep_2021">[minaee_deep_2021]</a> - Minaee, Shervin and Kalchbrenner, Nal and Cambria, Erik and Nikzad, Narjes and Chenaghlu, Meysam and Gao, Jianfeng - <a href="http://arxiv.org/abs/2004.03705" target="_blank"><cite>Deep Learning Based Text Classification: A Comprehensive Review</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite minaee_deep_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-102" id="summaryabstract-102">Summary/Abstract</a></h1>
<div>Deep learning based models have surpassed classical machine learning based approaches in various text classification tasks, including sentiment analysis, news categorization, question answering, and natural language inference. In this paper, we provide a comprehensive review of more than 150 deep learning based models for text classification developed in recent years, and discuss their technical contributions, similarities, and strengths. We also provide a summary of more than 40 popular datasets widely used for text classification. Finally, we provide a quantitative analysis of the performance of different deep learning models on popular benchmarks, and discuss future research directions.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="minsky_framework_1974" class=ref>
<summary class=citation>
<a id="minsky_framework_1974">[minsky_framework_1974]</a> - Minsky, Marvin - <a href="https://web.media.mit.edu/~minsky/papers/Frames/frames.html" target="_blank"><cite>A Framework for Representing Knowledge</cite></a>. - 1974. -
<button onclick="copyToClipboard('\{\{ #cite minsky_framework_1974 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-103" id="summaryabstract-103">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="minsky_k-lines_1979" class=ref>
<summary class=citation>
<a id="minsky_k-lines_1979">[minsky_k-lines_1979]</a> - Minsky, Marvin - <a href="https://dspace.mit.edu/handle/1721.1/5739" target="_blank"><cite>K-Lines: A Theory of Memory</cite></a>. - 1979. -
<button onclick="copyToClipboard('\{\{ #cite minsky_k-lines_1979 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-104" id="summaryabstract-104">Summary/Abstract</a></h1>
<div>Most theories of memory suggest that when  we learn or memorize something, some  representation of that something is  constructed, stored and later retrieved. This  raises questions like: How is information  represented? How is it stored? How is it  retrieved? Then, how is it use? This paper  tries to deal with all these at once. When you  get an idea and want to remember it, you  create a K-line for it. When later activated, the  K-line induces a partial mental state  resembling the one that created it. A partial  mental state is a subset of those mental  agencies operating at one moment. This view  leads to many ideas about the development,  structure and physiology of Memory, and  about how to implement frame-like  representations in a distributed processor.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="minsky_perceptrons_1987" class=ref>
<summary class=citation>
<a id="minsky_perceptrons_1987">[minsky_perceptrons_1987]</a> - Minsky, Marvin and Papert, Seymour A. - <cite>Perceptrons: An Introduction to Computational Geometry, Expanded Edition</cite>. - 1987. -
<button onclick="copyToClipboard('\{\{ #cite minsky_perceptrons_1987 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-105" id="summaryabstract-105">Summary/Abstract</a></h1>
<div>Perceptrons - the first systematic study of parallelism in computation - has remained a classical work on threshold automata networks for nearly two decades. It marked a historical turn in artificial intelligence, and it is required reading for anyone who wants to understand the connectionist counterrevolution that is going on today. Artificial-intelligence research, which for a time concentrated on the programming of ton Neumann computers, is swinging back to the idea that intelligence might emerge from the activity of networks of neuronlike entities. Minsky and Papert&#x27;s book was the first example of a mathematical analysis carried far enough to show the exact limitations of a class of computing machines that could seriously be considered as models of the brain. Now the new developments in mathematical tools, the recent interest of physicists in the theory of disordered matter, the new insights into and psychological models of how the brain works, and the evolution of fast computers that can simulate networks of automata have given Perceptrons new importance.Witnessing the swing of the intellectual pendulum, Minsky and Papert have added a new chapter in which they discuss the current state of parallel computers, review developments since the appearance of the 1972 edition, and identify new research directions related to connectionism. They note a central theoretical challenge facing connectionism: the challenge to reach a deeper understanding of how objects or agents with individuality can emerge in a network. Progress in this area would link connectionism with what the authors have called society theories of mind. Marvin L. Minsky is Donner Professor of Science in M.I.T.&#x27;s Electrical Engineering and Computer Science Department. Seymour A. Papert is Professor of Media Technology at M.I.T. .</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="mnih_human-level_2015" class=ref>
<summary class=citation>
<a id="mnih_human-level_2015">[mnih_human-level_2015]</a> - Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Rusu, Andrei A. and Veness, Joel and Bellemare, Marc G. and Graves, Alex and Riedmiller, Martin and Fidjeland, Andreas K. and Ostrovski, Georg and Petersen, Stig and Beattie, Charles and Sadik, Amir and Antonoglou, Ioannis and King, Helen and Kumaran, Dharshan and Wierstra, Daan and Legg, Shane and Hassabis, Demis - <a href="http://www.nature.com/articles/nature14236" target="_blank"><cite>Human-level control through deep reinforcement learning</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite mnih_human-level_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-106" id="summaryabstract-106">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="molnar_interpretable_nodate" class=ref>
<summary class=citation>
<a id="molnar_interpretable_nodate">[molnar_interpretable_nodate]</a> - Molnar, Christoph - <a href="https://christophm.github.io/interpretable-ml-book/" target="_blank"><cite>Interpretable Machine Learning</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite molnar_interpretable_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-107" id="summaryabstract-107">Summary/Abstract</a></h1>
<div>Machine learning algorithms usually operate as black boxes and it is unclear how they derived a certain decision. This book is a guide for practitioners to make machine learning decisions interpretable.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="mudgal_deep_2018" class=ref>
<summary class=citation>
<a id="mudgal_deep_2018">[mudgal_deep_2018]</a> - Mudgal, Sidharth and Li, Han and Rekatsinas, Theodoros and Doan, {AnHai} and Park, Youngchoon and Krishnan, Ganesh and Deep, Rohit and Arcaute, Esteban and Raghavendra, Vijay - <a href="https://dl.acm.org/doi/10.1145/3183713.3196926" target="_blank"><cite>Deep Learning for Entity Matching: A Design Space Exploration</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite mudgal_deep_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-108" id="summaryabstract-108">Summary/Abstract</a></h1>
<div>Entity matching ({EM}) finds data instances that refer to the same real-world entity. In this paper we examine applying deep learning ({DL}) to {EM}, to understand {DL}’s benefits and limitations. We review many {DL} solutions that have been developed for related matching tasks in text processing (e.g., entity linking, textual entailment, etc.). We categorize these solutions and define a space of {DL} solutions for {EM}, as embodied by four solutions with varying representational power: {SIF}, {RNN}, Attention, and Hybrid. Next, we investigate the types of {EM} problems for which {DL} can be helpful. We consider three such problem types, which match structured data instances, textual instances, and dirty instances, respectively. We empirically compare the above four {DL} solutions with Magellan, a state-of-the-art learning-based {EM} solution. The results show that {DL} does not outperform current solutions on structured {EM}, but it can significantly outperform them on textual and dirty {EM}. For practitioners, this suggests that they should seriously consider using {DL} for textual and dirty {EM} problems. Finally, we analyze {DL}’s performance and discuss future research directions.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="nakkiran_deep_2019" class=ref>
<summary class=citation>
<a id="nakkiran_deep_2019">[nakkiran_deep_2019]</a> - Nakkiran, Preetum and Kaplun, Gal and Bansal, Yamini and Yang, Tristan and Barak, Boaz and Sutskever, Ilya - <a href="http://arxiv.org/abs/1912.02292" target="_blank"><cite>Deep Double Descent: Where Bigger Models and More Data Hurt</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite nakkiran_deep_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-109" id="summaryabstract-109">Summary/Abstract</a></h1>
<div>We show that a variety of modern deep learning tasks exhibit a double-descent phenomenon where, as we increase model size, performance first gets worse and then gets better. Moreover, we show that double descent occurs not just as a function of model size, but also as a function of the number of training epochs. We unify the above phenomena by defining a new complexity measure we call the effective model complexity and conjecture a generalized double descent with respect to this measure. Furthermore, our notion of model complexity allows us to identify certain regimes where increasing (even quadrupling) the number of train samples actually hurts test performance.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="nasr_scalable_2023" class=ref>
<summary class=citation>
<a id="nasr_scalable_2023">[nasr_scalable_2023]</a> - Nasr, Milad and Carlini, Nicholas and Hayase, Jonathan and Jagielski, Matthew and Cooper, A. Feder and Ippolito, Daphne and Choquette-Choo, Christopher A. and Wallace, Eric and Tramèr, Florian and Lee, Katherine - <a href="http://arxiv.org/abs/2311.17035" target="_blank"><cite>Scalable Extraction of Training Data from (Production) Language Models</cite></a>. - 2023. -
<button onclick="copyToClipboard('\{\{ #cite nasr_scalable_2023 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-110" id="summaryabstract-110">Summary/Abstract</a></h1>
<div>This paper studies extractable memorization: training data that an adversary can efficiently extract by querying a machine learning model without prior knowledge of the training dataset. We show an adversary can extract gigabytes of training data from open-source language models like Pythia or {GPT}-Neo, semi-open models like {LLaMA} or Falcon, and closed models like {ChatGPT}. Existing techniques from the literature suffice to attack unaligned models; in order to attack the aligned {ChatGPT}, we develop a new divergence attack that causes the model to diverge from its chatbot-style generations and emit training data at a rate 150x higher than when behaving properly. Our methods show practical attacks can recover far more data than previously thought, and reveal that current alignment techniques do not eliminate memorization.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="pan_survey_2010" class=ref>
<summary class=citation>
<a id="pan_survey_2010">[pan_survey_2010]</a> - Pan, Sinno Jialin and Yang, Qiang - <a href="http://ieeexplore.ieee.org/document/5288526/" target="_blank"><cite>A Survey on Transfer Learning</cite></a>. - 2010. -
<button onclick="copyToClipboard('\{\{ #cite pan_survey_2010 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-111" id="summaryabstract-111">Summary/Abstract</a></h1>
<div>A major assumption in many machine learning and data mining algorithms is that the training and future data must be in the same feature space and have the same distribution. However, in many real-world applications, this assumption may not hold. For example, we sometimes have a classiﬁcation task in one domain of interest, but we only have sufﬁcient training data in another domain of interest, where the latter data may be in a different feature space or follow a different data distribution. In such cases, knowledge transfer, if done successfully, would greatly improve the performance of learning by avoiding much expensive data labeling efforts. In recent years, transfer learning has emerged as a new learning framework to address this problem. This survey focuses on categorizing and reviewing the current progress on transfer learning for classiﬁcation, regression and clustering problems. In this survey, we discuss the relationship between transfer learning and other related machine learning techniques such as domain adaptation, multitask learning and sample selection bias, as well as co-variate shift. We also explore some potential future issues in transfer learning research.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="parisi_continual_2019" class=ref>
<summary class=citation>
<a id="parisi_continual_2019">[parisi_continual_2019]</a> - Parisi, German I. and Kemker, Ronald and Part, Jose L. and Kanan, Christopher and Wermter, Stefan - <a href="http://arxiv.org/abs/1802.07569" target="_blank"><cite>Continual Lifelong Learning with Neural Networks: A Review</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite parisi_continual_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-112" id="summaryabstract-112">Summary/Abstract</a></h1>
<div>Humans and animals have the ability to continually acquire, fine-tune, and transfer knowledge and skills throughout their lifespan. This ability, referred to as lifelong learning, is mediated by a rich set of neurocognitive mechanisms that together contribute to the development and specialization of our sensorimotor skills as well as to long-term memory consolidation and retrieval. Consequently, lifelong learning capabilities are crucial for autonomous agents interacting in the real world and processing continuous streams of information. However, lifelong learning remains a long-standing challenge for machine learning and neural network models since the continual acquisition of incrementally available information from non-stationary data distributions generally leads to catastrophic forgetting or interference. This limitation represents a major drawback for state-of-the-art deep neural network models that typically learn representations from stationary batches of training data, thus without accounting for situations in which information becomes incrementally available over time. In this review, we critically summarize the main challenges linked to lifelong learning for artificial learning systems and compare existing neural network approaches that alleviate, to different extents, catastrophic forgetting. We discuss well-established and emerging research motivated by lifelong learning factors in biological systems such as structural plasticity, memory replay, curriculum and transfer learning, intrinsic motivation, and multisensory integration.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="parmar_logicbench_2024" class=ref>
<summary class=citation>
<a id="parmar_logicbench_2024">[parmar_logicbench_2024]</a> - Parmar, Mihir and Patel, Nisarg and Varshney, Neeraj and Nakamura, Mutsumi and Luo, Man and Mashetty, Santosh and Mitra, Arindam and Baral, Chitta - <a href="https://aclanthology.org/2024.acl-long.739" target="_blank"><cite>{LogicBench}: Towards Systematic Evaluation of Logical Reasoning Ability of Large Language Models</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite parmar_logicbench_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-113" id="summaryabstract-113">Summary/Abstract</a></h1>
<div>Recently developed large language models ({LLMs}) have been shown to perform remarkably well on a wide range of language understanding tasks. But, can they really “reason” over the natural language? This question has been receiving significant research attention and many reasoning skills such as commonsense, numerical, and qualitative have been studied. However, the crucial skill pertaining to &#x60;logical reasoning&#x27; has remained underexplored. Existing work investigating this reasoning ability of {LLMs} has focused only on a couple of inference rules (such as modus ponens and modus tollens) of propositional and first-order logic. Addressing the above limitation, we comprehensively evaluate the logical reasoning ability of {LLMs} on 25 different reasoning patterns spanning over propositional, first-order, and non-monotonic logics. To enable systematic evaluation, we introduce {LogicBench}, a natural language question-answering dataset focusing on the use of a single inference rule. We conduct detailed analysis with a range of {LLMs} such as {GPT}-4, {ChatGPT}, Gemini, Llama-2, and Mistral using chain-of-thought prompting. Experimental results show that existing {LLMs} do not fare well on {LogicBench}; especially, they struggle with instances involving complex reasoning and negations. Furthermore, they sometimes tend to prioritize parametric knowledge over contextual information and overlook the correct reasoning chain. We believe that our work and findings facilitate future research for evaluating and enhancing the logical reasoning ability of {LLMs}.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="pearl_book_2020" class=ref>
<summary class=citation>
<a id="pearl_book_2020">[pearl_book_2020]</a> - Pearl, Judea and Mackenzie, Dana - <cite>The Book of Why: The New Science of Cause and Effect</cite>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite pearl_book_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-114" id="summaryabstract-114">Summary/Abstract</a></h1>
<div>A Turing Award-winning computer scientist and statistician shows how understanding causality has revolutionized science and will revolutionize artificial intelligence Correlation is not causation. This mantra, chanted by scientists for more than a century, has led to a virtual prohibition on causal talk. Today, that taboo is dead. The causal revolution, instigated by Judea Pearl and his colleagues, has cut through a century of confusion and established causality -- the study of cause and effect -- on a firm scientific basis. His work explains how we can know easy things, like whether it was rain or a sprinkler that made a sidewalk wet; and how to answer hard questions, like whether a drug cured an illness. Pearl&#x27;s work enables us to know not just whether one thing causes another: it lets us explore the world that is and the worlds that could have been. It shows us the essence of human thought and key to artificial intelligence. Anyone who wants to understand either needs The Book of Why.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="peng_hierarchical_2019" class=ref>
<summary class=citation>
<a id="peng_hierarchical_2019">[peng_hierarchical_2019]</a> - Peng, Hao and Li, Jianxin and Gong, Qiran and Wang, Senzhang and He, Lifang and Li, Bo and Wang, Lihong and Yu, Philip S. - <a href="http://arxiv.org/abs/1906.04898" target="_blank"><cite>Hierarchical Taxonomy-Aware and Attentional Graph Capsule {RCNNs} for Large-Scale Multi-Label Text Classification</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite peng_hierarchical_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-115" id="summaryabstract-115">Summary/Abstract</a></h1>
<div>{CNNs}, {RNNs}, {GCNs}, and {CapsNets} have shown significant insights in representation learning and are widely used in various text mining tasks such as large-scale multi-label text classification. However, most existing deep models for multi-label text classification consider either the non-consecutive and long-distance semantics or the sequential semantics, but how to consider them both coherently is less studied. In addition, most existing methods treat output labels as independent methods, but ignore the hierarchical relations among them, leading to useful semantic information loss. In this paper, we propose a novel hierarchical taxonomy-aware and attentional graph capsule recurrent {CNNs} framework for large-scale multi-label text classification. Specifically, we first propose to model each document as a word order preserved graph-of-words and normalize it as a corresponding words-matrix representation which preserves both the non-consecutive, long-distance and local sequential semantics. Then the words-matrix is input to the proposed attentional graph capsule recurrent {CNNs} for more effectively learning the semantic features. To leverage the hierarchical relations among the class labels, we propose a hierarchical taxonomy embedding method to learn their representations, and define a novel weighted margin loss by incorporating the label representation similarity. Extensive evaluations on three datasets show that our model significantly improves the performance of large-scale multi-label text classification by comparing with state-of-the-art approaches.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="peters_deep_2018" class=ref>
<summary class=citation>
<a id="peters_deep_2018">[peters_deep_2018]</a> - Peters, Matthew E. and Neumann, Mark and Iyyer, Mohit and Gardner, Matt and Clark, Christopher and Lee, Kenton and Zettlemoyer, Luke - <a href="http://arxiv.org/abs/1802.05365" target="_blank"><cite>Deep contextualized word representations</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite peters_deep_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-116" id="summaryabstract-116">Summary/Abstract</a></h1>
<div>We introduce a new type of deep contextualized word representation that models both (1) complex characteristics of word use (e.g., syntax and semantics), and (2) how these uses vary across linguistic contexts (i.e., to model polysemy). Our word vectors are learned functions of the internal states of a deep bidirectional language model ({biLM}), which is pre-trained on a large text corpus. We show that these representations can be easily added to existing models and significantly improve the state of the art across six challenging {NLP} problems, including question answering, textual entailment and sentiment analysis. We also present an analysis showing that exposing the deep internals of the pre-trained network is crucial, allowing downstream models to mix different types of semi-supervision signals.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="polyzotis_slice_2019" class=ref>
<summary class=citation>
<a id="polyzotis_slice_2019">[polyzotis_slice_2019]</a> - Polyzotis, Neoklis and Whang, Steven and Kraska, Tim Klas and Chung, Yeounoh - <a href="https://arxiv.org/pdf/1807.06068.pdf" target="_blank"><cite>Slice Finder: Automated Data Slicing for Model Validation</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite polyzotis_slice_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-117" id="summaryabstract-117">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="primpeli_profiling_2020" class=ref>
<summary class=citation>
<a id="primpeli_profiling_2020">[primpeli_profiling_2020]</a> - Primpeli, Anna and Bizer, Christian - <a href="https://dl.acm.org/doi/10.1145/3340531.3412781" target="_blank"><cite>Profiling Entity Matching Benchmark Tasks</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite primpeli_profiling_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-118" id="summaryabstract-118">Summary/Abstract</a></h1>
<div>Entity matching is a central task in data integration which has been researched for decades. Over this time, a wide range of benchmark tasks for evaluating entity matching methods has been developed. This resource paper systematically complements, profiles, and compares 21 entity matching benchmark tasks. In order to better understand the specific challenges associated with different tasks, we define a set of profiling dimensions which capture central aspects of the matching tasks. Using these dimensions, we create groups of benchmark tasks having similar characteristics. Afterwards, we assess the difficulty of the tasks in each group by computing baseline evaluation results using standard feature engineering together with two common classification methods. In order to enable the exact reproducibility of evaluation results, matching tasks need to contain exactly defined sets of matching and non-matching record pairs, as well as a fixed development and test split. As this is not the case for some widely-used benchmark tasks, we complement these tasks with fixed sets of non-matching pairs, as well as fixed splits, and provide the resulting development and test sets for public download. By profiling and complementing the benchmark tasks, we support researchers to select challenging as well as diverse tasks and to compare matching systems on clearly defined grounds.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="prukalpa_future_2022" class=ref>
<summary class=citation>
<a id="prukalpa_future_2022">[prukalpa_future_2022]</a> - Prukalpa - <a href="https://towardsdatascience.com/the-future-of-the-modern-data-stack-in-2022-4f4c91bb778f" target="_blank"><cite>The Future of the Modern Data Stack in 2022</cite></a>. - 2022. -
<button onclick="copyToClipboard('\{\{ #cite prukalpa_future_2022 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-119" id="summaryabstract-119">Summary/Abstract</a></h1>
<div>Featuring the 6 big ideas you should know from 2021</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="radford_language_nodate" class=ref>
<summary class=citation>
<a id="radford_language_nodate">[radford_language_nodate]</a> - Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya - <cite>Language Models are Unsupervised Multitask Learners</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite radford_language_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-120" id="summaryabstract-120">Summary/Abstract</a></h1>
<div>Natural language processing tasks, such as question answering, machine translation, reading comprehension, and summarization, are typically approached with supervised learning on taskspeciﬁc datasets. We demonstrate that language models begin to learn these tasks without any explicit supervision when trained on a new dataset of millions of webpages called {WebText}. When conditioned on a document plus questions, the answers generated by the language model reach 55 F1 on the {CoQA} dataset - matching or exceeding the performance of 3 out of 4 baseline systems without using the 127,000+ training examples. The capacity of the language model is essential to the success of zero-shot task transfer and increasing it improves performance in a log-linear fashion across tasks. Our largest model, {GPT}-2, is a 1.5B parameter Transformer that achieves state of the art results on 7 out of 8 tested language modeling datasets in a zero-shot setting but still underﬁts {WebText}. Samples from the model reﬂect these improvements and contain coherent paragraphs of text. These ﬁndings suggest a promising path towards building language processing systems which learn to perform tasks from their naturally occurring demonstrations.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="raffel_exploring_2020" class=ref>
<summary class=citation>
<a id="raffel_exploring_2020">[raffel_exploring_2020]</a> - Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J. - <a href="http://arxiv.org/abs/1910.10683" target="_blank"><cite>Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite raffel_exploring_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-121" id="summaryabstract-121">Summary/Abstract</a></h1>
<div>Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing ({NLP}). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for {NLP} by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new &#x60;&#x60;Colossal Clean Crawled Corpus&#x27;&#x27;, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for {NLP}, we release our data set, pre-trained models, and code.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="rajbhandari_deepspeed-moe_2022" class=ref>
<summary class=citation>
<a id="rajbhandari_deepspeed-moe_2022">[rajbhandari_deepspeed-moe_2022]</a> - Rajbhandari, Samyam and Li, Conglong and Yao, Zhewei and Zhang, Minjia and Aminabadi, Reza Yazdani and Awan, Ammar Ahmad and Rasley, Jeff and He, Yuxiong - <a href="http://arxiv.org/abs/2201.05596" target="_blank"><cite>{DeepSpeed}-{MoE}: Advancing Mixture-of-Experts Inference and Training to Power Next-Generation {AI} Scale</cite></a>. - 2022. -
<button onclick="copyToClipboard('\{\{ #cite rajbhandari_deepspeed-moe_2022 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-122" id="summaryabstract-122">Summary/Abstract</a></h1>
<div>As the training of giant dense models hits the boundary on the availability and capability of the hardware resources today, Mixture-of-Experts ({MoE}) models become one of the most promising model architectures due to their significant training cost reduction compared to a quality-equivalent dense model. Its training cost saving is demonstrated from encoder-decoder models (prior works) to a 5x saving for auto-aggressive language models (this work along with parallel explorations). However, due to the much larger model size and unique architecture, how to provide fast {MoE} model inference remains challenging and unsolved, limiting its practical usage. To tackle this, we present {DeepSpeed}-{MoE}, an end-to-end {MoE} training and inference solution as part of the {DeepSpeed} library, including novel {MoE} architecture designs and model compression techniques that reduce {MoE} model size by up to 3.7x, and a highly optimized inference system that provides 7.3x better latency and cost compared to existing {MoE} inference solutions. {DeepSpeed}-{MoE} offers an unprecedented scale and efficiency to serve massive {MoE} models with up to 4.5x faster and 9x cheaper inference compared to quality-equivalent dense models. We hope our innovations and systems help open a promising path to new directions in the large model landscape, a shift from dense to sparse {MoE} models, where training and deploying higher-quality models with fewer resources becomes more widely possible.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="rajpurkar_squad_2016" class=ref>
<summary class=citation>
<a id="rajpurkar_squad_2016">[rajpurkar_squad_2016]</a> - Rajpurkar, Pranav and Zhang, Jian and Lopyrev, Konstantin and Liang, Percy - <a href="http://arxiv.org/abs/1606.05250" target="_blank"><cite>{SQuAD}: 100,000+ Questions for Machine Comprehension of Text</cite></a>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite rajpurkar_squad_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-123" id="summaryabstract-123">Summary/Abstract</a></h1>
<div>We present the Stanford Question Answering Dataset ({SQuAD}), a new reading comprehension dataset consisting of 100,000+ questions posed by crowdworkers on a set of Wikipedia articles, where the answer to each question is a segment of text from the corresponding reading passage. We analyze the dataset to understand the types of reasoning required to answer the questions, leaning heavily on dependency and constituency trees. We build a strong logistic regression model, which achieves an F1 score of 51.0\%, a significant improvement over a simple baseline (20\%). However, human performance (86.8\%) is much higher, indicating that the dataset presents a good challenge problem for future research. The dataset is freely available at https://stanford-qa.com</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="real_automl-zero_2020" class=ref>
<summary class=citation>
<a id="real_automl-zero_2020">[real_automl-zero_2020]</a> - Real, Esteban and Liang, Chen and So, David R. and Le, Quoc V. - <a href="http://arxiv.org/abs/2003.03384" target="_blank"><cite>{AutoML}-Zero: Evolving Machine Learning Algorithms From Scratch</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite real_automl-zero_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-124" id="summaryabstract-124">Summary/Abstract</a></h1>
<div>Machine learning research has advanced in multiple aspects, including model structures and learning methods. The effort to automate such research, known as {AutoML}, has also made significant progress. However, this progress has largely focused on the architecture of neural networks, where it has relied on sophisticated expert-designed layers as building blocks---or similarly restrictive search spaces. Our goal is to show that {AutoML} can go further: it is possible today to automatically discover complete machine learning algorithms just using basic mathematical operations as building blocks. We demonstrate this by introducing a novel framework that significantly reduces human bias through a generic search space. Despite the vastness of this space, evolutionary search can still discover two-layer neural networks trained by backpropagation. These simple neural networks can then be surpassed by evolving directly on tasks of interest, e.g. {CIFAR}-10 variants, where modern techniques emerge in the top algorithms, such as bilinear interactions, normalized gradients, and weight averaging. Moreover, evolution adapts algorithms to different task types: e.g., dropout-like techniques appear when little data is available. We believe these preliminary successes in discovering machine learning algorithms from scratch indicate a promising new direction for the field.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="rebuffel_controlling_2021" class=ref>
<summary class=citation>
<a id="rebuffel_controlling_2021">[rebuffel_controlling_2021]</a> - Rebuffel, Clément and Roberti, Marco and Soulier, Laure and Scoutheeten, Geoffrey and Cancelliere, Rossella and Gallinari, Patrick - <a href="http://arxiv.org/abs/2102.02810" target="_blank"><cite>Controlling Hallucinations at Word Level in Data-to-Text Generation</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite rebuffel_controlling_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-125" id="summaryabstract-125">Summary/Abstract</a></h1>
<div>Data-to-Text Generation ({DTG}) is a subfield of Natural Language Generation aiming at transcribing structured data in natural language descriptions. The field has been recently boosted by the use of neural-based generators which exhibit on one side great syntactic skills without the need of hand-crafted pipelines; on the other side, the quality of the generated text reflects the quality of the training data, which in realistic settings only offer imperfectly aligned structure-text pairs. Consequently, state-of-art neural models include misleading statements - usually called hallucinations - in their outputs. The control of this phenomenon is today a major challenge for {DTG}, and is the problem addressed in the paper. Previous work deal with this issue at the instance level: using an alignment score for each table-reference pair. In contrast, we propose a finer-grained approach, arguing that hallucinations should rather be treated at the word level. Specifically, we propose a Multi-Branch Decoder which is able to leverage word-level labels to learn the relevant parts of each training instance. These labels are obtained following a simple and efficient scoring procedure based on co-occurrence analysis and dependency parsing. Extensive evaluations, via automated metrics and human judgment on the standard {WikiBio} benchmark, show the accuracy of our alignment labels and the effectiveness of the proposed Multi-Branch Decoder. Our model is able to reduce and control hallucinations, while keeping fluency and coherence in generated texts. Further experiments on a degraded version of {ToTTo} show that our model could be successfully used on very noisy settings.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="ribeiro_beyond_2020" class=ref>
<summary class=citation>
<a id="ribeiro_beyond_2020">[ribeiro_beyond_2020]</a> - Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer - <a href="http://arxiv.org/abs/2005.04118" target="_blank"><cite>Beyond Accuracy: Behavioral Testing of {NLP} models with {CheckList}</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite ribeiro_beyond_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-126" id="summaryabstract-126">Summary/Abstract</a></h1>
<div>Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of {NLP} models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce {CheckList}, a task-agnostic methodology for testing {NLP} models. {CheckList} includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of {CheckList} with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, {NLP} practitioners with {CheckList} created twice as many tests, and found almost three times as many bugs as users without it.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="ribeiro_beyond_2020-1" class=ref>
<summary class=citation>
<a id="ribeiro_beyond_2020-1">[ribeiro_beyond_2020-1]</a> - Ribeiro, Marco Tulio and Wu, Tongshuang and Guestrin, Carlos and Singh, Sameer - <a href="https://www.aclweb.org/anthology/2020.acl-main.442" target="_blank"><cite>Beyond Accuracy: Behavioral Testing of {NLP} Models with {CheckList}</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite ribeiro_beyond_2020-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-127" id="summaryabstract-127">Summary/Abstract</a></h1>
<div>Although measuring held-out accuracy has been the primary approach to evaluate generalization, it often overestimates the performance of {NLP} models, while alternative approaches for evaluating models either focus on individual tasks or on specific behaviors. Inspired by principles of behavioral testing in software engineering, we introduce {CheckList}, a task-agnostic methodology for testing {NLP} models. {CheckList} includes a matrix of general linguistic capabilities and test types that facilitate comprehensive test ideation, as well as a software tool to generate a large and diverse number of test cases quickly. We illustrate the utility of {CheckList} with tests for three tasks, identifying critical failures in both commercial and state-of-art models. In a user study, a team responsible for a commercial sentiment analysis model found new and actionable bugs in an extensively tested model. In another user study, {NLP} practitioners with {CheckList} created twice as many tests, and found almost three times as many bugs as users without it.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="rios_few-shot_2018" class=ref>
<summary class=citation>
<a id="rios_few-shot_2018">[rios_few-shot_2018]</a> - Rios, Anthony and Kavuluru, Ramakanth - <a href="https://www.aclweb.org/anthology/D18-1352" target="_blank"><cite>Few-Shot and Zero-Shot Multi-Label Learning for Structured Label Spaces</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite rios_few-shot_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-128" id="summaryabstract-128">Summary/Abstract</a></h1>
<div>Large multi-label datasets contain labels that occur thousands of times (frequent group), those that occur only a few times (few-shot group), and labels that never appear in the training dataset (zero-shot group). Multi-label few- and zero-shot label prediction is mostly unexplored on datasets with large label spaces, especially for text classification. In this paper, we perform a fine-grained evaluation to understand how state-of-the-art methods perform on infrequent labels. Furthermore, we develop few- and zero-shot methods for multi-label text classification when there is a known structure over the label space, and evaluate them on two publicly available medical text datasets: {MIMIC} {II} and {MIMIC} {III}. For few-shot labels we achieve improvements of 6.2\% and 4.8\% in R_at_10 for {MIMIC} {II} and {MIMIC} {III}, respectively, over prior efforts; the corresponding R_at_10 improvements for zero-shot labels are 17.3\% and 19\%.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="ruder_transfer_2019" class=ref>
<summary class=citation>
<a id="ruder_transfer_2019">[ruder_transfer_2019]</a> - Ruder, Sebastian and Peters, Matthew E. and Swayamdipta, Swabha and Wolf, Thomas - <a href="https://www.aclweb.org/anthology/N19-5004" target="_blank"><cite>Transfer Learning in Natural Language Processing</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite ruder_transfer_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-129" id="summaryabstract-129">Summary/Abstract</a></h1>
<div>The classic supervised machine learning paradigm is based on learning in isolation, a single predictive model for a task using a single dataset. This approach requires a large number of training examples and performs best for well-defined and narrow tasks. Transfer learning refers to a set of methods that extend this approach by leveraging data from additional domains or tasks to train a model with better generalization properties. Over the last two years, the field of Natural Language Processing ({NLP}) has witnessed the emergence of several transfer learning methods and architectures which significantly improved upon the state-of-the-art on a wide range of {NLP} tasks. These improvements together with the wide availability and ease of integration of these methods are reminiscent of the factors that led to the success of pretrained word embeddings and {ImageNet} pretraining in computer vision, and indicate that these methods will likely become a common tool in the {NLP} landscape as well as an important research direction. We will present an overview of modern transfer learning methods in {NLP}, how models are pre-trained, what information the representations they learn capture, and review examples and case studies on how these models can be integrated and adapted in downstream {NLP} tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="ruffy_state_2019" class=ref>
<summary class=citation>
<a id="ruffy_state_2019">[ruffy_state_2019]</a> - Ruffy, Fabian and Chahal, Karanbir - <a href="https://arxiv.org/abs/1912.10850v1" target="_blank"><cite>The State of Knowledge Distillation for Classification</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite ruffy_state_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-130" id="summaryabstract-130">Summary/Abstract</a></h1>
<div>We survey various knowledge distillation ({KD}) strategies for simple
classification tasks and implement a set of techniques that claim
state-of-the-art accuracy. Our experiments using standardized model
architectures, fixed compute budgets, and consistent training schedules
indicate that many of these distillation results are hard to reproduce. This is
especially apparent with methods using some form of feature distillation.
Further examination reveals a lack of generalizability where these techniques
may only succeed for specific architectures and training settings. We observe
that appropriately tuned classical distillation in combination with a data
augmentation training scheme gives an orthogonal improvement over other
techniques. We validate this approach and open-source our code.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="salimans_weight_2016" class=ref>
<summary class=citation>
<a id="salimans_weight_2016">[salimans_weight_2016]</a> - Salimans, Tim and Kingma, Diederik P. - <a href="http://arxiv.org/abs/1602.07868" target="_blank"><cite>Weight Normalization: A Simple Reparameterization to Accelerate Training of Deep Neural Networks</cite></a>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite salimans_weight_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-131" id="summaryabstract-131">Summary/Abstract</a></h1>
<div>We present weight normalization: a reparameterization of the weight vectors in a neural network that decouples the length of those weight vectors from their direction. By reparameterizing the weights in this way we improve the conditioning of the optimization problem and we speed up convergence of stochastic gradient descent. Our reparameterization is inspired by batch normalization but does not introduce any dependencies between the examples in a minibatch. This means that our method can also be applied successfully to recurrent models such as {LSTMs} and to noise-sensitive applications such as deep reinforcement learning or generative models, for which batch normalization is less well suited. Although our method is much simpler, it still provides much of the speed-up of full batch normalization. In addition, the computational overhead of our method is lower, permitting more optimization steps to be taken in the same amount of time. We demonstrate the usefulness of our method on applications in supervised image recognition, generative modelling, and deep reinforcement learning.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sanh_distilbert_2020" class=ref>
<summary class=citation>
<a id="sanh_distilbert_2020">[sanh_distilbert_2020]</a> - Sanh, Victor and Debut, Lysandre and Chaumond, Julien and Wolf, Thomas - <a href="http://arxiv.org/abs/1910.01108" target="_blank"><cite>{DistilBERT}, a distilled version of {BERT}: smaller, faster, cheaper and lighter</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite sanh_distilbert_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-132" id="summaryabstract-132">Summary/Abstract</a></h1>
<div>As Transfer Learning from large-scale pre-trained models becomes more prevalent in Natural Language Processing ({NLP}), operating these large models in on-the-edge and/or under constrained computational training or inference budgets remains challenging. In this work, we propose a method to pre-train a smaller general-purpose language representation model, called {DistilBERT}, which can then be fine-tuned with good performances on a wide range of tasks like its larger counterparts. While most prior work investigated the use of distillation for building task-specific models, we leverage knowledge distillation during the pre-training phase and show that it is possible to reduce the size of a {BERT} model by 40\%, while retaining 97\% of its language understanding capabilities and being 60\% faster. To leverage the inductive biases learned by larger models during pre-training, we introduce a triple loss combining language modeling, distillation and cosine-distance losses. Our smaller, faster and lighter model is cheaper to pre-train and we demonstrate its capabilities for on-device computations in a proof-of-concept experiment and a comparative on-device study.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="schaul_prioritized_2015" class=ref>
<summary class=citation>
<a id="schaul_prioritized_2015">[schaul_prioritized_2015]</a> - Schaul, Tom and Quan, John and Antonoglou, Ioannis and Silver, David - <a href="https://arxiv.org/abs/1511.05952v4" target="_blank"><cite>Prioritized Experience Replay</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite schaul_prioritized_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-133" id="summaryabstract-133">Summary/Abstract</a></h1>
<div>Experience replay lets online reinforcement learning agents remember and
reuse experiences from the past. In prior work, experience transitions were
uniformly sampled from a replay memory. However, this approach simply replays
transitions at the same frequency that they were originally experienced,
regardless of their significance. In this paper we develop a framework for
prioritizing experience, so as to replay important transitions more frequently,
and therefore learn more efficiently. We use prioritized experience replay in
Deep Q-Networks ({DQN}), a reinforcement learning algorithm that achieved
human-level performance across many Atari games. {DQN} with prioritized
experience replay achieves a new state-of-the-art, outperforming {DQN} with
uniform replay on 41 out of 49 games.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="schmidhuber_deep_2015" class=ref>
<summary class=citation>
<a id="schmidhuber_deep_2015">[schmidhuber_deep_2015]</a> - Schmidhuber, Juergen - <a href="http://arxiv.org/abs/1404.7828" target="_blank"><cite>Deep Learning in Neural Networks: An Overview</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite schmidhuber_deep_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-134" id="summaryabstract-134">Summary/Abstract</a></h1>
<div>In recent years, deep artiﬁcial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarises relevant work, much of it from the previous millennium. Shallow and deep learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning \&amp; evolutionary computation, and indirect search for short programs encoding deep and large networks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="schrimpf_neural_2021" class=ref>
<summary class=citation>
<a id="schrimpf_neural_2021">[schrimpf_neural_2021]</a> - Schrimpf, Martin and Blank, Idan Asher and Tuckute, Greta and Kauf, Carina and Hosseini, Eghbal A. and Kanwisher, Nancy and Tenenbaum, Joshua B. and Fedorenko, Evelina - <a href="https://pnas.org/doi/full/10.1073/pnas.2105646118" target="_blank"><cite>The neural architecture of language: Integrative modeling converges on predictive processing</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite schrimpf_neural_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-135" id="summaryabstract-135">Summary/Abstract</a></h1>
<div>Significance
            Language is a quintessentially human ability. Research has long probed the functional architecture of language in the mind and brain using diverse neuroimaging, behavioral, and computational modeling approaches. However, adequate neurally-mechanistic accounts of how meaning might be extracted from language are sorely lacking. Here, we report a first step toward addressing this gap by connecting recent artificial neural networks from machine learning to human recordings during language processing. We find that the most powerful models predict neural and behavioral responses across different datasets up to noise levels. Models that perform better at predicting the next word in a sequence also better predict brain measurements—providing computationally explicit evidence that predictive processing fundamentally shapes the language comprehension mechanisms in the brain.
          , 
            The neuroscience of perception has recently been revolutionized with an integrative modeling approach in which computation, brain function, and behavior are linked across many datasets and many computational models. By revealing trends across models, this approach yields novel insights into cognitive and neural mechanisms in the target domain. We here present a systematic study taking this approach to higher-level cognition: human language processing, our species’ signature cognitive skill. We find that the most powerful “transformer” models predict nearly 100\% of explainable variance in neural responses to sentences and generalize across different datasets and imaging modalities (functional {MRI} and electrocorticography). Models’ neural fits (“brain score”) and fits to behavioral responses are both strongly correlated with model accuracy on the next-word prediction task (but not other language tasks). Model architecture appears to substantially contribute to neural fit. These results provide computationally explicit evidence that predictive processing fundamentally shapes the language comprehension mechanisms in the human brain.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="schwarz_progress_2018" class=ref>
<summary class=citation>
<a id="schwarz_progress_2018">[schwarz_progress_2018]</a> - Schwarz, Jonathan and Luketina, Jelena and Czarnecki, Wojciech M. and Grabska-Barwinska, Agnieszka and Teh, Yee Whye and Pascanu, Razvan and Hadsell, Raia - <a href="http://arxiv.org/abs/1805.06370" target="_blank"><cite>Progress \&amp; Compress: A scalable framework for continual learning</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite schwarz_progress_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-136" id="summaryabstract-136">Summary/Abstract</a></h1>
<div>We introduce a conceptually simple and scalable framework for continual learning domains where tasks are learned sequentially. Our method is constant in the number of parameters and is designed to preserve performance on previously encountered tasks while accelerating learning progress on subsequent problems. This is achieved by training a network with two components: A knowledge base, capable of solving previously encountered problems, which is connected to an active column that is employed to efficiently learn the current task. After learning a new task, the active column is distilled into the knowledge base, taking care to protect any previously acquired skills. This cycle of active learning (progression) followed by consolidation (compression) requires no architecture growth, no access to or storing of previous data or tasks, and no task-specific parameters. We demonstrate the progress \&amp; compress approach on sequential classification of handwritten alphabets as well as two reinforcement learning domains: Atari games and 3D maze navigation.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sculley_hidden_2015" class=ref>
<summary class=citation>
<a id="sculley_hidden_2015">[sculley_hidden_2015]</a> - Sculley, D. and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael and Crespo, Jean-François and Dennison, Dan - <a href="http://papers.nips.cc/paper/5656-hidden-technical-debt-in-machine-learning-systems.pdf" target="_blank"><cite>Hidden Technical Debt in Machine Learning Systems</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite sculley_hidden_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-137" id="summaryabstract-137">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sculley_machine_2014" class=ref>
<summary class=citation>
<a id="sculley_machine_2014">[sculley_machine_2014]</a> - Sculley, D. and Holt, Gary and Golovin, D. and Davydov, Eugene and Phillips, Todd and Ebner, D. and Chaudhary, Vinay and Young, M. - <a href="/paper/Machine-Learning%3A-The-High-Interest-Credit-Card-of-Sculley-Holt/51891710e30da33c4ced4ae7daee1593e0cb5cc4" target="_blank"><cite>Machine Learning: The High Interest Credit Card of Technical Debt</cite></a>. - 2014. -
<button onclick="copyToClipboard('\{\{ #cite sculley_machine_2014 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-138" id="summaryabstract-138">Summary/Abstract</a></h1>
<div>Machine learning offers a fantastically powerful toolkit for building complex systems quickly. This paper argues that it is dangerous to think of these quick wins as coming for free. Using the framework of technical debt, we note that it is remarkably easy to incur massive ongoing maintenance costs at the system level when applying machine learning. The goal of this paper is highlight several machine learning specific risk factors and design patterns to be avoided or refactored where possible. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, changes in the external world, and a variety of system-level anti-patterns. 1 Machine Learning and Complex Systems Real world software engineers are often faced with the challenge of moving quickly to ship new products or services, which can lead to a dilemma between speed of execution and quality of engineering. The concept of technical debt was first introduced by Ward Cunningham in 1992 as a way to help quantify the cost of such decisions. Like incurring fiscal debt, there are often sound strategic reasons to take on technical debt. Not all debt is necessarily bad, but technical debt does tend to compound. Deferring the work to pay it off results in increasing costs, system brittleness, and reduced rates of innovation. Traditional methods of paying off technical debt include refactoring, increasing coverage of unit tests, deleting dead code, reducing dependencies, tightening {APIs}, and improving documentation [4]. The goal of these activities is not to add new functionality, but to make it easier to add future improvements, be cheaper to maintain, and reduce the likelihood of bugs. One of the basic arguments in this paper is that machine learning packages have all the basic code complexity issues as normal code, but also have a larger system-level complexity that can create hidden debt. Thus, refactoring these libraries, adding better unit tests, and associated activity is time well spent but does not necessarily address debt at a systems level. In this paper, we focus on the system-level interaction between machine learning code and larger systems as an area where hidden technical debt may rapidly accumulate. At a system-level, a machine learning model may subtly erode abstraction boundaries. It may be tempting to re-use input signals in ways that create unintended tight coupling of otherwise disjoint systems. Machine learning packages may often be treated as black boxes, resulting in large masses of “glue code” or calibration layers that can lock in assumptions. Changes in the external world may make models or input signals change behavior in unintended ways, ratcheting up maintenance cost and the burden of any debt. Even monitoring that the system as a whole is operating as intended may be difficult without careful design.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sculley_machine_2014-1" class=ref>
<summary class=citation>
<a id="sculley_machine_2014-1">[sculley_machine_2014-1]</a> - Sculley, D. and Holt, Gary and Golovin, D. and Davydov, Eugene and Phillips, Todd and Ebner, D. and Chaudhary, Vinay and Young, M. - <a href="/paper/Machine-Learning%3A-The-High-Interest-Credit-Card-of-Sculley-Holt/51891710e30da33c4ced4ae7daee1593e0cb5cc4" target="_blank"><cite>Machine Learning: The High Interest Credit Card of Technical Debt</cite></a>. - 2014. -
<button onclick="copyToClipboard('\{\{ #cite sculley_machine_2014-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-139" id="summaryabstract-139">Summary/Abstract</a></h1>
<div>Machine learning offers a fantastically powerful toolkit for building complex systems quickly. This paper argues that it is dangerous to think of these quick wins as coming for free. Using the framework of technical debt, we note that it is remarkably easy to incur massive ongoing maintenance costs at the system level when applying machine learning. The goal of this paper is highlight several machine learning specific risk factors and design patterns to be avoided or refactored where possible. These include boundary erosion, entanglement, hidden feedback loops, undeclared consumers, data dependencies, changes in the external world, and a variety of system-level anti-patterns. 1 Machine Learning and Complex Systems Real world software engineers are often faced with the challenge of moving quickly to ship new products or services, which can lead to a dilemma between speed of execution and quality of engineering. The concept of technical debt was first introduced by Ward Cunningham in 1992 as a way to help quantify the cost of such decisions. Like incurring fiscal debt, there are often sound strategic reasons to take on technical debt. Not all debt is necessarily bad, but technical debt does tend to compound. Deferring the work to pay it off results in increasing costs, system brittleness, and reduced rates of innovation. Traditional methods of paying off technical debt include refactoring, increasing coverage of unit tests, deleting dead code, reducing dependencies, tightening {APIs}, and improving documentation [4]. The goal of these activities is not to add new functionality, but to make it easier to add future improvements, be cheaper to maintain, and reduce the likelihood of bugs. One of the basic arguments in this paper is that machine learning packages have all the basic code complexity issues as normal code, but also have a larger system-level complexity that can create hidden debt. Thus, refactoring these libraries, adding better unit tests, and associated activity is time well spent but does not necessarily address debt at a systems level. In this paper, we focus on the system-level interaction between machine learning code and larger systems as an area where hidden technical debt may rapidly accumulate. At a system-level, a machine learning model may subtly erode abstraction boundaries. It may be tempting to re-use input signals in ways that create unintended tight coupling of otherwise disjoint systems. Machine learning packages may often be treated as black boxes, resulting in large masses of “glue code” or calibration layers that can lock in assumptions. Changes in the external world may make models or input signals change behavior in unintended ways, ratcheting up maintenance cost and the burden of any debt. Even monitoring that the system as a whole is operating as intended may be difficult without careful design.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sculley_machine_2014-2" class=ref>
<summary class=citation>
<a id="sculley_machine_2014-2">[sculley_machine_2014-2]</a> - Sculley, D. and Holt, Gary and Golovin, Daniel and Davydov, Eugene and Phillips, Todd and Ebner, Dietmar and Chaudhary, Vinay and Young, Michael - <cite>Machine Learning: The High Interest Credit Card of Technical Debt</cite>. - 2014. -
<button onclick="copyToClipboard('\{\{ #cite sculley_machine_2014-2 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-140" id="summaryabstract-140">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sejnowski_deep_2018" class=ref>
<summary class=citation>
<a id="sejnowski_deep_2018">[sejnowski_deep_2018]</a> - Sejnowski, Terrence J. - <cite>The Deep Learning Revolution</cite>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite sejnowski_deep_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-141" id="summaryabstract-141">Summary/Abstract</a></h1>
<div>How deep learning—from Google Translate to driverless cars to personal cognitive assistants—is changing our lives and transforming every sector of the economy.The deep learning revolution has brought us driverless cars, the greatly improved Google Translate, fluent conversations with Siri and Alexa, and enormous profits from automated trading on the New York Stock Exchange. Deep learning networks can play poker better than professional poker players and defeat a world champion at Go. In this book, Terry Sejnowski explains how deep learning went from being an arcane academic field to a disruptive technology in the information economy.Sejnowski played an important role in the founding of deep learning, as one of a small group of researchers in the 1980s who challenged the prevailing logic-and-symbol based version of {AI}. The new version of {AI} Sejnowski and others developed, which became deep learning, is fueled instead by data. Deep networks learn from data in the same way that babies experience the world, starting with fresh eyes and gradually acquiring the skills needed to navigate novel environments. Learning algorithms extract information from raw data; information can be used to create knowledge; knowledge underlies understanding; understanding leads to wisdom. Someday a driverless car will know the road better than you do and drive with more skill; a deep learning network will diagnose your illness; a personal cognitive assistant will augment your puny human brain. It took nature many millions of years to evolve human intelligence; {AI} is on a trajectory measured in decades. Sejnowski prepares us for a deep learning future.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="shaw_self-attention_2018" class=ref>
<summary class=citation>
<a id="shaw_self-attention_2018">[shaw_self-attention_2018]</a> - Shaw, Peter and Uszkoreit, Jakob and Vaswani, Ashish - <a href="http://arxiv.org/abs/1803.02155" target="_blank"><cite>Self-Attention with Relative Position Representations</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite shaw_self-attention_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-142" id="summaryabstract-142">Summary/Abstract</a></h1>
<div>Relying entirely on an attention mechanism, the Transformer introduced by Vaswani et al. (2017) achieves state-of-the-art results for machine translation. In contrast to recurrent and convolutional neural networks, it does not explicitly model relative or absolute position information in its structure. Instead, it requires adding representations of absolute positions to its inputs. In this work we present an alternative approach, extending the self-attention mechanism to efficiently consider representations of the relative positions, or distances between sequence elements. On the {WMT} 2014 English-to-German and English-to-French translation tasks, this approach yields improvements of 1.3 {BLEU} and 0.3 {BLEU} over absolute position representations, respectively. Notably, we observe that combining relative and absolute position representations yields no further improvement in translation quality. We describe an efficient implementation of our method and cast it as an instance of relation-aware self-attention mechanisms that can generalize to arbitrary graph-labeled inputs.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="shin_continual_2017" class=ref>
<summary class=citation>
<a id="shin_continual_2017">[shin_continual_2017]</a> - Shin, Hanul and Lee, Jung Kwon and Kim, Jaehong and Kim, Jiwon - <a href="http://arxiv.org/abs/1705.08690" target="_blank"><cite>Continual Learning with Deep Generative Replay</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite shin_continual_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-143" id="summaryabstract-143">Summary/Abstract</a></h1>
<div>Attempts to train a comprehensive artificial intelligence capable of solving multiple tasks have been impeded by a chronic problem called catastrophic forgetting. Although simply replaying all previous data alleviates the problem, it requires large memory and even worse, often infeasible in real world applications where the access to past data is limited. Inspired by the generative nature of hippocampus as a short-term memory system in primate brain, we propose the Deep Generative Replay, a novel framework with a cooperative dual model architecture consisting of a deep generative model (generator) and a task solving model (solver). With only these two models, training data for previous tasks can easily be sampled and interleaved with those for a new task. We test our methods in several sequential learning settings involving image classification tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="shoeybi_megatron-lm:_2019" class=ref>
<summary class=citation>
<a id="shoeybi_megatron-lm:_2019">[shoeybi_megatron-lm:_2019]</a> - Shoeybi, Mohammad and Patwary, Mostofa and Puri, Raul and {LeGresley}, Patrick and Casper, Jared and Catanzaro, Bryan - <a href="https://arxiv.org/abs/1909.08053v3" target="_blank"><cite>Megatron-{LM}: Training Multi-Billion Parameter Language Models Using Model Parallelism</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite shoeybi_megatron-lm:_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-144" id="summaryabstract-144">Summary/Abstract</a></h1>
<div>Recent work in unsupervised language modeling demonstrates that training
large neural language models advances the state of the art in Natural Language
Processing applications. However, for very large models, memory constraints
limit the size of models that can be practically trained. Model parallelism
allows us to train larger models, because the parameters can be split across
multiple processors. In this work, we implement a simple, efficient intra-layer
model parallel approach that enables training state of the art transformer
language models with billions of parameters. Our approach does not require a
new compiler or library changes, is orthogonal and complimentary to pipeline
model parallelism, and can be fully implemented with the insertion of a few
communication operations in native {PyTorch}. We illustrate this approach by
converging an 8.3 billion parameter transformer language model using 512 {GPUs},
making it the largest transformer model ever trained at 24x times the size of
{BERT} and 5.6x times the size of {GPT}-2. We sustain up to 15.1 {PetaFLOPs} per
second across the entire application with 76\% scaling efficiency, compared to a
strong single processor baseline that sustains 39 {TeraFLOPs} per second, which
is 30\% of peak {FLOPs}. The model is trained on 174GB of text, requiring 12
{ZettaFLOPs} over 9.2 days to converge. Transferring this language model achieves
state of the art ({SOTA}) results on the {WikiText}103 (10.8 compared to {SOTA}
perplexity of 16.4) and {LAMBADA} (66.5\% compared to {SOTA} accuracy of 63.2\%)
datasets. We release training and evaluation code, as well as the weights of
our smaller portable model, for reproducibility.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sukhbaatar_adaptive_2019" class=ref>
<summary class=citation>
<a id="sukhbaatar_adaptive_2019">[sukhbaatar_adaptive_2019]</a> - Sukhbaatar, Sainbayar and Grave, Edouard and Bojanowski, Piotr and Joulin, Armand - <a href="http://arxiv.org/abs/1905.07799" target="_blank"><cite>Adaptive Attention Span in Transformers</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite sukhbaatar_adaptive_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-145" id="summaryabstract-145">Summary/Abstract</a></h1>
<div>We propose a novel self-attention mechanism that can learn its optimal attention span. This allows us to extend significantly the maximum context size used in Transformer, while maintaining control over their memory footprint and computational time. We show the effectiveness of our approach on the task of character level language modeling, where we achieve state-of-the-art performances on text8 and enwiki8 by using a maximum context of 8k characters.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sun_how_2020" class=ref>
<summary class=citation>
<a id="sun_how_2020">[sun_how_2020]</a> - Sun, Chi and Qiu, Xipeng and Xu, Yige and Huang, Xuanjing - <a href="http://arxiv.org/abs/1905.05583" target="_blank"><cite>How to Fine-Tune {BERT} for Text Classification?</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite sun_how_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-146" id="summaryabstract-146">Summary/Abstract</a></h1>
<div>Language model pre-training has proven to be useful in learning universal language representations. As a state-of-the-art language model pre-training model, {BERT} (Bidirectional Encoder Representations from Transformers) has achieved amazing results in many language understanding tasks. In this paper, we conduct exhaustive experiments to investigate different fine-tuning methods of {BERT} on text classification task and provide a general solution for {BERT} fine-tuning. Finally, the proposed solution obtains new state-of-the-art results on eight widely-studied text classification datasets.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sundareswaran_survey_2020" class=ref>
<summary class=citation>
<a id="sundareswaran_survey_2020">[sundareswaran_survey_2020]</a> - Sundareswaran, Veena and Shankari, T and Sowmiya, Senthil and Varsha, Mundhra - <cite>A {SURVEY} {ON} {TOOLS} {USED} {FOR} {MACHINE} {LEARNING}</cite>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite sundareswaran_survey_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-147" id="summaryabstract-147">Summary/Abstract</a></h1>
<div>In this paper, a brief introduction to Machine Learning and its Tools are studied. In the recent developments, most of the Machine learning tools are more advanced and efficient. The various tools learn the machine by using a training set, which predicts the output correctly and efficiently. Machine Learning is applied in different applications such as Agriculture, Data Quality, Information Retrieval, Financial Market Analysis etc.., In this paper, we have discussed few tools like Scikit learn, Pytorch, Tensor flow, Amazon Machine Learning, {KNIME}, Rapid Miner, Keras, and Shogun with its features and its advantages.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sutton_reinforcement_2018" class=ref>
<summary class=citation>
<a id="sutton_reinforcement_2018">[sutton_reinforcement_2018]</a> - Sutton, Richard S. and Barto, Andrew G. - <cite>Reinforcement Learning, second edition: An Introduction</cite>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite sutton_reinforcement_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-148" id="summaryabstract-148">Summary/Abstract</a></h1>
<div>The significantly expanded and updated new edition of a widely used text on reinforcement learning, one of the most active research areas in artificial intelligence.Reinforcement learning, one of the most active research areas in artificial intelligence, is a computational approach to learning whereby an agent tries to maximize the total amount of reward it receives while interacting with a complex, uncertain environment. In Reinforcement Learning, Richard Sutton and Andrew Barto provide a clear and simple account of the field&#x27;s key ideas and algorithms. This second edition has been significantly expanded and updated, presenting new topics and updating coverage of other topics.Like the first edition, this second edition focuses on core online learning algorithms, with the more mathematical material set off in shaded boxes. Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found. Many algorithms presented in this part are new to the second edition, including {UCB}, Expected Sarsa, and Double Learning. Part {II} extends these ideas to function approximation, with new sections on such topics as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods. Part {III} has new chapters on reinforcement learning&#x27;s relationships to psychology and neuroscience, as well as an updated case-studies chapter including {AlphaGo} and {AlphaGo} Zero, Atari game playing, and {IBM} Watson&#x27;s wagering strategy. The final chapter discusses the future societal impacts of reinforcement learning.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="sutton_reinforcement_1998" class=ref>
<summary class=citation>
<a id="sutton_reinforcement_1998">[sutton_reinforcement_1998]</a> - Sutton, Richard S. and Barto, Andrew G. - <cite>Reinforcement learning: an introduction</cite>. - 1998. -
<button onclick="copyToClipboard('\{\{ #cite sutton_reinforcement_1998 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-149" id="summaryabstract-149">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="synced_google_2019" class=ref>
<summary class=citation>
<a id="synced_google_2019">[synced_google_2019]</a> - Synced - <a href="https://medium.com/syncedreview/google-t5-explores-the-limits-of-transfer-learning-a87afbf2615b" target="_blank"><cite>Google T5 Explores the Limits of Transfer Learning</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite synced_google_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-150" id="summaryabstract-150">Summary/Abstract</a></h1>
<div>A Google research team recently published the paper Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer…</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="tan_survey_2018" class=ref>
<summary class=citation>
<a id="tan_survey_2018">[tan_survey_2018]</a> - Tan, Chuanqi and Sun, Fuchun and Kong, Tao and Zhang, Wenchang and Yang, Chao and Liu, Chunfang - <a href="http://arxiv.org/abs/1808.01974" target="_blank"><cite>A Survey on Deep Transfer Learning</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite tan_survey_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-151" id="summaryabstract-151">Summary/Abstract</a></h1>
<div>As a new classification platform, deep learning has recently received increasing attention from researchers and has been successfully applied to many domains. In some domains, like bioinformatics and robotics, it is very difficult to construct a large-scale well-annotated dataset due to the expense of data acquisition and costly annotation, which limits its development. Transfer learning relaxes the hypothesis that the training data must be independent and identically distributed (i.i.d.) with the test data, which motivates us to use transfer learning to solve the problem of insufficient training data. This survey focuses on reviewing the current researches of transfer learning by using deep neural network and its applications. We defined deep transfer learning, category and review the recent research works based on the techniques used in deep transfer learning.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="tavakoli_prioritizing_2019" class=ref>
<summary class=citation>
<a id="tavakoli_prioritizing_2019">[tavakoli_prioritizing_2019]</a> - Tavakoli, Arash and Levdik, Vitaly and Islam, Riashat and Kormushev, Petar - <a href="http://arxiv.org/abs/1811.11298" target="_blank"><cite>Prioritizing Starting States for Reinforcement Learning</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite tavakoli_prioritizing_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-152" id="summaryabstract-152">Summary/Abstract</a></h1>
<div>Online, off-policy reinforcement learning algorithms are able to use an experience memory to remember and replay past experiences. In prior work, this approach was used to stabilize training by breaking the temporal correlations of the updates and avoiding the rapid forgetting of possibly rare experiences. In this work, we propose a conceptually simple framework that uses an experience memory to help exploration by prioritizing the starting states from which the agent starts acting in the environment, importantly, in a fashion that is also compatible with on-policy algorithms. Given the capacity to restart the agent in states corresponding to its past observations, we achieve this objective by (i) enabling the agent to restart in states belonging to significant past experiences (e.g., nearby goals), and (ii) promoting faster coverage of the state space through starting from a more diverse set of states. While, using a good priority measure to identify significant past transitions, we expect case (i) to more considerably help exploration in certain domains (e.g., sparse reward tasks), we hypothesize that case (ii) will generally be beneficial, even without any prioritization. We show empirically that our approach improves learning performance for both off-policy and on-policy deep reinforcement learning methods, with most notable gains in highly sparse reward tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="tj_idles_2024" class=ref>
<summary class=citation>
<a id="tj_idles_2024">[tj_idles_2024]</a> - {TJ} - <a href="https://www.youtube.com/watch?v&#x3D;POrZqZSNzes" target="_blank"><cite>{IDLES} Live The Warfield, San Francisco {CA} 2024-05-11 [Full Show]</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite tj_idles_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-153" id="summaryabstract-153">Summary/Abstract</a></h1>
<div>{IDLES} - Live
2024-05-11
The Warfield
San Francisco, {CA}
<p>Setlist:</p>
<p>{IDEA} 01
Colossus
Gift Horse
Mr. Motivator
Mother
Car Crash
I'm Scum
1049 Gotho
The Wheel
Jungle
War
Wizz
Benzocaine
Grounds
Gratitude
Divide and Conquer
{POP} {POP} {POP}
Samaritans
Crawl!
The Beachland Ballroom
Never Fight a Man With a Perm
Dancer
Danny Nedelko
Rottweiler</p>
<p>Support {IDLES}!! And Free Palestine!</p>
<p>Official: https://www.idlesband.com
{IG}:   / idlesband  
{FB}:   / idlesband  
Bandcamp: https://idlesband.bandcamp.com/merch
Spotify: https://open.spotify.com/artist/75maf...</div></p>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="tsuda_modeling_2020" class=ref>
<summary class=citation>
<a id="tsuda_modeling_2020">[tsuda_modeling_2020]</a> - Tsuda, Ben and Tye, Kay M. and Siegelmann, Hava T. and Sejnowski, Terrence J. - <a href="https://www.pnas.org/content/117/47/29872" target="_blank"><cite>A modeling framework for adaptive lifelong learning with transfer and savings through gating in the prefrontal cortex</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite tsuda_modeling_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-154" id="summaryabstract-154">Summary/Abstract</a></h1>
<div>The prefrontal cortex encodes and stores numerous, often disparate, schemas and flexibly switches between them. Recent research on artificial neural networks trained by reinforcement learning has made it possible to model fundamental processes underlying schema encoding and storage. Yet how the brain is able to create new schemas while preserving and utilizing old schemas remains unclear. Here we propose a simple neural network framework that incorporates hierarchical gating to model the prefrontal cortex’s ability to flexibly encode and use multiple disparate schemas. We show how gating naturally leads to transfer learning and robust memory savings. We then show how neuropsychological impairments observed in patients with prefrontal damage are mimicked by lesions of our network. Our architecture, which we call {DynaMoE}, provides a fundamental framework for how the prefrontal cortex may handle the abundance of schemas necessary to navigate the real world.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="tunstall_efficient_2022" class=ref>
<summary class=citation>
<a id="tunstall_efficient_2022">[tunstall_efficient_2022]</a> - Tunstall, Lewis and Reimers, Nils and Jo, Unso Eun Seo and Bates, Luke and Korat, Daniel and Wasserblat, Moshe and Pereg, Oren - <a href="http://arxiv.org/abs/2209.11055" target="_blank"><cite>Efficient Few-Shot Learning Without Prompts</cite></a>. - 2022. -
<button onclick="copyToClipboard('\{\{ #cite tunstall_efficient_2022 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-155" id="summaryabstract-155">Summary/Abstract</a></h1>
<div>Recent few-shot methods, such as parameter-efficient fine-tuning ({PEFT}) and pattern exploiting training ({PET}), have achieved impressive results in label-scarce settings. However, they are difficult to employ since they are subject to high variability from manually crafted prompts, and typically require billion-parameter language models to achieve high accuracy. To address these shortcomings, we propose {SetFit} (Sentence Transformer Fine-tuning), an efficient and prompt-free framework for few-shot fine-tuning of Sentence Transformers ({ST}). {SetFit} works by first fine-tuning a pretrained {ST} on a small number of text pairs, in a contrastive Siamese manner. The resulting model is then used to generate rich text embeddings, which are used to train a classification head. This simple framework requires no prompts or verbalizers, and achieves high accuracy with orders of magnitude less parameters than existing techniques. Our experiments show that {SetFit} obtains comparable results with {PEFT} and {PET} techniques, while being an order of magnitude faster to train. We also show that {SetFit} can be applied in multilingual settings by simply switching the {ST} body. Our code is available at https://github.com/huggingface/setfit and our datasets at https://huggingface.co/setfit .</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="tunstall_efficient_2022-1" class=ref>
<summary class=citation>
<a id="tunstall_efficient_2022-1">[tunstall_efficient_2022-1]</a> - Tunstall, Lewis and Reimers, Nils and Jo, Unso Eun Seo and Bates, Luke and Korat, Daniel and Wasserblat, Moshe and Pereg, Oren - <a href="http://arxiv.org/abs/2209.11055" target="_blank"><cite>Efficient Few-Shot Learning Without Prompts</cite></a>. - 2022. -
<button onclick="copyToClipboard('\{\{ #cite tunstall_efficient_2022-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-156" id="summaryabstract-156">Summary/Abstract</a></h1>
<div>Recent few-shot methods, such as parameter-efficient fine-tuning ({PEFT}) and pattern exploiting training ({PET}), have achieved impressive results in label-scarce settings. However, they are difficult to employ since they are subject to high variability from manually crafted prompts, and typically require billion-parameter language models to achieve high accuracy. To address these shortcomings, we propose {SetFit} (Sentence Transformer Fine-tuning), an efficient and prompt-free framework for few-shot fine-tuning of Sentence Transformers ({ST}). {SetFit} works by first fine-tuning a pretrained {ST} on a small number of text pairs, in a contrastive Siamese manner. The resulting model is then used to generate rich text embeddings, which are used to train a classification head. This simple framework requires no prompts or verbalizers, and achieves high accuracy with orders of magnitude less parameters than existing techniques. Our experiments show that {SetFit} obtains comparable results with {PEFT} and {PET} techniques, while being an order of magnitude faster to train. We also show that {SetFit} can be applied in multilingual settings by simply switching the {ST} body. Our code is available at https://github.com/huggingface/setfit and our datasets at https://huggingface.co/setfit .</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="tversky_mind_2019" class=ref>
<summary class=citation>
<a id="tversky_mind_2019">[tversky_mind_2019]</a> - Tversky, Barbara - <cite>Mind in Motion: How Action Shapes Thought</cite>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite tversky_mind_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-157" id="summaryabstract-157">Summary/Abstract</a></h1>
<div>An eminent psychologist offers a major new theory of human cognition: movement, not language, is the foundation of {thoughtWhen} we try to think about how we think, we can&#x27;t help but think of words. Indeed, some have called language the stuff of thought. But pictures are remembered far better than words, and describing faces, scenes, and events defies words. Anytime you take a shortcut or play chess or basketball or rearrange your furniture in your mind, you&#x27;ve done something remarkable: abstract thinking without words. In Mind in Motion, psychologist Barbara Tversky shows that spatial cognition isn&#x27;t just a peripheral aspect of thought, but its very foundation, enabling us to draw meaning from our bodies and their actions in the world. Our actions in real space get turned into mental actions on thought, often spouting spontaneously from our bodies as gestures. Spatial thinking underlies creating and using maps, assembling furniture, devising football strategies, designing airports, understanding the flow of people, traffic, water, and ideas. Spatial thinking even underlies the structure and meaning of language: why we say we push ideas forward or tear them apart, why we&#x27;re feeling up or have grown far apart. Like Thinking, Fast and Slow before it, Mind in Motion gives us a new way to think about how--and where--thinking takes place.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="van_de_ven_three_2019" class=ref>
<summary class=citation>
<a id="van_de_ven_three_2019">[van_de_ven_three_2019]</a> - van de Ven, Gido M. and Tolias, Andreas S. - <a href="http://arxiv.org/abs/1904.07734" target="_blank"><cite>Three scenarios for continual learning</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite van_de_ven_three_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-158" id="summaryabstract-158">Summary/Abstract</a></h1>
<div>Standard artificial neural networks suffer from the well-known issue of catastrophic forgetting, making continual or lifelong learning difficult for machine learning. In recent years, numerous methods have been proposed for continual learning, but due to differences in evaluation protocols it is difficult to directly compare their performance. To enable more structured comparisons, we describe three continual learning scenarios based on whether at test time task identity is provided and–in case it is not–whether it must be inferred. Any sequence of well-defined tasks can be performed according to each scenario. Using the split and permuted {MNIST} task protocols, for each scenario we carry out an extensive comparison of recently proposed continual learning methods. We demonstrate substantial differences between the three scenarios in terms of difficulty and in terms of how efficient different methods are. In particular, when task identity must be inferred (i.e., class incremental learning), we find that regularization-based approaches (e.g., elastic weight consolidation) fail and that replaying representations of previous experiences seems required for solving this scenario.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="van_de_ven_generative_2019" class=ref>
<summary class=citation>
<a id="van_de_ven_generative_2019">[van_de_ven_generative_2019]</a> - van de Ven, Gido M. and Tolias, Andreas S. - <a href="http://arxiv.org/abs/1809.10635" target="_blank"><cite>Generative replay with feedback connections as a general strategy for continual learning</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite van_de_ven_generative_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-159" id="summaryabstract-159">Summary/Abstract</a></h1>
<div>A major obstacle to developing artificial intelligence applications capable of true lifelong learning is that artificial neural networks quickly or catastrophically forget previously learned tasks when trained on a new one. Numerous methods for alleviating catastrophic forgetting are currently being proposed, but differences in evaluation protocols make it difficult to directly compare their performance. To enable more meaningful comparisons, here we identified three distinct scenarios for continual learning based on whether task identity is known and, if it is not, whether it needs to be inferred. Performing the split and permuted {MNIST} task protocols according to each of these scenarios, we found that regularization-based approaches (e.g., elastic weight consolidation) failed when task identity needed to be inferred. In contrast, generative replay combined with distillation (i.e., using class probabilities as soft targets) achieved superior performance in all three scenarios. Addressing the issue of efficiency, we reduced the computational cost of generative replay by integrating the generative model into the main model by equipping it with generative feedback or backward connections. This Replay-through-Feedback approach substantially shortened training time with no or negligible loss in performance. We believe this to be an important first step towards making the powerful technique of generative replay scalable to real-world continual learning applications.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="van_de_ven_brain-inspired_2020" class=ref>
<summary class=citation>
<a id="van_de_ven_brain-inspired_2020">[van_de_ven_brain-inspired_2020]</a> - van de Ven, Gido M. and Siegelmann, Hava T. and Tolias, Andreas S. - <a href="https://www.nature.com/articles/s41467-020-17866-2" target="_blank"><cite>Brain-inspired replay for continual learning with artificial neural networks</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite van_de_ven_brain-inspired_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-160" id="summaryabstract-160">Summary/Abstract</a></h1>
<div>Artificial neural networks suffer from catastrophic forgetting. Unlike humans, when these networks are trained on something new, they rapidly forget what was learned before. In the brain, a mechanism thought to be important for protecting memories is the reactivation of neuronal activity patterns representing those memories. In artificial neural networks, such memory replay can be implemented as ‘generative replay’, which can successfully – and surprisingly efficiently – prevent catastrophic forgetting on toy examples even in a class-incremental learning scenario. However, scaling up generative replay to complicated problems with many tasks or complex inputs is challenging. We propose a new, brain-inspired variant of replay in which internal or hidden representations are replayed that are generated by the network’s own, context-modulated feedback connections. Our method achieves state-of-the-art performance on challenging continual learning benchmarks (e.g., class-incremental learning on {CIFAR}-100) without storing data, and it provides a novel model for replay in the brain.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="van_hasselt_deep_2015" class=ref>
<summary class=citation>
<a id="van_hasselt_deep_2015">[van_hasselt_deep_2015]</a> - van Hasselt, Hado and Guez, Arthur and Silver, David - <a href="http://arxiv.org/abs/1509.06461" target="_blank"><cite>Deep Reinforcement Learning with Double Q-learning</cite></a>. - 2015. -
<button onclick="copyToClipboard('\{\{ #cite van_hasselt_deep_2015 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-161" id="summaryabstract-161">Summary/Abstract</a></h1>
<div>The popular Q-learning algorithm is known to overestimate action values under certain conditions. It was not previously known whether, in practice, such overestimations are common, whether they harm performance, and whether they can generally be prevented. In this paper, we answer all these questions affirmatively. In particular, we first show that the recent {DQN} algorithm, which combines Q-learning with a deep neural network, suffers from substantial overestimations in some games in the Atari 2600 domain. We then show that the idea behind the Double Q-learning algorithm, which was introduced in a tabular setting, can be generalized to work with large-scale function approximation. We propose a specific adaptation to the {DQN} algorithm and show that the resulting algorithm not only reduces the observed overestimations, as hypothesized, but that this also leads to much better performance on several games.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="vaswani_attention_2017" class=ref>
<summary class=citation>
<a id="vaswani_attention_2017">[vaswani_attention_2017]</a> - Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Lukasz and Polosukhin, Illia - <a href="http://arxiv.org/abs/1706.03762" target="_blank"><cite>Attention Is All You Need</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite vaswani_attention_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-162" id="summaryabstract-162">Summary/Abstract</a></h1>
<div>The dominant sequence transduction models are based on complex recurrent or convolutional neural networks in an encoder-decoder configuration. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 {BLEU} on the {WMT} 2014 English-to-German translation task, improving over the existing best results, including ensembles by over 2 {BLEU}. On the {WMT} 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art {BLEU} score of 41.8 after training for 3.5 days on eight {GPUs}, a small fraction of the training costs of the best models from the literature. We show that the Transformer generalizes well to other tasks by applying it successfully to English constituency parsing both with large and limited training data.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="venkatesan_strategy_2017" class=ref>
<summary class=citation>
<a id="venkatesan_strategy_2017">[venkatesan_strategy_2017]</a> - Venkatesan, Ragav and Venkateswara, Hemanth and Panchanathan, Sethuraman and Li, Baoxin - <a href="http://arxiv.org/abs/1705.00744" target="_blank"><cite>A Strategy for an Uncompromising Incremental Learner</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite venkatesan_strategy_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-163" id="summaryabstract-163">Summary/Abstract</a></h1>
<div>Multi-class supervised learning systems require the knowledge of the entire range of labels they predict. Often when learnt incrementally, they suffer from catastrophic forgetting. To avoid this, generous leeways have to be made to the philosophy of incremental learning that either forces a part of the machine to not learn, or to retrain the machine again with a selection of the historic data. While these hacks work to various degrees, they do not adhere to the spirit of incremental learning. In this article, we redefine incremental learning with stringent conditions that do not allow for any undesirable relaxations and assumptions. We design a strategy involving generative models and the distillation of dark knowledge as a means of hallucinating data along with appropriate targets from past distributions. We call this technique, phantom sampling.We show that phantom sampling helps avoid catastrophic forgetting during incremental learning. Using an implementation based on deep neural networks, we demonstrate that phantom sampling dramatically avoids catastrophic forgetting. We apply these strategies to competitive multi-class incremental learning of deep neural networks. Using various benchmark datasets and through our strategy, we demonstrate that strict incremental learning could be achieved. We further put our strategy to test on challenging cases, including cross-domain increments and incrementing on a novel label space. We also propose a trivial extension to unbounded-continual learning and identify potential for future development.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wang_chain--thought_2024" class=ref>
<summary class=citation>
<a id="wang_chain--thought_2024">[wang_chain--thought_2024]</a> - Wang, Xuezhi and Zhou, Denny - <a href="http://arxiv.org/abs/2402.10200" target="_blank"><cite>Chain-of-Thought Reasoning Without Prompting</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite wang_chain--thought_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-164" id="summaryabstract-164">Summary/Abstract</a></h1>
<div>In enhancing the reasoning capabilities of large language models ({LLMs}), prior research primarily focuses on specific prompting techniques such as few-shot or zero-shot chain-of-thought ({CoT}) prompting. These methods, while effective, often involve manually intensive prompt engineering. Our study takes a novel approach by asking: Can {LLMs} reason effectively without prompting? Our findings reveal that, intriguingly, {CoT} reasoning paths can be elicited from pre-trained {LLMs} by simply altering the {\textbackslash}textit\{decoding\} process. Rather than conventional greedy decoding, we investigate the top-\$k\$ alternative tokens, uncovering that {CoT} paths are frequently inherent in these sequences. This approach not only bypasses the confounders of prompting but also allows us to assess the {LLMs}&#x27; {\textbackslash}textit\{intrinsic\} reasoning abilities. Moreover, we observe that the presence of a {CoT} in the decoding path correlates with a higher confidence in the model&#x27;s decoded answer. This confidence metric effectively differentiates between {CoT} and non-{CoT} paths. Extensive empirical studies on various reasoning benchmarks show that the proposed {CoT}-decoding effectively elicits reasoning capabilities from language models, which were previously obscured by standard greedy decoding.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wang_dueling_2016" class=ref>
<summary class=citation>
<a id="wang_dueling_2016">[wang_dueling_2016]</a> - Wang, Ziyu and Schaul, Tom and Hessel, Matteo and van Hasselt, Hado and Lanctot, Marc and de Freitas, Nando - <a href="http://arxiv.org/abs/1511.06581" target="_blank"><cite>Dueling Network Architectures for Deep Reinforcement Learning</cite></a>. - 2016. -
<button onclick="copyToClipboard('\{\{ #cite wang_dueling_2016 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-165" id="summaryabstract-165">Summary/Abstract</a></h1>
<div>In recent years there have been many successes of using deep representations in reinforcement learning. Still, many of these applications use conventional architectures, such as convolutional networks, {LSTMs}, or auto-encoders. In this paper, we present a new neural network architecture for model-free reinforcement learning. Our dueling network represents two separate estimators: one for the state value function and one for the state-dependent action advantage function. The main benefit of this factoring is to generalize learning across actions without imposing any change to the underlying reinforcement learning algorithm. Our results show that this architecture leads to better policy evaluation in the presence of many similar-valued actions. Moreover, the dueling architecture enables our {RL} agent to outperform the state-of-the-art on the Atari 2600 domain.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wang_glue_2019" class=ref>
<summary class=citation>
<a id="wang_glue_2019">[wang_glue_2019]</a> - Wang, Alex and Singh, Amanpreet and Michael, Julian and Hill, Felix and Levy, Omer and Bowman, Samuel R. - <a href="http://arxiv.org/abs/1804.07461" target="_blank"><cite>{GLUE}: A Multi-Task Benchmark and Analysis Platform for Natural Language Understanding</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite wang_glue_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-166" id="summaryabstract-166">Summary/Abstract</a></h1>
<div>For natural language understanding ({NLU}) technology to be maximally useful, both practically and as a scientific object of study, it must be general: it must be able to process language in a way that is not exclusively tailored to any one specific task or dataset. In pursuit of this objective, we introduce the General Language Understanding Evaluation benchmark ({GLUE}), a tool for evaluating and analyzing the performance of models across a diverse range of existing {NLU} tasks. {GLUE} is model-agnostic, but it incentivizes sharing knowledge across tasks because certain tasks have very limited training data. We further provide a hand-crafted diagnostic test suite that enables detailed linguistic analysis of {NLU} models. We evaluate baselines based on current methods for multi-task and transfer learning and find that they do not immediately give substantial improvements over the aggregate performance of training a separate model per task, indicating room for improvement in developing general and robust {NLU} systems.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wang_generalizing_2020" class=ref>
<summary class=citation>
<a id="wang_generalizing_2020">[wang_generalizing_2020]</a> - Wang, Yaqing and Yao, Quanming and Kwok, James and Ni, Lionel M. - <a href="http://arxiv.org/abs/1904.05046" target="_blank"><cite>Generalizing from a Few Examples: A Survey on Few-Shot Learning</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite wang_generalizing_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-167" id="summaryabstract-167">Summary/Abstract</a></h1>
<div>Machine learning has been highly successful in data-intensive applications but is often hampered when the data set is small. Recently, Few-Shot Learning ({FSL}) is proposed to tackle this problem. Using prior knowledge, {FSL} can rapidly generalize to new tasks containing only a few samples with supervised information. In this paper, we conduct a thorough survey to fully understand {FSL}. Starting from a formal definition of {FSL}, we distinguish {FSL} from several relevant machine learning problems. We then point out that the core issue in {FSL} is that the empirical risk minimized is unreliable. Based on how prior knowledge can be used to handle this core issue, we categorize {FSL} methods from three perspectives: (i) data, which uses prior knowledge to augment the supervised experience; (ii) model, which uses prior knowledge to reduce the size of the hypothesis space; and (iii) algorithm, which uses prior knowledge to alter the search for the best hypothesis in the given hypothesis space. With this taxonomy, we review and discuss the pros and cons of each category. Promising directions, in the aspects of the {FSL} problem setups, techniques, applications and theories, are also proposed to provide insights for future research.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wang_cordel_2020" class=ref>
<summary class=citation>
<a id="wang_cordel_2020">[wang_cordel_2020]</a> - Wang, Zhengyang and Sisman, Bunyamin and Wei, Hao and Dong, Xin Luna and Ji, Shuiwang - <a href="https://ieeexplore.ieee.org/document/9338287/" target="_blank"><cite>{CorDEL}: A Contrastive Deep Learning Approach for Entity Linkage</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite wang_cordel_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-168" id="summaryabstract-168">Summary/Abstract</a></h1>
<div>Entity linkage ({EL}) is a critical problem in data cleaning and integration. In the past several decades, {EL} has typically been done by rule-based systems or traditional machine learning models with hand-curated features, both of which heavily depend on manual human inputs. With the ever-increasing growth of new data, deep learning ({DL}) based approaches have been proposed to alleviate the high cost of {EL} associated with the traditional models. Existing exploration of {DL} models for {EL} strictly follows the well-known twin-network architecture. However, we argue that the twin-network architecture is sub-optimal to {EL}, leading to inherent drawbacks of existing models. In order to address the drawbacks, we propose a novel and generic contrastive {DL} framework for {EL}. The proposed framework is able to capture both syntactic and semantic matching signals and pays attention to subtle but critical differences. Based on the framework, we develop a contrastive {DL} approach for {EL}, {CORDEL}, with a simple yet powerful variant called {CORDEL}-Sum. We evaluate {CORDEL} with extensive experiments conducted on both public benchmark datasets and a real-world dataset. {CORDEL} outperforms previous state-of-the-art models by 5.2\% on public benchmark datasets. Moreover, {CORDEL} yields a 29.4\% improvement over the current best {DL} model on the real-world dataset, while reducing the number of training parameters by 96.8\%.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wang_machamp_2021" class=ref>
<summary class=citation>
<a id="wang_machamp_2021">[wang_machamp_2021]</a> - Wang, Jin and Li, Yuliang and Hirota, Wataru - <a href="http://arxiv.org/abs/2106.08455" target="_blank"><cite>Machamp: A Generalized Entity Matching Benchmark</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite wang_machamp_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-169" id="summaryabstract-169">Summary/Abstract</a></h1>
<div>Entity Matching ({EM}) refers to the problem of determining whether two different data representations refer to the same real-world entity. It has been a long-standing interest of the data management community and many efforts have been paid in creating benchmark tasks as well as in developing advanced matching techniques. However, existing benchmark tasks for {EM} are limited to the case where the two data collections of entities are structured tables with the same schema. Meanwhile, the data collections for matching could be structured, semi-structured, or unstructured in real-world scenarios of data science. In this paper, we come up with a new research problem -- Generalized Entity Matching to satisfy this requirement and create a benchmark Machamp for it. Machamp consists of seven tasks having diverse characteristics and thus provides good coverage of use cases in real applications. We summarize existing {EM} benchmark tasks for structured tables and conduct a series of processing and cleaning efforts to transform them into matching tasks between tables with different structures. Based on that, we further conduct comprehensive profiling of the proposed benchmark tasks and evaluate popular entity matching approaches on them. With the help of Machamp, it is the first time that researchers can evaluate {EM} techniques between data collections with different structures.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wang_machamp_2021-1" class=ref>
<summary class=citation>
<a id="wang_machamp_2021-1">[wang_machamp_2021-1]</a> - Wang, Jin and Li, Yuliang and Hirota, Wataru - <a href="http://arxiv.org/abs/2106.08455" target="_blank"><cite>Machamp: A Generalized Entity Matching Benchmark</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite wang_machamp_2021-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-170" id="summaryabstract-170">Summary/Abstract</a></h1>
<div>Entity Matching ({EM}) refers to the problem of determining whether two different data representations refer to the same real-world entity. It has been a long-standing interest of the data management community and many efforts have been paid in creating benchmark tasks as well as in developing advanced matching techniques. However, existing benchmark tasks for {EM} are limited to the case where the two data collections of entities are structured tables with the same schema. Meanwhile, the data collections for matching could be structured, semi-structured, or unstructured in real-world scenarios of data science. In this paper, we come up with a new research problem -- Generalized Entity Matching to satisfy this requirement and create a benchmark Machamp for it. Machamp consists of seven tasks having diverse characteristics and thus provides good coverage of use cases in real applications. We summarize existing {EM} benchmark tasks for structured tables and conduct a series of processing and cleaning efforts to transform them into matching tasks between tables with different structures. Based on that, we further conduct comprehensive profiling of the proposed benchmark tasks and evaluate popular entity matching approaches on them. With the help of Machamp, it is the first time that researchers can evaluate {EM} techniques between data collections with different structures.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wang_linformer_2020" class=ref>
<summary class=citation>
<a id="wang_linformer_2020">[wang_linformer_2020]</a> - Wang, Sinong and Li, Belinda Z. and Khabsa, Madian and Fang, Han and Ma, Hao - <a href="http://arxiv.org/abs/2006.04768" target="_blank"><cite>Linformer: Self-Attention with Linear Complexity</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite wang_linformer_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-171" id="summaryabstract-171">Summary/Abstract</a></h1>
<div>Large transformer models have shown extraordinary success in achieving state-of-the-art results in many natural language processing applications. However, training and deploying these models can be prohibitively costly for long sequences, as the standard self-attention mechanism of the Transformer uses \$O(n{\textasciicircum}2)\$ time and space with respect to sequence length. In this paper, we demonstrate that the self-attention mechanism can be approximated by a low-rank matrix. We further exploit this finding to propose a new self-attention mechanism, which reduces the overall self-attention complexity from \$O(n{\textasciicircum}2)\$ to \$O(n)\$ in both time and space. The resulting linear transformer, the {\textbackslash}textit\{Linformer\}, performs on par with standard Transformer models, while being much more memory- and time-efficient.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wang_self-consistency_2023" class=ref>
<summary class=citation>
<a id="wang_self-consistency_2023">[wang_self-consistency_2023]</a> - Wang, Xuezhi and Wei, Jason and Schuurmans, Dale and Le, Quoc and Chi, Ed and Narang, Sharan and Chowdhery, Aakanksha and Zhou, Denny - <a href="http://arxiv.org/abs/2203.11171" target="_blank"><cite>Self-Consistency Improves Chain of Thought Reasoning in Language Models</cite></a>. - 2023. -
<button onclick="copyToClipboard('\{\{ #cite wang_self-consistency_2023 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-172" id="summaryabstract-172">Summary/Abstract</a></h1>
<div>Chain-of-thought prompting combined with pre-trained large language models has achieved encouraging results on complex reasoning tasks. In this paper, we propose a new decoding strategy, self-consistency, to replace the naive greedy decoding used in chain-of-thought prompting. It ﬁrst samples a diverse set of reasoning paths instead of only taking the greedy one, and then selects the most consistent answer by marginalizing out the sampled reasoning paths. Self-consistency leverages the intuition that a complex reasoning problem typically admits multiple different ways of thinking leading to its unique correct answer. Our extensive empirical evaluation shows that self-consistency boosts the performance of chain-of-thought prompting with a striking margin on a range of popular arithmetic and commonsense reasoning benchmarks, including {GSM}8K (+17.9\%), {SVAMP} (+11.0\%), {AQuA} (+12.2\%), {StrategyQA} (+6.4\%) and {ARC}-challenge (+3.9\%).</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wei_nezha_2019" class=ref>
<summary class=citation>
<a id="wei_nezha_2019">[wei_nezha_2019]</a> - Wei, Junqiu and Ren, Xiaozhe and Li, Xiaoguang and Huang, Wenyong and Liao, Yi and Wang, Yasheng and Lin, Jiashu and Jiang, Xin and Chen, Xiao and Liu, Qun - <a href="http://arxiv.org/abs/1909.00204" target="_blank"><cite>{NEZHA}: Neural Contextualized Representation for Chinese Language Understanding</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite wei_nezha_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-173" id="summaryabstract-173">Summary/Abstract</a></h1>
<div>The pre-trained language models have achieved great successes in various natural language understanding ({NLU}) tasks due to its capacity to capture the deep contextualized information in text by pre-training on large-scale corpora. In this technical report, we present our practice of pre-training language models named {NEZHA} ({NEural} {contextualiZed} representation for {CHinese} {lAnguage} understanding) on Chinese corpora and finetuning for the Chinese {NLU} tasks. The current version of {NEZHA} is based on {BERT} with a collection of proven improvements, which include Functional Relative Positional Encoding as an effective positional encoding scheme, Whole Word Masking strategy, Mixed Precision Training and the {LAMB} Optimizer in training the models. The experimental results show that {NEZHA} achieves the state-of-the-art performances when finetuned on several representative Chinese tasks, including named entity recognition (People&#x27;s Daily {NER}), sentence matching ({LCQMC}), Chinese sentiment classification ({ChnSenti}) and natural language inference ({XNLI}).</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wolfram_class_2020" class=ref>
<summary class=citation>
<a id="wolfram_class_2020">[wolfram_class_2020]</a> - Wolfram, Stephen - <a href="http://arxiv.org/abs/2004.08210" target="_blank"><cite>A Class of Models with the Potential to Represent Fundamental Physics</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite wolfram_class_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-174" id="summaryabstract-174">Summary/Abstract</a></h1>
<div>A class of models intended to be as minimal and structureless as possible is introduced. Even in cases with simple rules, rich and complex behavior is found to emerge, and striking correspondences to some important core known features of fundamental physics are seen, suggesting the possibility that the models may provide a new approach to finding a fundamental theory of physics.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wooldridge_brief_2021" class=ref>
<summary class=citation>
<a id="wooldridge_brief_2021">[wooldridge_brief_2021]</a> - Wooldridge, Michael - <cite>A Brief History of Artificial Intelligence: What It Is, Where We Are, and Where We Are Going</cite>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite wooldridge_brief_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-175" id="summaryabstract-175">Summary/Abstract</a></h1>
<div>From Oxford&#x27;s leading {AI} researcher comes a fun and accessible tour through the history and future of one of the most cutting edge and misunderstood field in science: Artificial {IntelligenceThe} somewhat ill-defined long-term aim of {AI} is to build machines that are conscious, self-aware, and sentient; machines capable of the kind of intelligent autonomous action that currently only people are capable of. As an {AI} researcher with 25 years of experience, professor Mike Wooldridge has learned to be obsessively cautious about such claims, while still promoting an intense optimism about the future of the field. There have been genuine scientific breakthroughs that have made {AI} systems possible in the past decade that the founders of the field would have hailed as miraculous. Driverless cars and automated translation tools are just two examples of {AI} technologies that have become a practical, everyday reality in the past few years, and which will have a huge impact on our world.While the dream of conscious machines remains, Professor Wooldridge believes, a distant prospect, the floodgates for {AI} have opened. Wooldridge&#x27;s A Brief History of Artificial Intelligence is an exciting romp through the history of this groundbreaking field--a one-stop-shop for {AI}&#x27;s past, present, and world-changing future.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wu_group_2018" class=ref>
<summary class=citation>
<a id="wu_group_2018">[wu_group_2018]</a> - Wu, Yuxin and He, Kaiming - <a href="http://arxiv.org/abs/1803.08494" target="_blank"><cite>Group Normalization</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite wu_group_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-176" id="summaryabstract-176">Summary/Abstract</a></h1>
<div>Batch Normalization ({BN}) is a milestone technique in the development of deep learning, enabling various networks to train. However, normalizing along the batch dimension introduces problems --- {BN}&#x27;s error increases rapidly when the batch size becomes smaller, caused by inaccurate batch statistics estimation. This limits {BN}&#x27;s usage for training larger models and transferring features to computer vision tasks including detection, segmentation, and video, which require small batches constrained by memory consumption. In this paper, we present Group Normalization ({GN}) as a simple alternative to {BN}. {GN} divides the channels into groups and computes within each group the mean and variance for normalization. {GN}&#x27;s computation is independent of batch sizes, and its accuracy is stable in a wide range of batch sizes. On {ResNet}-50 trained in {ImageNet}, {GN} has 10.6\% lower error than its {BN} counterpart when using a batch size of 2; when using typical batch sizes, {GN} is comparably good with {BN} and outperforms other normalization variants. Moreover, {GN} can be naturally transferred from pre-training to fine-tuning. {GN} can outperform its {BN}-based counterparts for object detection and segmentation in {COCO}, and for video classification in Kinetics, showing that {GN} can effectively replace the powerful {BN} in a variety of tasks. {GN} can be easily implemented by a few lines of code in modern libraries.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wu_incremental_2018" class=ref>
<summary class=citation>
<a id="wu_incremental_2018">[wu_incremental_2018]</a> - Wu, Yue and Chen, Yinpeng and Wang, Lijuan and Ye, Yuancheng and Liu, Zicheng and Guo, Yandong and Zhang, Zhengyou and Fu, Yun - <a href="http://arxiv.org/abs/1802.00853" target="_blank"><cite>Incremental Classifier Learning with Generative Adversarial Networks</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite wu_incremental_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-177" id="summaryabstract-177">Summary/Abstract</a></h1>
<div>In this paper, we address the incremental classifier learning problem, which suffers from catastrophic forgetting. The main reason for catastrophic forgetting is that the past data are not available during learning. Typical approaches keep some exemplars for the past classes and use distillation regularization to retain the classification capability on the past classes and balance the past and new classes. However, there are four main problems with these approaches. First, the loss function is not efficient for classification. Second, there is unbalance problem between the past and new classes. Third, the size of pre-decided exemplars is usually limited and they might not be distinguishable from unseen new classes. Forth, the exemplars may not be allowed to be kept for a long time due to privacy regulations. To address these problems, we propose (a) a new loss function to combine the cross-entropy loss and distillation loss, (b) a simple way to estimate and remove the unbalance between the old and new classes , and (c) using Generative Adversarial Networks ({GANs}) to generate historical data and select representative exemplars during generation. We believe that the data generated by {GANs} have much less privacy issues than real images because {GANs} do not directly copy any real image patches. We evaluate the proposed method on {CIFAR}-100, Flower-102, and {MS}-Celeb-1M-Base datasets and extensive experiments demonstrate the effectiveness of our method.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="wu_lite_2020" class=ref>
<summary class=citation>
<a id="wu_lite_2020">[wu_lite_2020]</a> - Wu, Zhanghao and Liu, Zhijian and Lin, Ji and Lin, Yujun and Han, Song - <a href="http://arxiv.org/abs/2004.11886" target="_blank"><cite>Lite Transformer with Long-Short Range Attention</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite wu_lite_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-178" id="summaryabstract-178">Summary/Abstract</a></h1>
<div>Transformer has become ubiquitous in natural language processing (e.g., machine translation, question answering); however, it requires enormous amount of computations to achieve high performance, which makes it not suitable for mobile applications that are tightly constrained by the hardware resources and battery. In this paper, we present an efficient mobile {NLP} architecture, Lite Transformer to facilitate deploying mobile {NLP} applications on edge devices. The key primitive is the Long-Short Range Attention ({LSRA}), where one group of heads specializes in the local context modeling (by convolution) while another group specializes in the long-distance relationship modeling (by attention). Such specialization brings consistent improvement over the vanilla transformer on three well-established language tasks: machine translation, abstractive summarization, and language modeling. Under constrained resources (500M/100M {MACs}), Lite Transformer outperforms transformer on {WMT}&#x27;14 English-French by 1.2/1.7 {BLEU}, respectively. Lite Transformer reduces the computation of transformer base model by 2.5x with 0.3 {BLEU} score degradation. Combining with pruning and quantization, we further compressed the model size of Lite Transformer by 18.2x. For language modeling, Lite Transformer achieves 1.8 lower perplexity than the transformer at around 500M {MACs}. Notably, Lite Transformer outperforms the {AutoML}-based Evolved Transformer by 0.5 higher {BLEU} for the mobile {NLP} setting without the costly architecture search that requires more than 250 {GPU} years. Code has been made available at https://github.com/mit-han-lab/lite-transformer.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="xie_adversarial_nodate" class=ref>
<summary class=citation>
<a id="xie_adversarial_nodate">[xie_adversarial_nodate]</a> - Xie, Cihang and Tan, Mingxing and Gong, Boqing and Wang, Jiang and Yuille, Alan and Le, Quoc V - <cite>Adversarial Examples Improve Image Recognition</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite xie_adversarial_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-179" id="summaryabstract-179">Summary/Abstract</a></h1>
<div>Adversarial examples are commonly viewed as a threat to {ConvNets}. Here we present an opposite perspective: adversarial examples can be used to improve image recognition models if harnessed in the right manner. We propose {AdvProp}, an enhanced adversarial training scheme which treats adversarial examples as additional examples, to prevent overﬁtting. Key to our method is the usage of a separate auxiliary batch norm for adversarial examples, as they have different underlying distributions to normal examples. We show that {AdvProp} improves a wide range of models on various image recognition tasks and performs better when the models are bigger. For instance, by applying {AdvProp} to the latest {EfﬁcientNet}-B7 [28] on {ImageNet}, we achieve signiﬁcant improvements on {ImageNet} (+0.7\%), {ImageNet}-C (+6.5\%), {ImageNet}-A (+7.0\%), {StylizedImageNet} (+4.8\%). With an enhanced {EfﬁcientNet}-B8, our method achieves the state-of-the-art 85.5\% {ImageNet} top-1 accuracy without extra data. This result even surpasses the best model in [20] which is trained with 3.5B Instagram images (∼3000× more than {ImageNet}) and ∼9.4× more parameters. Models are available at https://github.com/tensorflow/tpu/tree/ master/models/official/efficientnet.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="yang_finbert_2020" class=ref>
<summary class=citation>
<a id="yang_finbert_2020">[yang_finbert_2020]</a> - Yang, Yi and {UY}, Mark Christopher Siy and Huang, Allen - <a href="http://arxiv.org/abs/2006.08097" target="_blank"><cite>{FinBERT}: A Pretrained Language Model for Financial Communications</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite yang_finbert_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-180" id="summaryabstract-180">Summary/Abstract</a></h1>
<div>Contextual pretrained language models, such as {BERT} (Devlin et al., 2019), have made significant breakthrough in various {NLP} tasks by training on large scale of unlabeled text re-sources.Financial sector also accumulates large amount of financial communication text.However, there is no pretrained finance specific language models available. In this work,we address the need by pretraining a financial domain specific {BERT} models, {FinBERT}, using a large scale of financial communication corpora. Experiments on three financial sentiment classification tasks confirm the advantage of {FinBERT} over generic domain {BERT} model. The code and pretrained models are available at https://github.com/yya518/{FinBERT}. We hope this will be useful for practitioners and researchers working on financial {NLP} tasks.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="yasunaga_large_2024" class=ref>
<summary class=citation>
<a id="yasunaga_large_2024">[yasunaga_large_2024]</a> - Yasunaga, Michihiro and Chen, Xinyun and Li, Yujia and Pasupat, Panupong and Leskovec, Jure and Liang, Percy and Chi, Ed H. and Zhou, Denny - <a href="http://arxiv.org/abs/2310.01714" target="_blank"><cite>Large Language Models as Analogical Reasoners</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite yasunaga_large_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-181" id="summaryabstract-181">Summary/Abstract</a></h1>
<div>Chain-of-thought ({CoT}) prompting for language models demonstrates impressive performance across reasoning tasks, but typically needs labeled exemplars of the reasoning process. In this work, we introduce a new prompting approach, analogical prompting, designed to automatically guide the reasoning process of large language models. Inspired by analogical reasoning, a cognitive process in which humans draw from relevant past experiences to tackle new problems, our approach prompts language models to self-generate relevant exemplars or knowledge in the context, before proceeding to solve the given problem. This method presents several advantages: it obviates the need for labeling or retrieving exemplars, offering generality and convenience; it can also tailor the generated exemplars and knowledge to each problem, offering adaptability. Experimental results show that our approach outperforms 0-shot {CoT} and manual fewshot {CoT} in a variety of reasoning tasks, including math problem solving in {GSM}8K and {MATH}, code generation in Codeforces, and other reasoning tasks in {BIG}-Bench.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zaheer_big_2020" class=ref>
<summary class=citation>
<a id="zaheer_big_2020">[zaheer_big_2020]</a> - Zaheer, Manzil and Guruganesh, Guru and Dubey, Avinava and Ainslie, Joshua and Alberti, Chris and Ontanon, Santiago and Pham, Philip and Ravula, Anirudh and Wang, Qifan and Yang, Li and Ahmed, Amr - <a href="http://arxiv.org/abs/2007.14062" target="_blank"><cite>Big Bird: Transformers for Longer Sequences</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite zaheer_big_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-182" id="summaryabstract-182">Summary/Abstract</a></h1>
<div>Transformers-based models, such as {BERT}, have been one of the most successful deep learning models for {NLP}. Unfortunately, one of their core limitations is the quadratic dependency (mainly in terms of memory) on the sequence length due to their full attention mechanism. To remedy this, we propose, {BigBird}, a sparse attention mechanism that reduces this quadratic dependency to linear. We show that {BigBird} is a universal approximator of sequence functions and is Turing complete, thereby preserving these properties of the quadratic, full attention model. Along the way, our theoretical analysis reveals some of the benefits of having \$O(1)\$ global tokens (such as {CLS}), that attend to the entire sequence as part of the sparse attention mechanism. The proposed sparse attention can handle sequences of length up to 8x of what was previously possible using similar hardware. As a consequence of the capability to handle longer context, {BigBird} drastically improves performance on various {NLP} tasks such as question answering and summarization. We also propose novel applications to genomics data.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zelikman_star_2022" class=ref>
<summary class=citation>
<a id="zelikman_star_2022">[zelikman_star_2022]</a> - Zelikman, Eric and Wu, Yuhuai and Mu, Jesse and Goodman, Noah D. - <a href="http://arxiv.org/abs/2203.14465" target="_blank"><cite>{STaR}: Bootstrapping Reasoning With Reasoning</cite></a>. - 2022. -
<button onclick="copyToClipboard('\{\{ #cite zelikman_star_2022 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-183" id="summaryabstract-183">Summary/Abstract</a></h1>
<div>Generating step-by-step chain-of-thought rationales improves language model performance on complex reasoning tasks like mathematics or commonsense question-answering. However, inducing language model rationale generation currently requires either constructing massive rationale datasets or sacrificing accuracy by using only few-shot inference. We propose a technique to iteratively leverage a small number of rationale examples and a large dataset without rationales, to bootstrap the ability to perform successively more complex reasoning. This technique, the Self-Taught Reasoner ({STaR}), relies on a simple loop: generate rationales to answer many questions, prompted with a few rationale examples; if the generated answers are wrong, try again to generate a rationale given the correct answer; fine-tune on all the rationales that ultimately yielded correct answers; repeat. We show that {STaR} significantly improves performance on multiple datasets compared to a model fine-tuned to directly predict final answers, and performs comparably to fine-tuning a 30\${\textbackslash}times\$ larger state-of-the-art language model on {CommensenseQA}. Thus, {STaR} lets a model improve itself by learning from its own generated reasoning.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zelikman_quiet-star_2024" class=ref>
<summary class=citation>
<a id="zelikman_quiet-star_2024">[zelikman_quiet-star_2024]</a> - Zelikman, Eric and Harik, Georges and Shao, Yijia and Jayasiri, Varuna and Haber, Nick and Goodman, Noah D. - <a href="http://arxiv.org/abs/2403.09629" target="_blank"><cite>Quiet-{STaR}: Language Models Can Teach Themselves to Think Before Speaking</cite></a>. - 2024. -
<button onclick="copyToClipboard('\{\{ #cite zelikman_quiet-star_2024 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-184" id="summaryabstract-184">Summary/Abstract</a></h1>
<div>When writing and talking, people sometimes pause to think. Although reasoning-focused works have often framed reasoning as a method of answering questions or completing agentic tasks, reasoning is implicit in almost all written text. For example, this applies to the steps not stated between the lines of a proof or to the theory of mind underlying a conversation. In the Self-Taught Reasoner ({STaR}, Zelikman et al. 2022), useful thinking is learned by inferring rationales from few-shot examples in question-answering and learning from those that lead to a correct answer. This is a highly constrained setting -- ideally, a language model could instead learn to infer unstated rationales in arbitrary text. We present Quiet-{STaR}, a generalization of {STaR} in which {LMs} learn to generate rationales at each token to explain future text, improving their predictions. We address key challenges, including 1) the computational cost of generating continuations, 2) the fact that the {LM} does not initially know how to generate or use internal thoughts, and 3) the need to predict beyond individual next tokens. To resolve these, we propose a tokenwise parallel sampling algorithm, using learnable tokens indicating a thought&#x27;s start and end, and an extended teacher-forcing technique. Encouragingly, generated rationales disproportionately help model difficult-to-predict tokens and improve the {LM}&#x27;s ability to directly answer difficult questions. In particular, after continued pretraining of an {LM} on a corpus of internet text with Quiet-{STaR}, we find zero-shot improvements on {GSM}8K (5.9\%\${\textbackslash}rightarrow\$10.9\%) and {CommonsenseQA} (36.3\%\${\textbackslash}rightarrow\$47.2\%) and observe a perplexity improvement of difficult tokens in natural text. Crucially, these improvements require no fine-tuning on these tasks. Quiet-{STaR} marks a step towards {LMs} that can learn to reason in a more general and scalable way.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zenke_continual_2017" class=ref>
<summary class=citation>
<a id="zenke_continual_2017">[zenke_continual_2017]</a> - Zenke, Friedemann and Poole, Ben and Ganguli, Surya - <a href="https://arxiv.org/abs/1703.04200v3" target="_blank"><cite>Continual Learning Through Synaptic Intelligence</cite></a>. - 2017. -
<button onclick="copyToClipboard('\{\{ #cite zenke_continual_2017 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-185" id="summaryabstract-185">Summary/Abstract</a></h1>
<div>While deep learning has led to remarkable advances across diverse
applications, it struggles in domains where the data distribution changes over
the course of learning. In stark contrast, biological neural networks
continually adapt to changing domains, possibly by leveraging complex molecular
machinery to solve many tasks simultaneously. In this study, we introduce
intelligent synapses that bring some of this biological complexity into
artificial neural networks. Each synapse accumulates task relevant information
over time, and exploits this information to rapidly store new memories without
forgetting old ones. We evaluate our approach on continual learning of
classification tasks, and show that it dramatically reduces forgetting while
maintaining computational efficiency.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zhang_dive_nodate" class=ref>
<summary class=citation>
<a id="zhang_dive_nodate">[zhang_dive_nodate]</a> - Zhang, Aston and Lipton, Zachary C and Li, Mu and Smola, Alexander J - <cite>Dive into Deep Learning</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite zhang_dive_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-186" id="summaryabstract-186">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zhao_how_2020" class=ref>
<summary class=citation>
<a id="zhao_how_2020">[zhao_how_2020]</a> - Zhao, Yiyun and Bethard, Steven - <a href="https://www.aclweb.org/anthology/2020.acl-main.429" target="_blank"><cite>How does {BERT}&#x27;s attention change when you fine-tune? An analysis methodology and a case study in negation scope</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite zhao_how_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-187" id="summaryabstract-187">Summary/Abstract</a></h1>
<div>Large pretrained language models like {BERT}, after fine-tuning to a downstream task, have achieved high performance on a variety of {NLP} problems. Yet explaining their decisions is difficult despite recent work probing their internal representations. We propose a procedure and analysis methods that take a hypothesis of how a transformer-based model might encode a linguistic phenomenon, and test the validity of that hypothesis based on a comparison between knowledge-related downstream tasks with downstream control tasks, and measurement of cross-dataset consistency. We apply this methodology to test {BERT} and {RoBERTa} on a hypothesis that some attention heads will consistently attend from a word in negation scope to the negation cue. We find that after fine-tuning {BERT} and {RoBERTa} on a negation scope task, the average attention head improves its sensitivity to negation and its attention consistency across negation datasets compared to the pre-trained models. However, only the base models (not the large models) improve compared to a control task, indicating there is evidence for a shallow encoding of negation only in the base models.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zhou_least--most_2023" class=ref>
<summary class=citation>
<a id="zhou_least--most_2023">[zhou_least--most_2023]</a> - Zhou, Denny and Schärli, Nathanael and Hou, Le and Wei, Jason and Scales, Nathan and Wang, Xuezhi and Schuurmans, Dale and Cui, Claire and Bousquet, Olivier and Le, Quoc and Chi, Ed - <a href="http://arxiv.org/abs/2205.10625" target="_blank"><cite>Least-to-Most Prompting Enables Complex Reasoning in Large Language Models</cite></a>. - 2023. -
<button onclick="copyToClipboard('\{\{ #cite zhou_least--most_2023 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-188" id="summaryabstract-188">Summary/Abstract</a></h1>
<div>Chain-of-thought prompting has demonstrated remarkable performance on various natural language reasoning tasks. However, it tends to perform poorly on tasks which requires solving problems harder than the exemplars shown in the prompts. To overcome this challenge of easy-to-hard generalization, we propose a novel prompting strategy, least-to-most prompting. The key idea in this strategy is to break down a complex problem into a series of simpler subproblems and then solve them in sequence. Solving each subproblem is facilitated by the answers to previously solved subproblems. Our experimental results on tasks related to symbolic manipulation, compositional generalization, and math reasoning reveal that least-to-most prompting is capable of generalizing to more difﬁcult problems than those seen in the prompts. A notable ﬁnding is that when the {GPT}-3 code-davinci-002 model is used with least-to-most prompting, it can solve the compositional generalization benchmark {SCAN} in any split (including length split) with an accuracy of at least 99\% using just 14 exemplars, compared to only 16\% accuracy with chain-of-thought prompting. This is particularly noteworthy because neural-symbolic models in the literature that specialize in solving {SCAN} are trained on the entire training set containing over 15,000 examples. We have included prompts for all the tasks in the Appendix.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zhu_freelb_2019" class=ref>
<summary class=citation>
<a id="zhu_freelb_2019">[zhu_freelb_2019]</a> - Zhu, Chen and Cheng, Yu and Gan, Zhe and Sun, Siqi and Goldstein, Tom and Liu, Jingjing - <a href="http://arxiv.org/abs/1909.11764" target="_blank"><cite>{FreeLB}: Enhanced Adversarial Training for Language Understanding</cite></a>. - 2019. -
<button onclick="copyToClipboard('\{\{ #cite zhu_freelb_2019 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-189" id="summaryabstract-189">Summary/Abstract</a></h1>
<div>Adversarial training, which minimizes the maximal risk for label-preserving input perturbations, has proved to be effective for improving the generalization of language models. In this work, we propose a novel adversarial training algorithm - {FreeLB}, that promotes higher robustness and invariance in the embedding space, by adding adversarial perturbations to word embeddings and minimizing the resultant adversarial risk inside different regions around input samples. To validate the effectiveness of the proposed approach, we apply it to Transformer-based models for natural language understanding and commonsense reasoning tasks. Experiments on the {GLUE} benchmark show that when applied only to the finetuning stage, it is able to improve the overall test scores of {BERT}-based model from 78.3 to 79.4, and {RoBERTa}-large model from 88.5 to 88.8. In addition, the proposed approach achieves state-of-the-art single-model test accuracies of 85.44\% and 67.75\% on {ARC}-Easy and {ARC}-Challenge. Experiments on {CommonsenseQA} benchmark further demonstrate that {FreeLB} can be generalized and boost the performance of {RoBERTa}-large model on other tasks as well.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zhu_transfer_2020" class=ref>
<summary class=citation>
<a id="zhu_transfer_2020">[zhu_transfer_2020]</a> - Zhu, Zhuangdi and Lin, Kaixiang and Zhou, Jiayu - <a href="http://arxiv.org/abs/2009.07888" target="_blank"><cite>Transfer Learning in Deep Reinforcement Learning: A Survey</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite zhu_transfer_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-190" id="summaryabstract-190">Summary/Abstract</a></h1>
<div>This paper surveys the field of transfer learning in the problem setting of Reinforcement Learning ({RL}). {RL} has been a key solution to sequential decision-making problems. Along with the fast advances of {RL} in various domains, such as robotics and game-playing, transfer learning arises as an important technique to assist {RL} by leveraging and transferring external expertise to boost the learning process of {RL}. In this survey, we review the central issues of transfer learning in the {RL} domain, providing a systematic categorization of its state-of-the-art techniques. We analyze their goals, methodologies, applications, and the {RL} frameworks under which the transfer learning techniques are approachable. We discuss the relationship between transfer learning and other relevant topics from the {RL} perspective and also explore the potential challenges as well as future development directions for transfer learning in {RL}.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="zhuang_comprehensive_2020" class=ref>
<summary class=citation>
<a id="zhuang_comprehensive_2020">[zhuang_comprehensive_2020]</a> - Zhuang, Fuzhen and Qi, Zhiyuan and Duan, Keyu and Xi, Dongbo and Zhu, Yongchun and Zhu, Hengshu and Xiong, Hui and He, Qing - <a href="http://arxiv.org/abs/1911.02685" target="_blank"><cite>A Comprehensive Survey on Transfer Learning</cite></a>. - 2020. -
<button onclick="copyToClipboard('\{\{ #cite zhuang_comprehensive_2020 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-191" id="summaryabstract-191">Summary/Abstract</a></h1>
<div>Transfer learning aims at improving the performance of target learners on target domains by transferring the knowledge contained in different but related source domains. In this way, the dependence on a large number of target domain data can be reduced for constructing target learners. Due to the wide application prospects, transfer learning has become a popular and promising area in machine learning. Although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances in transfer learning. Due to the rapid expansion of the transfer learning area, it is both necessary and challenging to comprehensively review the relevant studies. This survey attempts to connect and systematize the existing transfer learning researches, as well as to summarize and interpret the mechanisms and the strategies of transfer learning in a comprehensive way, which may help readers have a better understanding of the current research status and ideas. Unlike previous surveys, this survey paper reviews more than forty representative transfer learning approaches, especially homogeneous transfer learning approaches, from the perspectives of data and model. The applications of transfer learning are also briefly introduced. In order to show the performance of different transfer learning models, over twenty representative transfer learning models are used for experiments. The models are performed on three different datasets, i.e., Amazon Reviews, Reuters-21578, and Office-31. And the experimental results demonstrate the importance of selecting appropriate transfer learning models for different applications in practice.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_using_nodate" class=ref>
<summary class=citation>
<a id="noauthor_using_nodate">[noauthor_using_nodate]</a> - N/A - <a href="https://www.confluent.io/blog/using-apache-kafka-drive-cutting-edge-machine-learning" target="_blank"><cite>Using Apache Kafka to Drive Cutting-Edge Machine Learning {\textbar} Confluent</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_using_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-192" id="summaryabstract-192">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_enforcing_nodate" class=ref>
<summary class=citation>
<a id="noauthor_enforcing_nodate">[noauthor_enforcing_nodate]</a> - N/A - <a href="https://stackoverflow.com/questions/19534896/enforcing-python-version-in-setup-py" target="_blank"><cite>Enforcing python version in setup.py</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_enforcing_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-193" id="summaryabstract-193">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_improvements_2018" class=ref>
<summary class=citation>
<a id="noauthor_improvements_2018">[noauthor_improvements_2018]</a> - N/A - <a href="https://www.freecodecamp.org/news/improvements-in-deep-q-learning-dueling-double-dqn-prioritized-experience-replay-and-fixed-58b130cc5682/" target="_blank"><cite>Improvements in Deep Q Learning: Dueling Double {DQN}, Prioritized Experience Replay, and fixed…</cite></a>. - 2018. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_improvements_2018 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-194" id="summaryabstract-194">Summary/Abstract</a></h1>
<div>by Thomas Simonini
<p>Improvements in Deep Q Learning: Dueling Double {DQN}, Prioritized Experience
Replay, and fixed Q-targets
{\textgreater} This article is part of Deep Reinforcement Learning Course with Tensorflow ?️.
Check the syllabus here.
[https://simoninithomas.github.io/Deep_reinforcement_learning_Course/]
In our last article about Deep Q Learning with Tensorflow
[https://medium.freecodecamp.org/an-introduction-to-deep-q-learning-lets-play-doom-54d02d8017d8]
, we implemented an agent that learns to pla</div></p>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_more_nodate" class=ref>
<summary class=citation>
<a id="noauthor_more_nodate">[noauthor_more_nodate]</a> - N/A - <a href="http://ai.googleblog.com/2020/03/more-efficient-nlp-model-pre-training.html" target="_blank"><cite>More Efficient {NLP} Model Pre-training with {ELECTRA}</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_more_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-195" id="summaryabstract-195">Summary/Abstract</a></h1>
<div>Posted by Kevin Clark, Student Researcher and Thang Luong, Senior Research Scientist, Google Research, Brain Team   Recent advances in langu...</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_state_nodate" class=ref>
<summary class=citation>
<a id="noauthor_state_nodate">[noauthor_state_nodate]</a> - N/A - <a href="https://ruder.io/state-of-transfer-learning-in-nlp/" target="_blank"><cite>The State of Transfer Learning in {NLP}</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_state_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-196" id="summaryabstract-196">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_ganfather_nodate" class=ref>
<summary class=citation>
<a id="noauthor_ganfather_nodate">[noauthor_ganfather_nodate]</a> - N/A - <a href="https://www.technologyreview.com/2018/02/21/145289/the-ganfather-the-man-whos-given-machines-the-gift-of-imagination/" target="_blank"><cite>The {GANfather}: The man who’s given machines the gift of imagination</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_ganfather_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-197" id="summaryabstract-197">Summary/Abstract</a></h1>
<div>One night in 2014, Ian Goodfellow went drinking to celebrate with a fellow doctoral student who had just graduated. At Les 3 Brasseurs (The Three Brewers), a favorite Montreal watering hole, some friends asked for his help with a thorny project they were working on: a computer that could create photos by itself. Researchers were…</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_explainable_nodate" class=ref>
<summary class=citation>
<a id="noauthor_explainable_nodate">[noauthor_explainable_nodate]</a> - N/A - <a href="https://www.darpa.mil/program/explainable-artificial-intelligence" target="_blank"><cite>Explainable Artificial Intelligence</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_explainable_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-198" id="summaryabstract-198">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_introduction_nodate" class=ref>
<summary class=citation>
<a id="noauthor_introduction_nodate">[noauthor_introduction_nodate]</a> - N/A - <a href="https://www.coursera.org/learn/negotiation/home/week/2" target="_blank"><cite>Introduction to Negotiation: A Strategic Playbook for Becoming a Principled and Persuasive Negotiator - Negotiation Caselets</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_introduction_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-199" id="summaryabstract-199">Summary/Abstract</a></h1>
<div>You&#x27;ve got the theory. Now let&#x27;s use it. I&#x27;ll show how the pie framework applies to some mini cases, or caselets. The Merger Case considers how the synergy gains from a merger will be shared by the two parties. While this is still a stylized ...</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_contrastive_nodate" class=ref>
<summary class=citation>
<a id="noauthor_contrastive_nodate">[noauthor_contrastive_nodate]</a> - N/A - <a href="https://www.amazon.science/publications/contrastive-entity-linkage-mining-variational-attributes-from-large-catalogs-for-entity-linkage" target="_blank"><cite>Contrastive entity linkage: Mining variational attributes from large catalogs for entity linkage</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_contrastive_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-200" id="summaryabstract-200">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_collective_nodate" class=ref>
<summary class=citation>
<a id="noauthor_collective_nodate">[noauthor_collective_nodate]</a> - N/A - <a href="https://www.amazon.science/publications/collective-knowledge-graph-multi-type-entity-alignment" target="_blank"><cite>Collective knowledge graph multi-type entity alignment</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_collective_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-201" id="summaryabstract-201">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_notitle_nodate" class=ref>
<summary class=citation>
<a id="noauthor_notitle_nodate">[noauthor_notitle_nodate]</a> - N/A - <cite>Not Found</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_notitle_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-202" id="summaryabstract-202">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_notitle_nodate-1" class=ref>
<summary class=citation>
<a id="noauthor_notitle_nodate-1">[noauthor_notitle_nodate-1]</a> - N/A - <cite>Not Found</cite>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_notitle_nodate-1 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-203" id="summaryabstract-203">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_papers_nodate" class=ref>
<summary class=citation>
<a id="noauthor_papers_nodate">[noauthor_papers_nodate]</a> - N/A - <a href="https://paperswithcode.com/paper/profiling-entity-matching-benchmark-tasks" target="_blank"><cite>Papers with Code - Profiling Entity Matching Benchmark Tasks</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_papers_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-204" id="summaryabstract-204">Summary/Abstract</a></h1>
<div>\#2 best model for Entity Resolution on Amazon-Google (F1 (\%) metric)</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_red_2021" class=ref>
<summary class=citation>
<a id="noauthor_red_2021">[noauthor_red_2021]</a> - N/A - <a href="https://mattturck.com/data2021/" target="_blank"><cite>Red Hot: The 2021 Machine Learning, {AI} and Data ({MAD}) Landscape</cite></a>. - 2021. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_red_2021 \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-205" id="summaryabstract-205">Summary/Abstract</a></h1>
<div>Full resolution version of the landscape image here
<p>It’s been a hot, hot year in the world of data, machine learning and {AI}. </p>
<p>Just when you thought it couldn’t grow any more explosively, the data/{AI} landscape just did: rapid pace of company creation, exciting new product and project launch</div></p>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_220402311_nodate" class=ref>
<summary class=citation>
<a id="noauthor_220402311_nodate">[noauthor_220402311_nodate]</a> - N/A - <a href="https://arxiv.org/abs/2204.02311" target="_blank"><cite>[2204.02311] {PaLM}: Scaling Language Modeling with Pathways</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_220402311_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-206" id="summaryabstract-206">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_being_nodate" class=ref>
<summary class=citation>
<a id="noauthor_being_nodate">[noauthor_being_nodate]</a> - N/A - <a href="https://www.amazon.com/Being-You-New-Science-Consciousness/dp/1524742872/ref&#x3D;tmm_hrd_swatch_0?_encoding&#x3D;UTF8&amp;qid&#x3D;1695506152&amp;sr&#x3D;1-4" target="_blank"><cite>Being You: A New Science of Consciousness: Seth, Anil: 9781524742874: Amazon.com: Books</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_being_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-207" id="summaryabstract-207">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_experience_nodate" class=ref>
<summary class=citation>
<a id="noauthor_experience_nodate">[noauthor_experience_nodate]</a> - N/A - <a href="https://www.amazon.com/Experience-Machine-Minds-Predict-Reality/dp/1524748455/ref&#x3D;tmm_hrd_swatch_0?_encoding&#x3D;UTF8&amp;qid&#x3D;1695506203&amp;sr&#x3D;1-1" target="_blank"><cite>The Experience Machine: How Our Minds Predict and Shape Reality: Clark, Andy: 9781524748456: Amazon.com: Books</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_experience_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-208" id="summaryabstract-208">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_nebulagraph_nodate" class=ref>
<summary class=citation>
<a id="noauthor_nebulagraph_nodate">[noauthor_nebulagraph_nodate]</a> - N/A - <a href="https://www.nebula-graph.io/posts/graph-RAG" target="_blank"><cite>{NebulaGraph} Launches Industry-First Graph {RAG}: Retrieval-Augmented Generation with {LLM} Based on Knowledge Graphs</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_nebulagraph_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-209" id="summaryabstract-209">Summary/Abstract</a></h1>
<div>{NebulaGraph} database&#x27;s revolutionary Graph {RAG} (Retrieval-Augmented Generation) technique, which combines knowledge graphs with a large language model to provide more cost-effective, intelligent, and precise search results.</div>
</section>
</details>
</div>
<br/>
<div class="bib_div">
<details data-key="noauthor_200208909_nodate" class=ref>
<summary class=citation>
<a id="noauthor_200208909_nodate">[noauthor_200208909_nodate]</a> - N/A - <a href="https://arxiv.org/abs/2002.08909" target="_blank"><cite>[2002.08909] {REALM}: Retrieval-Augmented Language Model Pre-Training</cite></a>. - N/A. -
<button onclick="copyToClipboard('\{\{ #cite noauthor_200208909_nodate \}\}')">Copy citation_key</button>
</summary>
<section class=abstract>
<h1><a class="header" href="#summaryabstract-210" id="summaryabstract-210">Summary/Abstract</a></h1>
<div>N/A</div>
</section>
</details>
</div>
<br/>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>
        
        

    </body>
</html>
