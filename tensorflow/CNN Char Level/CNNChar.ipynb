{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class CharCNN(object):\n",
    "\n",
    "    def __init__(self,\n",
    "                 num_classes=2, \n",
    "                 filter_sizes=(7, 7, 3, 3, 3, 3), \n",
    "                 num_filters_per_size=256,\n",
    "                 l2_reg_lambda=0.0, \n",
    "                 sequence_max_length=1014, \n",
    "                 num_quantized_chars=70):\n",
    "\n",
    "        # Placeholders for input, output and dropout\n",
    "        self.input_x = tf.placeholder(tf.float32, [None, num_quantized_chars, sequence_max_length, 1], name=\"input_x\")\n",
    "        self.input_y = tf.placeholder(tf.float32, [None, num_classes], name=\"input_y\")\n",
    "        self.dropout_keep_prob = tf.placeholder(tf.float32, name=\"dropout_keep_prob\")\n",
    "\n",
    "        # Keeping track of l2 regularization loss (optional)\n",
    "        l2_loss = tf.constant(0.0)\n",
    "\n",
    "        # ================ Layer 1 ================\n",
    "        with tf.name_scope(\"conv-maxpool-1\"):\n",
    "            filter_shape = [num_quantized_chars, filter_sizes[0], 1, num_filters_per_size]\n",
    "            W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.05), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_filters_per_size]), name=\"b\")\n",
    "            conv = tf.nn.conv2d(self.input_x, W, strides=[1, 1, 1, 1], padding=\"VALID\", name=\"conv1\")\n",
    "            h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "            pooled = tf.nn.max_pool(\n",
    "                h,\n",
    "                ksize=[1, 1, 3, 1],\n",
    "                strides=[1, 1, 3, 1],\n",
    "                padding='VALID',\n",
    "                name=\"pool1\")\n",
    "\n",
    "        # ================ Layer 2 ================\n",
    "        with tf.name_scope(\"conv-maxpool-2\"):\n",
    "            filter_shape = [1, filter_sizes[1], num_filters_per_size, num_filters_per_size]\n",
    "            W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.05), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_filters_per_size]), name=\"b\")\n",
    "            conv = tf.nn.conv2d(pooled, W, strides=[1, 1, 1, 1], padding=\"VALID\", name=\"conv2\")\n",
    "            h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "            pooled = tf.nn.max_pool(\n",
    "                h,\n",
    "                ksize=[1, 1, 3, 1],\n",
    "                strides=[1, 1, 3, 1],\n",
    "                padding='VALID',\n",
    "                name=\"pool2\")\n",
    "\n",
    "        # ================ Layer 3 ================\n",
    "        with tf.name_scope(\"conv-3\"):\n",
    "            filter_shape = [1, filter_sizes[2], num_filters_per_size, num_filters_per_size]\n",
    "            W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.05), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_filters_per_size]), name=\"b\")\n",
    "            conv = tf.nn.conv2d(pooled, W, strides=[1, 1, 1, 1], padding=\"VALID\", name=\"conv3\")\n",
    "            h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "\n",
    "        # ================ Layer 4 ================\n",
    "        with tf.name_scope(\"conv-4\"):\n",
    "            filter_shape = [1, filter_sizes[3], num_filters_per_size, num_filters_per_size]\n",
    "            W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.05), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_filters_per_size]), name=\"b\")\n",
    "            conv = tf.nn.conv2d(h, W, strides=[1, 1, 1, 1], padding=\"VALID\", name=\"conv4\")\n",
    "            h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "\n",
    "        # ================ Layer 5 ================\n",
    "        with tf.name_scope(\"conv-5\"):\n",
    "            filter_shape = [1, filter_sizes[4], num_filters_per_size, num_filters_per_size]\n",
    "            W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.05), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_filters_per_size]), name=\"b\")\n",
    "            conv = tf.nn.conv2d(h, W, strides=[1, 1, 1, 1], padding=\"VALID\", name=\"conv5\")\n",
    "            h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "\n",
    "        # ================ Layer 6 ================\n",
    "        with tf.name_scope(\"conv-maxpool-6\"):\n",
    "            filter_shape = [1, filter_sizes[5], num_filters_per_size, num_filters_per_size]\n",
    "            W = tf.Variable(tf.truncated_normal(filter_shape, stddev=0.05), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_filters_per_size]), name=\"b\")\n",
    "            conv = tf.nn.conv2d(h, W, strides=[1, 1, 1, 1], padding=\"VALID\", name=\"conv6\")\n",
    "            h = tf.nn.relu(tf.nn.bias_add(conv, b), name=\"relu\")\n",
    "            pooled = tf.nn.max_pool(\n",
    "                h,\n",
    "                ksize=[1, 1, 3, 1],\n",
    "                strides=[1, 1, 3, 1],\n",
    "                padding='VALID',\n",
    "                name=\"pool6\")\n",
    "\n",
    "        # ================ Layer 7 ================\n",
    "        num_features_total = 34 * num_filters_per_size\n",
    "        h_pool_flat = tf.reshape(pooled, [-1, num_features_total])\n",
    "\n",
    "        # Add dropout\n",
    "        with tf.name_scope(\"dropout-1\"):\n",
    "            drop1 = tf.nn.dropout(h_pool_flat, self.dropout_keep_prob)\n",
    "\n",
    "        # Fully connected layer 1\n",
    "        with tf.name_scope(\"fc-1\"):\n",
    "            W = tf.Variable(tf.truncated_normal([num_features_total, 1024], stddev=0.05), name=\"W\")\n",
    "            # W = tf.get_variable(\"W\", shape=[num_features_total, 1024],\n",
    "            #                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[1024]), name=\"b\")\n",
    "            # l2_loss += tf.nn.l2_loss(W)\n",
    "            # l2_loss += tf.nn.l2_loss(b)\n",
    "\n",
    "            fc_1_output = tf.nn.relu(tf.nn.xw_plus_b(drop1, W, b), name=\"fc-1-out\")\n",
    "\n",
    "        # ================ Layer 8 ================\n",
    "        # Add dropout\n",
    "        with tf.name_scope(\"dropout-2\"):\n",
    "            drop2 = tf.nn.dropout(fc_1_output, self.dropout_keep_prob)\n",
    "\n",
    "        # Fully connected layer 2\n",
    "        with tf.name_scope(\"fc-2\"):\n",
    "            W = tf.Variable(tf.truncated_normal([1024, 1024], stddev=0.05), name=\"W\")\n",
    "            # W = tf.get_variable(\"W\", shape=[1024, 1024],\n",
    "            #                     initializer=tf.contrib.layers.xavier_initializer())\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[1024]), name=\"b\")\n",
    "            # l2_loss += tf.nn.l2_loss(W)\n",
    "            # l2_loss += tf.nn.l2_loss(b)\n",
    "\n",
    "            fc_2_output = tf.nn.relu(tf.nn.xw_plus_b(drop2, W, b), name=\"fc-2-out\")\n",
    "\n",
    "        # ================ Layer 9 ================\n",
    "        # Fully connected layer 3\n",
    "        with tf.name_scope(\"fc-3\"):\n",
    "            W = tf.Variable(tf.truncated_normal([1024, num_classes], stddev=0.05), name=\"W\")\n",
    "            b = tf.Variable(tf.constant(0.1, shape=[num_classes]), name=\"b\")\n",
    "            # l2_loss += tf.nn.l2_loss(W)\n",
    "            # l2_loss += tf.nn.l2_loss(b)\n",
    "\n",
    "            scores = tf.nn.xw_plus_b(fc_2_output, W, b, name=\"output\")\n",
    "            predictions = tf.argmax(scores, 1, name=\"predictions\")\n",
    "        # ================ Loss and Accuracy ================\n",
    "        # CalculateMean cross-entropy loss\n",
    "        with tf.name_scope(\"loss\"):\n",
    "            losses = tf.nn.softmax_cross_entropy_with_logits(logits=scores, labels=self.input_y)\n",
    "            self.loss = tf.reduce_mean(losses) + l2_reg_lambda * l2_loss\n",
    "\n",
    "        # Accuracy\n",
    "        with tf.name_scope(\"accuracy\"):\n",
    "            correct_predictions = tf.equal(predictions, tf.argmax(self.input_y, 1))\n",
    "            self.accuracy = tf.reduce_mean(tf.cast(correct_predictions, \"float\"), name=\"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
