{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[ 0.01870418],\n",
       "         [-0.92921925],\n",
       "         [-0.12055087],\n",
       "         [ 0.18857121],\n",
       "         [ 0.12271571]],\n",
       "\n",
       "        [[ 0.81799889],\n",
       "         [-0.49390912],\n",
       "         [-0.92477608],\n",
       "         [ 0.63109088],\n",
       "         [ 0.47854328]],\n",
       "\n",
       "        [[ 0.48442602],\n",
       "         [-0.2362926 ],\n",
       "         [-0.11595845],\n",
       "         [-0.72293115],\n",
       "         [ 0.52442193]],\n",
       "\n",
       "        [[-0.46741796],\n",
       "         [-0.29171753],\n",
       "         [-0.6304512 ],\n",
       "         [ 0.06384611],\n",
       "         [-0.43557835]],\n",
       "\n",
       "        [[-0.49989343],\n",
       "         [-0.36670852],\n",
       "         [ 0.36700058],\n",
       "         [-0.1702528 ],\n",
       "         [-0.20752215]],\n",
       "\n",
       "        [[-0.74625754],\n",
       "         [-0.47256565],\n",
       "         [-0.18132567],\n",
       "         [ 0.35549712],\n",
       "         [-0.04972649]],\n",
       "\n",
       "        [[-0.46741796],\n",
       "         [-0.29171753],\n",
       "         [-0.6304512 ],\n",
       "         [ 0.06384611],\n",
       "         [-0.43557835]]],\n",
       "\n",
       "\n",
       "       [[[-0.56025958],\n",
       "         [-0.74038267],\n",
       "         [-0.10035944],\n",
       "         [ 0.33942556],\n",
       "         [ 0.50724554]],\n",
       "\n",
       "        [[ 0.14959049],\n",
       "         [ 0.83783197],\n",
       "         [-0.24767685],\n",
       "         [ 0.90597963],\n",
       "         [ 0.42244148]],\n",
       "\n",
       "        [[-0.77977419],\n",
       "         [ 0.86942482],\n",
       "         [ 0.59211326],\n",
       "         [ 0.72064853],\n",
       "         [ 0.25795937]],\n",
       "\n",
       "        [[ 0.59523892],\n",
       "         [ 0.08083701],\n",
       "         [ 0.83845043],\n",
       "         [-0.12148046],\n",
       "         [ 0.07974362]],\n",
       "\n",
       "        [[-0.49989343],\n",
       "         [-0.36670852],\n",
       "         [ 0.36700058],\n",
       "         [-0.1702528 ],\n",
       "         [-0.20752215]],\n",
       "\n",
       "        [[-0.4428401 ],\n",
       "         [-0.81487513],\n",
       "         [-0.66635919],\n",
       "         [-0.33567762],\n",
       "         [-0.84587789]],\n",
       "\n",
       "        [[ 0.59523892],\n",
       "         [ 0.08083701],\n",
       "         [ 0.83845043],\n",
       "         [-0.12148046],\n",
       "         [ 0.07974362]]],\n",
       "\n",
       "\n",
       "       [[[ 0.19945192],\n",
       "         [-0.69236016],\n",
       "         [ 0.4302001 ],\n",
       "         [ 0.29391336],\n",
       "         [ 0.13333035]],\n",
       "\n",
       "        [[-0.23569012],\n",
       "         [-0.36615825],\n",
       "         [-0.6057992 ],\n",
       "         [-0.08838987],\n",
       "         [-0.99670553]],\n",
       "\n",
       "        [[ 0.12602043],\n",
       "         [ 0.10917044],\n",
       "         [ 0.53708839],\n",
       "         [-0.25069785],\n",
       "         [-0.11043501]],\n",
       "\n",
       "        [[ 0.97246957],\n",
       "         [ 0.02068782],\n",
       "         [-0.40937638],\n",
       "         [-0.41666961],\n",
       "         [-0.24201369]],\n",
       "\n",
       "        [[-0.49989343],\n",
       "         [-0.36670852],\n",
       "         [ 0.36700058],\n",
       "         [-0.1702528 ],\n",
       "         [-0.20752215]],\n",
       "\n",
       "        [[ 0.44204903],\n",
       "         [-0.28401184],\n",
       "         [ 0.70003104],\n",
       "         [-0.06749225],\n",
       "         [-0.07752967]],\n",
       "\n",
       "        [[ 0.97246957],\n",
       "         [ 0.02068782],\n",
       "         [-0.40937638],\n",
       "         [-0.41666961],\n",
       "         [-0.24201369]]],\n",
       "\n",
       "\n",
       "       [[[-0.12060452],\n",
       "         [ 0.45922184],\n",
       "         [-0.73926759],\n",
       "         [ 0.76385093],\n",
       "         [ 0.34210563]],\n",
       "\n",
       "        [[-0.85705924],\n",
       "         [-0.09785795],\n",
       "         [-0.3584094 ],\n",
       "         [ 0.76607037],\n",
       "         [-0.46503258]],\n",
       "\n",
       "        [[-0.92195272],\n",
       "         [ 0.69750237],\n",
       "         [-0.2332325 ],\n",
       "         [-0.96447802],\n",
       "         [-0.05293107]],\n",
       "\n",
       "        [[ 0.12859106],\n",
       "         [ 0.06823874],\n",
       "         [ 0.69701481],\n",
       "         [-0.58400297],\n",
       "         [ 0.00360012]],\n",
       "\n",
       "        [[-0.49989343],\n",
       "         [-0.36670852],\n",
       "         [ 0.36700058],\n",
       "         [-0.1702528 ],\n",
       "         [-0.20752215]],\n",
       "\n",
       "        [[-0.07154846],\n",
       "         [-0.56780958],\n",
       "         [-0.97263169],\n",
       "         [-0.92443514],\n",
       "         [-0.8284483 ]],\n",
       "\n",
       "        [[ 0.12859106],\n",
       "         [ 0.06823874],\n",
       "         [ 0.69701481],\n",
       "         [-0.58400297],\n",
       "         [ 0.00360012]]]], dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "sequence_length = 7\n",
    "vocab_size = 128\n",
    "embedding_size = 5\n",
    "\n",
    "# emb captures embeddings for the entire vocabulary\n",
    "# Usually obtained through word2vec training using some corpus (example: news data)\n",
    "# But for this toy example, we are randomly generating them - [128 x 5] matrix\n",
    "# We are also assuming we have only 128 words in this vocab set\n",
    "emb = tf.Variable(tf.random_uniform([vocab_size, embedding_size], -1.0, 1.0), name=\"emb\")\n",
    "\n",
    "# Place holder to hold batch of sentences\n",
    "# In this example, sentence is limited to max 7 words\n",
    "input_x = tf.placeholder(tf.int32, [None, sequence_length], name=\"input_x\")\n",
    "\n",
    "# Look up word embeddings from emb for each sentence (pay attention to matrix shape)\n",
    "emb_input = tf.nn.embedding_lookup(emb, input_x)\n",
    "\n",
    "# Add one more dimension at end - channel, so that we can use conv2d later\n",
    "# conv2d operator requires input to be in [batch, height, width, channel]\n",
    "# in our example we have only channel (in case of images, we may have 3 channels)\n",
    "# Convert data from [batch, height, width] => [batch, height, width, channel]\n",
    "# Remember - we are just adding one dimension to matrix, it can only have one channel\n",
    "emb_input_expanded = tf.expand_dims(emb_input, -1)\n",
    "\n",
    "# Create session and initialize weight matrices\n",
    "sess = tf.Session()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "# Write graph definition to a file, so that tensorboard can read it ...\n",
    "writer = tf.summary.FileWriter(\"./cnn_text\", graph=tf.get_default_graph())\n",
    "\n",
    "# Input setup, each row is one sentence, each column represents one word\n",
    "# Pick each words embeddings from previously trained embeddings\n",
    "# Batch contains 4 sentences, each sentence is one training sample (add labels later)\n",
    "batch_x = [\n",
    "    [1, 4, 6, 8, 20, 2, 8], \n",
    "    [11, 14, 16, 18, 20, 12, 18],\n",
    "    [21, 24, 26, 28, 20, 22, 28],\n",
    "    [31, 34, 36, 38, 20, 32, 38],\n",
    "]\n",
    "\n",
    "sess.run(emb_input_expanded, feed_dict={input_x:batch_x})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word embeddings matrix (128 vocab, each word is represented by 5 dimensions)\n",
    "w = sess.run(emb, feed_dict={input_x:batch_x})\n",
    "w.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.74625754, -0.47256565, -0.18132567,  0.35549712, -0.04972649], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just check out word embeddings of word 3 (index starts at 0)\n",
    "w[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 6, 8, 20, 2, 8]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just check input - batch of 4 sentences, explore the first sentence\n",
    "# Composed of 7 words indicated by their indices in vocabulary \n",
    "# Example - this sentence may by \"I like this movie very much !\"\n",
    "batch_x[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7, 5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract word embeddings for the entire batch [4 ,7]  (4 sentences and each sentence - 7 words)\n",
    "# batch [4, 7] => [4, 7, 5]\n",
    "we = sess.run(emb_input, feed_dict={input_x:batch_x})\n",
    "we.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01870418, -0.92921925, -0.12055087,  0.18857121,  0.12271571],\n",
       "       [ 0.81799889, -0.49390912, -0.92477608,  0.63109088,  0.47854328],\n",
       "       [ 0.48442602, -0.2362926 , -0.11595845, -0.72293115,  0.52442193],\n",
       "       [-0.46741796, -0.29171753, -0.6304512 ,  0.06384611, -0.43557835],\n",
       "       [-0.49989343, -0.36670852,  0.36700058, -0.1702528 , -0.20752215],\n",
       "       [-0.74625754, -0.47256565, -0.18132567,  0.35549712, -0.04972649],\n",
       "       [-0.46741796, -0.29171753, -0.6304512 ,  0.06384611, -0.43557835]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Explore first sentence word embeddings \n",
    "# these are word embeddings for sentence 0 => \"I like this movie very much !\" => [1, 4, 6, 8, 20, 2, 8]\n",
    "we[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 7, 5, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally convert [4, 7, 5] matrix into [4, 7, 5, 1] - Just added one dimension \n",
    "we_exp = sess.run(emb_input_expanded, feed_dict={input_x:batch_x})\n",
    "we_exp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.01870418],\n",
       "        [-0.92921925],\n",
       "        [-0.12055087],\n",
       "        [ 0.18857121],\n",
       "        [ 0.12271571]],\n",
       "\n",
       "       [[ 0.81799889],\n",
       "        [-0.49390912],\n",
       "        [-0.92477608],\n",
       "        [ 0.63109088],\n",
       "        [ 0.47854328]],\n",
       "\n",
       "       [[ 0.48442602],\n",
       "        [-0.2362926 ],\n",
       "        [-0.11595845],\n",
       "        [-0.72293115],\n",
       "        [ 0.52442193]],\n",
       "\n",
       "       [[-0.46741796],\n",
       "        [-0.29171753],\n",
       "        [-0.6304512 ],\n",
       "        [ 0.06384611],\n",
       "        [-0.43557835]],\n",
       "\n",
       "       [[-0.49989343],\n",
       "        [-0.36670852],\n",
       "        [ 0.36700058],\n",
       "        [-0.1702528 ],\n",
       "        [-0.20752215]],\n",
       "\n",
       "       [[-0.74625754],\n",
       "        [-0.47256565],\n",
       "        [-0.18132567],\n",
       "        [ 0.35549712],\n",
       "        [-0.04972649]],\n",
       "\n",
       "       [[-0.46741796],\n",
       "        [-0.29171753],\n",
       "        [-0.6304512 ],\n",
       "        [ 0.06384611],\n",
       "        [-0.43557835]]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "we_exp[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
